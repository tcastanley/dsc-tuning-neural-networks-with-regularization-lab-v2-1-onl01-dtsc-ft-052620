{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:08:34.371971Z",
     "start_time": "2020-09-14T16:08:34.365903Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:08:35.486050Z",
     "start_time": "2020-09-14T16:08:34.773971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 2 columns):\n",
      "Product                         60000 non-null object\n",
      "Consumer complaint narrative    60000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 937.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:00.589435Z",
     "start_time": "2020-09-14T16:09:00.581416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(10000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df_sample['Product']\n",
    "X = df_sample['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:01.603235Z",
     "start_time": "2020-09-14T16:09:01.597246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:02.231078Z",
     "start_time": "2020-09-14T16:09:02.225127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:15.020619Z",
     "start_time": "2020-09-14T16:09:12.801530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:29.535105Z",
     "start_time": "2020-09-14T16:09:29.509117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:08:37.200162Z",
     "start_time": "2020-09-14T16:08:37.196131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2000)\n",
      "(1, 2000)\n",
      "(1000, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens.shape)\n",
    "print(X_val_tokens.shape)\n",
    "print(y_val_lb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:39.046695Z",
     "start_time": "2020-09-14T16:09:39.016774Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:09:47.387583Z",
     "start_time": "2020-09-14T16:09:47.362691Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer='SGD', \n",
    "                       loss='categorical_crossentropy', \n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:10:27.105591Z",
     "start_time": "2020-09-14T16:09:55.173980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.9294 - acc: 0.1839 - val_loss: 1.9276 - val_acc: 0.1890\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.9054 - acc: 0.2129 - val_loss: 1.9076 - val_acc: 0.1880\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8818 - acc: 0.2397 - val_loss: 1.8856 - val_acc: 0.2020\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8554 - acc: 0.2595 - val_loss: 1.8599 - val_acc: 0.2300\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8243 - acc: 0.2896 - val_loss: 1.8287 - val_acc: 0.2620\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.7872 - acc: 0.3196 - val_loss: 1.7915 - val_acc: 0.2910\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.7438 - acc: 0.3517 - val_loss: 1.7493 - val_acc: 0.3060\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.6947 - acc: 0.3841 - val_loss: 1.7019 - val_acc: 0.3450\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.6410 - acc: 0.4169 - val_loss: 1.6501 - val_acc: 0.3810\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.5845 - acc: 0.4509 - val_loss: 1.5972 - val_acc: 0.4010\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.5272 - acc: 0.4823 - val_loss: 1.5423 - val_acc: 0.4280\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.4705 - acc: 0.5100 - val_loss: 1.4877 - val_acc: 0.4600\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.4153 - acc: 0.5389 - val_loss: 1.4357 - val_acc: 0.4850\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.3620 - acc: 0.5608 - val_loss: 1.3842 - val_acc: 0.5250\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.3114 - acc: 0.5801 - val_loss: 1.3368 - val_acc: 0.5380\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.2632 - acc: 0.5992 - val_loss: 1.2914 - val_acc: 0.5640\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.2185 - acc: 0.6077 - val_loss: 1.2494 - val_acc: 0.5850\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.1767 - acc: 0.6245 - val_loss: 1.2097 - val_acc: 0.5940\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.1381 - acc: 0.6367 - val_loss: 1.1748 - val_acc: 0.5910\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.1016 - acc: 0.6480 - val_loss: 1.1404 - val_acc: 0.6090\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.0680 - acc: 0.6557 - val_loss: 1.1092 - val_acc: 0.6280\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.0368 - acc: 0.6661 - val_loss: 1.0809 - val_acc: 0.6330\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.0079 - acc: 0.6733 - val_loss: 1.0539 - val_acc: 0.6400\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.9808 - acc: 0.6795 - val_loss: 1.0287 - val_acc: 0.6470\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9556 - acc: 0.6873 - val_loss: 1.0094 - val_acc: 0.6470\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9325 - acc: 0.6935 - val_loss: 0.9852 - val_acc: 0.6550\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.9102 - acc: 0.6997 - val_loss: 0.9668 - val_acc: 0.6590\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8896 - acc: 0.7057 - val_loss: 0.9484 - val_acc: 0.6610\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8703 - acc: 0.7084 - val_loss: 0.9320 - val_acc: 0.6640\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8526 - acc: 0.7173 - val_loss: 0.9151 - val_acc: 0.6810\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8351 - acc: 0.7213 - val_loss: 0.8999 - val_acc: 0.6840\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8192 - acc: 0.7275 - val_loss: 0.8919 - val_acc: 0.6840\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.8042 - acc: 0.7335 - val_loss: 0.8727 - val_acc: 0.6860\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7898 - acc: 0.7384 - val_loss: 0.8624 - val_acc: 0.6960\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7765 - acc: 0.7405 - val_loss: 0.8497 - val_acc: 0.6960\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7635 - acc: 0.7480 - val_loss: 0.8396 - val_acc: 0.7020\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7511 - acc: 0.7497 - val_loss: 0.8277 - val_acc: 0.7040\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7391 - acc: 0.7521 - val_loss: 0.8208 - val_acc: 0.7050\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7279 - acc: 0.7591 - val_loss: 0.8155 - val_acc: 0.7090\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7173 - acc: 0.7604 - val_loss: 0.8025 - val_acc: 0.7140\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7069 - acc: 0.7637 - val_loss: 0.7949 - val_acc: 0.7160\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.6970 - acc: 0.7660 - val_loss: 0.7876 - val_acc: 0.7150\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.6874 - acc: 0.7684 - val_loss: 0.7811 - val_acc: 0.7160\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.6787 - acc: 0.7745 - val_loss: 0.7761 - val_acc: 0.7130\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6706 - acc: 0.7767 - val_loss: 0.7701 - val_acc: 0.7220\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6618 - acc: 0.7804 - val_loss: 0.7624 - val_acc: 0.7180\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6535 - acc: 0.7836 - val_loss: 0.7533 - val_acc: 0.7190\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6460 - acc: 0.7845 - val_loss: 0.7515 - val_acc: 0.7190\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.6385 - acc: 0.7875 - val_loss: 0.7438 - val_acc: 0.7210\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.6311 - acc: 0.7896 - val_loss: 0.7426 - val_acc: 0.7220\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.6239 - acc: 0.7897 - val_loss: 0.7363 - val_acc: 0.7220\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6175 - acc: 0.7937 - val_loss: 0.7344 - val_acc: 0.7250\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6108 - acc: 0.7968 - val_loss: 0.7315 - val_acc: 0.7330\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.6043 - acc: 0.7969 - val_loss: 0.7220 - val_acc: 0.7280\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5976 - acc: 0.8000 - val_loss: 0.7254 - val_acc: 0.7250\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.5924 - acc: 0.8011 - val_loss: 0.7152 - val_acc: 0.7290\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.5859 - acc: 0.8047 - val_loss: 0.7144 - val_acc: 0.7280\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5798 - acc: 0.8064 - val_loss: 0.7119 - val_acc: 0.7220\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.5746 - acc: 0.8087 - val_loss: 0.7100 - val_acc: 0.7300\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5695 - acc: 0.8095 - val_loss: 0.7074 - val_acc: 0.7340\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5634 - acc: 0.8121 - val_loss: 0.7012 - val_acc: 0.7410\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5581 - acc: 0.8155 - val_loss: 0.6993 - val_acc: 0.7280\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.5533 - acc: 0.8155 - val_loss: 0.6996 - val_acc: 0.7390\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5481 - acc: 0.8175 - val_loss: 0.6943 - val_acc: 0.7300\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5431 - acc: 0.8211 - val_loss: 0.6927 - val_acc: 0.7380\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5384 - acc: 0.8219 - val_loss: 0.6947 - val_acc: 0.7410\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5339 - acc: 0.8200 - val_loss: 0.6870 - val_acc: 0.7320\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5289 - acc: 0.8257 - val_loss: 0.6873 - val_acc: 0.7340\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5244 - acc: 0.8265 - val_loss: 0.6847 - val_acc: 0.7380\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5196 - acc: 0.8272 - val_loss: 0.6837 - val_acc: 0.7350\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5154 - acc: 0.8303 - val_loss: 0.6793 - val_acc: 0.7380\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.5108 - acc: 0.8299 - val_loss: 0.6811 - val_acc: 0.7360\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5070 - acc: 0.8309 - val_loss: 0.6760 - val_acc: 0.7360\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.5026 - acc: 0.8337 - val_loss: 0.6771 - val_acc: 0.7420\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.4985 - acc: 0.8360 - val_loss: 0.6773 - val_acc: 0.7400\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.4942 - acc: 0.8360 - val_loss: 0.6772 - val_acc: 0.7430\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4900 - acc: 0.8371 - val_loss: 0.6745 - val_acc: 0.7410\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4861 - acc: 0.8393 - val_loss: 0.6691 - val_acc: 0.7450\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4825 - acc: 0.8419 - val_loss: 0.6715 - val_acc: 0.7460\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4783 - acc: 0.8419 - val_loss: 0.6709 - val_acc: 0.7400\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4745 - acc: 0.8449 - val_loss: 0.6733 - val_acc: 0.7440\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.4710 - acc: 0.8468 - val_loss: 0.6681 - val_acc: 0.7420\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4669 - acc: 0.8473 - val_loss: 0.6690 - val_acc: 0.7440\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4637 - acc: 0.8477 - val_loss: 0.6644 - val_acc: 0.7410\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4597 - acc: 0.8504 - val_loss: 0.6637 - val_acc: 0.7430\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4560 - acc: 0.8521 - val_loss: 0.6666 - val_acc: 0.7430\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4522 - acc: 0.8527 - val_loss: 0.6654 - val_acc: 0.7410\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4488 - acc: 0.8527 - val_loss: 0.6674 - val_acc: 0.7450\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4454 - acc: 0.8551 - val_loss: 0.6649 - val_acc: 0.7460\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4418 - acc: 0.8559 - val_loss: 0.6624 - val_acc: 0.7470\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4389 - acc: 0.8569 - val_loss: 0.6666 - val_acc: 0.7430\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4352 - acc: 0.8595 - val_loss: 0.6614 - val_acc: 0.7490\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4319 - acc: 0.8583 - val_loss: 0.6693 - val_acc: 0.7370\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4289 - acc: 0.8604 - val_loss: 0.6642 - val_acc: 0.7410\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.4252 - acc: 0.8625 - val_loss: 0.6613 - val_acc: 0.7470\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4222 - acc: 0.8645 - val_loss: 0.6641 - val_acc: 0.7440\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4187 - acc: 0.8636 - val_loss: 0.6597 - val_acc: 0.7430\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4160 - acc: 0.8671 - val_loss: 0.6642 - val_acc: 0.7430\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4129 - acc: 0.8699 - val_loss: 0.6623 - val_acc: 0.7480\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4091 - acc: 0.8700 - val_loss: 0.6601 - val_acc: 0.7480\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4063 - acc: 0.8715 - val_loss: 0.6612 - val_acc: 0.7420\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.4030 - acc: 0.8720 - val_loss: 0.6598 - val_acc: 0.7470\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.4002 - acc: 0.8731 - val_loss: 0.6595 - val_acc: 0.7460\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3972 - acc: 0.8748 - val_loss: 0.6620 - val_acc: 0.7460\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3939 - acc: 0.8760 - val_loss: 0.6609 - val_acc: 0.7390\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3913 - acc: 0.8772 - val_loss: 0.6624 - val_acc: 0.7440\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3885 - acc: 0.8789 - val_loss: 0.6589 - val_acc: 0.7460\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3857 - acc: 0.8787 - val_loss: 0.6655 - val_acc: 0.7380\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3824 - acc: 0.8812 - val_loss: 0.6645 - val_acc: 0.7410\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.3797 - acc: 0.8815 - val_loss: 0.6644 - val_acc: 0.7470\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3772 - acc: 0.8833 - val_loss: 0.6653 - val_acc: 0.7460\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3740 - acc: 0.8836 - val_loss: 0.6653 - val_acc: 0.7400\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3712 - acc: 0.8839 - val_loss: 0.6627 - val_acc: 0.7450\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3686 - acc: 0.8844 - val_loss: 0.6666 - val_acc: 0.7440\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3661 - acc: 0.8877 - val_loss: 0.6663 - val_acc: 0.7420\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3636 - acc: 0.8861 - val_loss: 0.6638 - val_acc: 0.7420\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3609 - acc: 0.8884 - val_loss: 0.6662 - val_acc: 0.7410\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3582 - acc: 0.8885 - val_loss: 0.6654 - val_acc: 0.7420\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3556 - acc: 0.8891 - val_loss: 0.6672 - val_acc: 0.7420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3525 - acc: 0.8903 - val_loss: 0.6690 - val_acc: 0.7430\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3505 - acc: 0.8901 - val_loss: 0.6758 - val_acc: 0.7390\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3487 - acc: 0.8912 - val_loss: 0.6718 - val_acc: 0.7420\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3454 - acc: 0.8925 - val_loss: 0.6691 - val_acc: 0.7450\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3432 - acc: 0.8943 - val_loss: 0.6718 - val_acc: 0.7440\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3406 - acc: 0.8935 - val_loss: 0.6682 - val_acc: 0.7460\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3378 - acc: 0.8963 - val_loss: 0.6680 - val_acc: 0.7470\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3357 - acc: 0.8953 - val_loss: 0.6712 - val_acc: 0.7470\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3335 - acc: 0.8960 - val_loss: 0.6708 - val_acc: 0.7470\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3310 - acc: 0.8980 - val_loss: 0.6722 - val_acc: 0.7440\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3283 - acc: 0.8991 - val_loss: 0.6770 - val_acc: 0.7420\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3264 - acc: 0.9003 - val_loss: 0.6779 - val_acc: 0.7430\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3239 - acc: 0.9008 - val_loss: 0.6787 - val_acc: 0.7430\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3215 - acc: 0.9013 - val_loss: 0.6751 - val_acc: 0.7470\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3190 - acc: 0.9031 - val_loss: 0.6756 - val_acc: 0.7440\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3173 - acc: 0.9051 - val_loss: 0.6827 - val_acc: 0.7390\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3150 - acc: 0.9059 - val_loss: 0.6744 - val_acc: 0.7490\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3124 - acc: 0.9055 - val_loss: 0.6794 - val_acc: 0.7480\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3106 - acc: 0.9075 - val_loss: 0.6784 - val_acc: 0.7480\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3078 - acc: 0.9065 - val_loss: 0.6802 - val_acc: 0.7460\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3061 - acc: 0.9093 - val_loss: 0.6800 - val_acc: 0.7490\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3039 - acc: 0.9096 - val_loss: 0.6807 - val_acc: 0.7470\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3020 - acc: 0.9096 - val_loss: 0.6811 - val_acc: 0.7480\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.2999 - acc: 0.9093 - val_loss: 0.6932 - val_acc: 0.7410\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.2978 - acc: 0.9100 - val_loss: 0.6833 - val_acc: 0.7490\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.2957 - acc: 0.9124 - val_loss: 0.6839 - val_acc: 0.7500\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.2936 - acc: 0.9116 - val_loss: 0.6885 - val_acc: 0.7470\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.2914 - acc: 0.9131 - val_loss: 0.6881 - val_acc: 0.7490\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.2899 - acc: 0.9123 - val_loss: 0.6875 - val_acc: 0.7450\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.2877 - acc: 0.9140 - val_loss: 0.6900 - val_acc: 0.7480\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.2858 - acc: 0.9161 - val_loss: 0.6974 - val_acc: 0.7390\n"
     ]
    }
   ],
   "source": [
    "baseline_model_val = baseline_model.fit(X_train_tokens, \n",
    "                                        y_train_lb, \n",
    "                                        epochs=150, \n",
    "                                        batch_size=256, \n",
    "                                        validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:11:46.854356Z",
     "start_time": "2020-09-14T16:11:46.849401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:13:52.800678Z",
     "start_time": "2020-09-14T16:13:52.533689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step\n",
      "----------\n",
      "Training Loss: 0.285 \n",
      "Training Accuracy: 0.914\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:14:53.908082Z",
     "start_time": "2020-09-14T16:14:53.834766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 46us/step\n",
      "----------\n",
      "Test Loss: 0.627 \n",
      "Test Accuracy: 0.779\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:17:05.772501Z",
     "start_time": "2020-09-14T16:17:05.467714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "plt.plot(baseline_model_val_dict['loss'], 'b', label='Training Loss')\n",
    "plt.plot(baseline_model_val_dict['val_loss'], 'orange', label='Val Loss')\n",
    "plt.title('Training vs Val Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:17:39.449710Z",
     "start_time": "2020-09-14T16:17:39.303144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets\n",
    "plt.plot(baseline_model_val_dict['acc'], 'b', label='Training Acc')\n",
    "plt.plot(baseline_model_val_dict['val_acc'], 'orange', label='Val Acc')\n",
    "plt.title('Training vs Val Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:19:15.195784Z",
     "start_time": "2020-09-14T16:19:15.138886Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:25:37.578449Z",
     "start_time": "2020-09-14T16:25:37.575254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(patience=10, monitor='val_loss'),\n",
    "                  ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:27:24.572637Z",
     "start_time": "2020-09-14T16:26:52.917682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.9333 - acc: 0.1808 - val_loss: 1.9247 - val_acc: 0.1810\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9138 - acc: 0.2100 - val_loss: 1.9094 - val_acc: 0.2010\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8974 - acc: 0.2321 - val_loss: 1.8943 - val_acc: 0.2220\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8808 - acc: 0.2552 - val_loss: 1.8785 - val_acc: 0.2360\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8629 - acc: 0.2747 - val_loss: 1.8605 - val_acc: 0.2570\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8431 - acc: 0.2947 - val_loss: 1.8407 - val_acc: 0.2720\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8211 - acc: 0.3133 - val_loss: 1.8183 - val_acc: 0.2910\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7962 - acc: 0.3352 - val_loss: 1.7930 - val_acc: 0.3150\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7686 - acc: 0.3620 - val_loss: 1.7656 - val_acc: 0.3480\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7388 - acc: 0.3893 - val_loss: 1.7364 - val_acc: 0.3710\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7065 - acc: 0.4225 - val_loss: 1.7052 - val_acc: 0.3920\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.6714 - acc: 0.4445 - val_loss: 1.6717 - val_acc: 0.4200\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.6340 - acc: 0.4708 - val_loss: 1.6347 - val_acc: 0.4590\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5949 - acc: 0.4935 - val_loss: 1.5965 - val_acc: 0.4750\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5544 - acc: 0.5149 - val_loss: 1.5571 - val_acc: 0.4890\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5128 - acc: 0.5389 - val_loss: 1.5177 - val_acc: 0.5100\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4705 - acc: 0.5548 - val_loss: 1.4766 - val_acc: 0.5410\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4278 - acc: 0.5771 - val_loss: 1.4370 - val_acc: 0.5530\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3852 - acc: 0.5911 - val_loss: 1.3942 - val_acc: 0.5680\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3427 - acc: 0.6083 - val_loss: 1.3536 - val_acc: 0.5880\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3008 - acc: 0.6213 - val_loss: 1.3154 - val_acc: 0.5950\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2596 - acc: 0.6321 - val_loss: 1.2739 - val_acc: 0.6200\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2198 - acc: 0.6481 - val_loss: 1.2370 - val_acc: 0.6320\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1813 - acc: 0.6619 - val_loss: 1.2012 - val_acc: 0.6430\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1447 - acc: 0.6711 - val_loss: 1.1681 - val_acc: 0.6500\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1100 - acc: 0.6773 - val_loss: 1.1344 - val_acc: 0.6630\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.0767 - acc: 0.6856 - val_loss: 1.1039 - val_acc: 0.6740\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.0461 - acc: 0.693 - 0s 34us/step - loss: 1.0450 - acc: 0.6940 - val_loss: 1.0722 - val_acc: 0.6800\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0148 - acc: 0.7012 - val_loss: 1.0454 - val_acc: 0.6830\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9865 - acc: 0.7065 - val_loss: 1.0199 - val_acc: 0.6820\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9593 - acc: 0.7149 - val_loss: 0.9939 - val_acc: 0.6910\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9343 - acc: 0.7195 - val_loss: 0.9723 - val_acc: 0.7000\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9101 - acc: 0.7205 - val_loss: 0.9500 - val_acc: 0.7010\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.8879 - acc: 0.7280 - val_loss: 0.9278 - val_acc: 0.7100\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8663 - acc: 0.7317 - val_loss: 0.9079 - val_acc: 0.7070\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8461 - acc: 0.7361 - val_loss: 0.8906 - val_acc: 0.7170\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8268 - acc: 0.7400 - val_loss: 0.8734 - val_acc: 0.7150\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8090 - acc: 0.7437 - val_loss: 0.8569 - val_acc: 0.7130\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7918 - acc: 0.7492 - val_loss: 0.8438 - val_acc: 0.7170\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7759 - acc: 0.7545 - val_loss: 0.8342 - val_acc: 0.7170\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7613 - acc: 0.7567 - val_loss: 0.8184 - val_acc: 0.7130\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7467 - acc: 0.7624 - val_loss: 0.8077 - val_acc: 0.7120\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7333 - acc: 0.7645 - val_loss: 0.7941 - val_acc: 0.7200\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7210 - acc: 0.7676 - val_loss: 0.7850 - val_acc: 0.7230\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7087 - acc: 0.7713 - val_loss: 0.7769 - val_acc: 0.7130\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6974 - acc: 0.7711 - val_loss: 0.7654 - val_acc: 0.7160\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.6866 - acc: 0.7737 - val_loss: 0.7564 - val_acc: 0.7260\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6766 - acc: 0.7789 - val_loss: 0.7482 - val_acc: 0.7170\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6666 - acc: 0.7779 - val_loss: 0.7424 - val_acc: 0.7250\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6573 - acc: 0.7820 - val_loss: 0.7396 - val_acc: 0.7200\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6487 - acc: 0.7828 - val_loss: 0.7305 - val_acc: 0.7280\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6402 - acc: 0.7861 - val_loss: 0.7275 - val_acc: 0.7160\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6323 - acc: 0.7887 - val_loss: 0.7206 - val_acc: 0.7200\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6247 - acc: 0.7901 - val_loss: 0.7158 - val_acc: 0.7310\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6169 - acc: 0.7925 - val_loss: 0.7088 - val_acc: 0.7250\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.6097 - acc: 0.7976 - val_loss: 0.7046 - val_acc: 0.7250\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.6028 - acc: 0.8003 - val_loss: 0.7003 - val_acc: 0.7220\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5959 - acc: 0.8011 - val_loss: 0.6988 - val_acc: 0.7360\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.5901 - acc: 0.8028 - val_loss: 0.6947 - val_acc: 0.7260\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5838 - acc: 0.8057 - val_loss: 0.6894 - val_acc: 0.7290\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5777 - acc: 0.8063 - val_loss: 0.6857 - val_acc: 0.7310\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5720 - acc: 0.8084 - val_loss: 0.6856 - val_acc: 0.7370\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5666 - acc: 0.8088 - val_loss: 0.6817 - val_acc: 0.7360\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5606 - acc: 0.8111 - val_loss: 0.6770 - val_acc: 0.7250\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5552 - acc: 0.8147 - val_loss: 0.6760 - val_acc: 0.7310\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5500 - acc: 0.8159 - val_loss: 0.6770 - val_acc: 0.7330\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5449 - acc: 0.8177 - val_loss: 0.6715 - val_acc: 0.7300\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5402 - acc: 0.8179 - val_loss: 0.6696 - val_acc: 0.7300\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5350 - acc: 0.8209 - val_loss: 0.6677 - val_acc: 0.7370\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5303 - acc: 0.8227 - val_loss: 0.6672 - val_acc: 0.7320\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5256 - acc: 0.8245 - val_loss: 0.6629 - val_acc: 0.7310\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5206 - acc: 0.8268 - val_loss: 0.6625 - val_acc: 0.7360\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5164 - acc: 0.8280 - val_loss: 0.6573 - val_acc: 0.7320\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5118 - acc: 0.8309 - val_loss: 0.6577 - val_acc: 0.7320\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5077 - acc: 0.8296 - val_loss: 0.6566 - val_acc: 0.7300\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5031 - acc: 0.8321 - val_loss: 0.6556 - val_acc: 0.7320\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4993 - acc: 0.8339 - val_loss: 0.6537 - val_acc: 0.7360\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4944 - acc: 0.8361 - val_loss: 0.6537 - val_acc: 0.7320\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4905 - acc: 0.8363 - val_loss: 0.6529 - val_acc: 0.7360\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4865 - acc: 0.8388 - val_loss: 0.6514 - val_acc: 0.7310\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4826 - acc: 0.8389 - val_loss: 0.6491 - val_acc: 0.7360\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4789 - acc: 0.8411 - val_loss: 0.6501 - val_acc: 0.7320\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.4749 - acc: 0.8432 - val_loss: 0.6521 - val_acc: 0.7380\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4712 - acc: 0.8445 - val_loss: 0.6480 - val_acc: 0.7380\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4671 - acc: 0.8447 - val_loss: 0.6468 - val_acc: 0.7360\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4633 - acc: 0.8476 - val_loss: 0.6492 - val_acc: 0.7350\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4602 - acc: 0.8464 - val_loss: 0.6480 - val_acc: 0.7330\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4563 - acc: 0.8495 - val_loss: 0.6467 - val_acc: 0.7420\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4523 - acc: 0.8519 - val_loss: 0.6469 - val_acc: 0.7350\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4486 - acc: 0.8519 - val_loss: 0.6430 - val_acc: 0.7410\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4454 - acc: 0.8537 - val_loss: 0.6430 - val_acc: 0.7410\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4419 - acc: 0.8541 - val_loss: 0.6419 - val_acc: 0.7460\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4382 - acc: 0.8569 - val_loss: 0.6432 - val_acc: 0.7420\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.4351 - acc: 0.8571 - val_loss: 0.6433 - val_acc: 0.7460\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4318 - acc: 0.8581 - val_loss: 0.6437 - val_acc: 0.7430\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4287 - acc: 0.8597 - val_loss: 0.6449 - val_acc: 0.7400\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4252 - acc: 0.8597 - val_loss: 0.6419 - val_acc: 0.7430\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4219 - acc: 0.8624 - val_loss: 0.6422 - val_acc: 0.7490\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4190 - acc: 0.8631 - val_loss: 0.6432 - val_acc: 0.7430\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4157 - acc: 0.8641 - val_loss: 0.6414 - val_acc: 0.7480\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4125 - acc: 0.8655 - val_loss: 0.6456 - val_acc: 0.7440\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4099 - acc: 0.8677 - val_loss: 0.6418 - val_acc: 0.7430\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4060 - acc: 0.8667 - val_loss: 0.6496 - val_acc: 0.7420\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.4034 - acc: 0.8680 - val_loss: 0.6455 - val_acc: 0.7480\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4001 - acc: 0.8705 - val_loss: 0.6408 - val_acc: 0.7510\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3970 - acc: 0.8728 - val_loss: 0.6429 - val_acc: 0.7430\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3944 - acc: 0.8720 - val_loss: 0.6447 - val_acc: 0.7450\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3913 - acc: 0.8713 - val_loss: 0.6474 - val_acc: 0.7450\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3883 - acc: 0.8747 - val_loss: 0.6438 - val_acc: 0.7480\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3853 - acc: 0.8743 - val_loss: 0.6447 - val_acc: 0.7490\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3822 - acc: 0.8799 - val_loss: 0.6498 - val_acc: 0.7500\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3797 - acc: 0.8795 - val_loss: 0.6471 - val_acc: 0.7460\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3769 - acc: 0.8812 - val_loss: 0.6428 - val_acc: 0.7500\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3736 - acc: 0.8813 - val_loss: 0.6481 - val_acc: 0.7520\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3709 - acc: 0.8833 - val_loss: 0.6427 - val_acc: 0.7510\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens,\n",
    "                          y_train_lb,\n",
    "                          epochs=150,\n",
    "                          batch_size=256,\n",
    "                          validation_data=(X_val_tokens, y_val_lb),\n",
    "                          callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:28:13.562623Z",
     "start_time": "2020-09-14T16:28:13.210610Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:28:16.869324Z",
     "start_time": "2020-09-14T16:28:16.510896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 39us/step\n",
      "Training Loss: 0.397 \n",
      "Training Accuracy: 0.873\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 37us/step\n",
      "Test Loss: 0.593 \n",
      "Test Accuracy: 0.774\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:33:00.673916Z",
     "start_time": "2020-09-14T16:32:19.313402Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 2.5852 - acc: 0.1735 - val_loss: 2.5688 - val_acc: 0.1660\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.5576 - acc: 0.2063 - val_loss: 2.5468 - val_acc: 0.2080\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.5345 - acc: 0.2407 - val_loss: 2.5254 - val_acc: 0.2370\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.5110 - acc: 0.2748 - val_loss: 2.5028 - val_acc: 0.2630\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.4855 - acc: 0.3081 - val_loss: 2.4775 - val_acc: 0.2960\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.4570 - acc: 0.3317 - val_loss: 2.4492 - val_acc: 0.3350\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.4245 - acc: 0.3713 - val_loss: 2.4169 - val_acc: 0.3890\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.3880 - acc: 0.4028 - val_loss: 2.3801 - val_acc: 0.4070\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.3471 - acc: 0.4339 - val_loss: 2.3397 - val_acc: 0.4380\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.3020 - acc: 0.4619 - val_loss: 2.2956 - val_acc: 0.4650\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.2534 - acc: 0.4924 - val_loss: 2.2479 - val_acc: 0.4840\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.2016 - acc: 0.5163 - val_loss: 2.1981 - val_acc: 0.5080\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.1484 - acc: 0.5416 - val_loss: 2.1463 - val_acc: 0.5280\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 2.0951 - acc: 0.5661 - val_loss: 2.0962 - val_acc: 0.5450\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.0420 - acc: 0.5807 - val_loss: 2.0462 - val_acc: 0.5620\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.9898 - acc: 0.5967 - val_loss: 1.9971 - val_acc: 0.5850\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.9392 - acc: 0.6141 - val_loss: 1.9490 - val_acc: 0.5910\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8898 - acc: 0.6297 - val_loss: 1.9038 - val_acc: 0.6050\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8424 - acc: 0.6439 - val_loss: 1.8579 - val_acc: 0.6120\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.7975 - acc: 0.6585 - val_loss: 1.8181 - val_acc: 0.6170\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.7546 - acc: 0.6681 - val_loss: 1.7779 - val_acc: 0.6260\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.7145 - acc: 0.6757 - val_loss: 1.7385 - val_acc: 0.6290\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6762 - acc: 0.6896 - val_loss: 1.7040 - val_acc: 0.6370\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.6408 - acc: 0.6993 - val_loss: 1.6724 - val_acc: 0.6420\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.6076 - acc: 0.7057 - val_loss: 1.6415 - val_acc: 0.6480\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.5769 - acc: 0.7116 - val_loss: 1.6138 - val_acc: 0.6520\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5481 - acc: 0.7183 - val_loss: 1.5873 - val_acc: 0.6640\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.5212 - acc: 0.7241 - val_loss: 1.5634 - val_acc: 0.6690\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4964 - acc: 0.7291 - val_loss: 1.5397 - val_acc: 0.6730\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4730 - acc: 0.7337 - val_loss: 1.5199 - val_acc: 0.6760\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4515 - acc: 0.7371 - val_loss: 1.5027 - val_acc: 0.6820\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4316 - acc: 0.7392 - val_loss: 1.4807 - val_acc: 0.6870\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4121 - acc: 0.7479 - val_loss: 1.4678 - val_acc: 0.6950\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.3949 - acc: 0.7504 - val_loss: 1.4505 - val_acc: 0.6930\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3775 - acc: 0.7544 - val_loss: 1.4358 - val_acc: 0.6960\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3619 - acc: 0.7568 - val_loss: 1.4215 - val_acc: 0.7000\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3467 - acc: 0.7616 - val_loss: 1.4065 - val_acc: 0.7020\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3329 - acc: 0.7655 - val_loss: 1.3963 - val_acc: 0.7030\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.3195 - acc: 0.7672 - val_loss: 1.3877 - val_acc: 0.7070\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3074 - acc: 0.7709 - val_loss: 1.3757 - val_acc: 0.7120\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2949 - acc: 0.7723 - val_loss: 1.3643 - val_acc: 0.7150\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2832 - acc: 0.7759 - val_loss: 1.3559 - val_acc: 0.7130\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.2721 - acc: 0.7781 - val_loss: 1.3466 - val_acc: 0.7170\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.2613 - acc: 0.7817 - val_loss: 1.3361 - val_acc: 0.7170\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2513 - acc: 0.7829 - val_loss: 1.3293 - val_acc: 0.7190\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2415 - acc: 0.7864 - val_loss: 1.3231 - val_acc: 0.7230\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2318 - acc: 0.7875 - val_loss: 1.3140 - val_acc: 0.7240\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2223 - acc: 0.7912 - val_loss: 1.3072 - val_acc: 0.7300\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2138 - acc: 0.7940 - val_loss: 1.2999 - val_acc: 0.7260\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.2049 - acc: 0.7957 - val_loss: 1.2913 - val_acc: 0.7340\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1966 - acc: 0.7992 - val_loss: 1.2882 - val_acc: 0.7290\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1887 - acc: 0.7980 - val_loss: 1.2820 - val_acc: 0.7250\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1803 - acc: 0.8008 - val_loss: 1.2767 - val_acc: 0.7290\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1723 - acc: 0.8032 - val_loss: 1.2728 - val_acc: 0.7250\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1649 - acc: 0.7996 - val_loss: 1.2633 - val_acc: 0.7370\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1573 - acc: 0.8056 - val_loss: 1.2598 - val_acc: 0.7390\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1501 - acc: 0.8096 - val_loss: 1.2538 - val_acc: 0.7350\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1432 - acc: 0.8091 - val_loss: 1.2470 - val_acc: 0.7430\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1365 - acc: 0.8120 - val_loss: 1.2447 - val_acc: 0.7370\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1294 - acc: 0.8105 - val_loss: 1.2393 - val_acc: 0.7420\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1229 - acc: 0.8123 - val_loss: 1.2351 - val_acc: 0.7440\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1161 - acc: 0.8147 - val_loss: 1.2303 - val_acc: 0.7400\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1094 - acc: 0.8163 - val_loss: 1.2276 - val_acc: 0.7330\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1030 - acc: 0.8180 - val_loss: 1.2225 - val_acc: 0.7390\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0964 - acc: 0.8203 - val_loss: 1.2176 - val_acc: 0.7370\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0905 - acc: 0.8228 - val_loss: 1.2135 - val_acc: 0.7390\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0847 - acc: 0.8235 - val_loss: 1.2116 - val_acc: 0.7400\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0786 - acc: 0.8227 - val_loss: 1.2056 - val_acc: 0.7400\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0728 - acc: 0.8259 - val_loss: 1.1995 - val_acc: 0.7510\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0665 - acc: 0.8285 - val_loss: 1.1950 - val_acc: 0.7510\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0609 - acc: 0.8299 - val_loss: 1.1919 - val_acc: 0.7500\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0557 - acc: 0.8304 - val_loss: 1.1895 - val_acc: 0.7490\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0498 - acc: 0.8335 - val_loss: 1.1885 - val_acc: 0.7400\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0441 - acc: 0.8333 - val_loss: 1.1828 - val_acc: 0.7480\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0391 - acc: 0.8361 - val_loss: 1.1855 - val_acc: 0.7420\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0337 - acc: 0.8367 - val_loss: 1.1773 - val_acc: 0.7420\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0288 - acc: 0.8381 - val_loss: 1.1728 - val_acc: 0.7520\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0230 - acc: 0.8388 - val_loss: 1.1712 - val_acc: 0.7500\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0184 - acc: 0.8408 - val_loss: 1.1677 - val_acc: 0.7380\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0129 - acc: 0.8411 - val_loss: 1.1642 - val_acc: 0.7490\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0076 - acc: 0.8435 - val_loss: 1.1627 - val_acc: 0.7510\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0028 - acc: 0.8437 - val_loss: 1.1622 - val_acc: 0.7430\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9977 - acc: 0.8453 - val_loss: 1.1568 - val_acc: 0.7500\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9932 - acc: 0.8476 - val_loss: 1.1556 - val_acc: 0.7360\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9877 - acc: 0.8485 - val_loss: 1.1541 - val_acc: 0.7430\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9833 - acc: 0.8497 - val_loss: 1.1517 - val_acc: 0.7410\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9788 - acc: 0.8492 - val_loss: 1.1453 - val_acc: 0.7440\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9738 - acc: 0.8508 - val_loss: 1.1443 - val_acc: 0.7520\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9692 - acc: 0.8531 - val_loss: 1.1416 - val_acc: 0.7450\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9646 - acc: 0.8512 - val_loss: 1.1389 - val_acc: 0.7480\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9601 - acc: 0.8556 - val_loss: 1.1354 - val_acc: 0.7510\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9553 - acc: 0.8571 - val_loss: 1.1369 - val_acc: 0.7480\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9508 - acc: 0.8561 - val_loss: 1.1301 - val_acc: 0.7520\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9466 - acc: 0.8577 - val_loss: 1.1280 - val_acc: 0.7500\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9426 - acc: 0.8597 - val_loss: 1.1286 - val_acc: 0.7500\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9380 - acc: 0.8617 - val_loss: 1.1285 - val_acc: 0.7440\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9336 - acc: 0.8620 - val_loss: 1.1225 - val_acc: 0.7510\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9293 - acc: 0.8603 - val_loss: 1.1196 - val_acc: 0.7550\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9251 - acc: 0.8629 - val_loss: 1.1183 - val_acc: 0.7520\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9211 - acc: 0.8660 - val_loss: 1.1159 - val_acc: 0.7510\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9169 - acc: 0.8661 - val_loss: 1.1138 - val_acc: 0.7520\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9130 - acc: 0.8659 - val_loss: 1.1125 - val_acc: 0.7540\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9087 - acc: 0.8664 - val_loss: 1.1076 - val_acc: 0.7510\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9048 - acc: 0.8701 - val_loss: 1.1084 - val_acc: 0.7530\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9008 - acc: 0.8692 - val_loss: 1.1036 - val_acc: 0.7550\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8967 - acc: 0.8727 - val_loss: 1.1054 - val_acc: 0.7470\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8931 - acc: 0.8711 - val_loss: 1.1040 - val_acc: 0.7470\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8888 - acc: 0.8736 - val_loss: 1.1008 - val_acc: 0.7530\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8854 - acc: 0.8743 - val_loss: 1.0996 - val_acc: 0.7550\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8818 - acc: 0.8745 - val_loss: 1.0985 - val_acc: 0.7500\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8776 - acc: 0.8747 - val_loss: 1.0999 - val_acc: 0.7500\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8738 - acc: 0.8772 - val_loss: 1.0937 - val_acc: 0.7490\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8700 - acc: 0.8783 - val_loss: 1.1007 - val_acc: 0.7420\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8663 - acc: 0.8763 - val_loss: 1.0891 - val_acc: 0.7550\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8631 - acc: 0.8795 - val_loss: 1.0890 - val_acc: 0.7510\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8592 - acc: 0.8812 - val_loss: 1.0853 - val_acc: 0.7540\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8557 - acc: 0.8813 - val_loss: 1.0894 - val_acc: 0.7480\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8522 - acc: 0.8811 - val_loss: 1.0852 - val_acc: 0.7530\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8487 - acc: 0.8823 - val_loss: 1.0841 - val_acc: 0.7520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8452 - acc: 0.8840 - val_loss: 1.0815 - val_acc: 0.7510\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8415 - acc: 0.8851 - val_loss: 1.0792 - val_acc: 0.7560\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8379 - acc: 0.8849 - val_loss: 1.0763 - val_acc: 0.7520\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8345 - acc: 0.8868 - val_loss: 1.0782 - val_acc: 0.7540\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8313 - acc: 0.8877 - val_loss: 1.0749 - val_acc: 0.7570\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8277 - acc: 0.8880 - val_loss: 1.0726 - val_acc: 0.7560\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8247 - acc: 0.8887 - val_loss: 1.0708 - val_acc: 0.7550\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8212 - acc: 0.8904 - val_loss: 1.0723 - val_acc: 0.7560\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8179 - acc: 0.8903 - val_loss: 1.0697 - val_acc: 0.7560\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8148 - acc: 0.8911 - val_loss: 1.0714 - val_acc: 0.7560\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8111 - acc: 0.8917 - val_loss: 1.0680 - val_acc: 0.7530\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8083 - acc: 0.8928 - val_loss: 1.0710 - val_acc: 0.7470\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8055 - acc: 0.8929 - val_loss: 1.0630 - val_acc: 0.7560\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8018 - acc: 0.8935 - val_loss: 1.0616 - val_acc: 0.7610\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7988 - acc: 0.8956 - val_loss: 1.0609 - val_acc: 0.7590\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7956 - acc: 0.8957 - val_loss: 1.0612 - val_acc: 0.7580\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7925 - acc: 0.8952 - val_loss: 1.0578 - val_acc: 0.7620\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7896 - acc: 0.8985 - val_loss: 1.0615 - val_acc: 0.7490\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7867 - acc: 0.8980 - val_loss: 1.0561 - val_acc: 0.7560\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7837 - acc: 0.8985 - val_loss: 1.0536 - val_acc: 0.7600\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7806 - acc: 0.8999 - val_loss: 1.0539 - val_acc: 0.7620\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7777 - acc: 0.9009 - val_loss: 1.0538 - val_acc: 0.7580\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7748 - acc: 0.8989 - val_loss: 1.0519 - val_acc: 0.7600\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7717 - acc: 0.9012 - val_loss: 1.0519 - val_acc: 0.7550\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7690 - acc: 0.9013 - val_loss: 1.0510 - val_acc: 0.7540\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7660 - acc: 0.9009 - val_loss: 1.0506 - val_acc: 0.7600\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7635 - acc: 0.9039 - val_loss: 1.0478 - val_acc: 0.7580\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7604 - acc: 0.9048 - val_loss: 1.0472 - val_acc: 0.7620\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7575 - acc: 0.9047 - val_loss: 1.0495 - val_acc: 0.7610\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7548 - acc: 0.9069 - val_loss: 1.0450 - val_acc: 0.7590\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7518 - acc: 0.9076 - val_loss: 1.0420 - val_acc: 0.7610\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "kernel_regularizer=regularizers.l2(0.005)\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50,\n",
    "                          activation='relu',\n",
    "                          input_shape=(2000,),\n",
    "                          kernel_regularizer=kernel_regularizer))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(25,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=kernel_regularizer))\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:34:08.837792Z",
     "start_time": "2020-09-14T16:34:08.614341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAHwCAYAAACG+PhNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNX9+P/XmSUzk32ZLJBAEhBZAkkIkUUigrQolkURS1E+LVik+rEuX3/9fUstn4/g0q+tywerrdVa/LaKUC21igtWEUUUgYCsYZWsJGTfM5n1fP+YISYQMCAxEN7Px2MezL333HPPXYD3nPu+5yqtNUIIIYQQQohzY+jpBgghhBBCCHExk4BaCCGEEEKIb0ECaiGEEEIIIb4FCaiFEEIIIYT4FiSgFkIIIYQQ4luQgFoIIYQQQohvQQJqIcQZKaWMSqkmpVT/81n2QqeUekUptTTwfaJSal9Xyp7DdnrNMRPfvW9z7Qkhzh8JqIXoZQLB2YmPTynlaDd969nWp7X2aq1DtdZF57PsuVBKXaGU2qGUalRKHVBKfa87tnMyrfXHWuu081GXUmqTUmp+u7q79ZhdCk4+pu3mD1VKvaWUqlRK1Sil3lNKDeqBJgohejkJqIXoZQLBWajWOhQoAqa3m7fy5PJKKdN338pz9kfgLSAcuB441rPNEaejlDIopXr6/5gI4F/AYCAe2Am88V024EL9+3WBnB8heg35yyTEJUYp9YhS6u9KqVVKqUZgnlJqnFLqC6VUnVKqTCn1e6WUOVDepJTSSqmUwPQrgeXvBXqKNyulUs+2bGD5VKXUIaVUvVLqGaXUZ531NLbjAQq131Gt9f5v2NfDSqnr2k0HBXoq0wMBxT+UUscD+/2xUmroaer5nlKqoN30KKXUzsA+rQIs7ZbFKKXeDfSK1iql1iqlEgPLfguMA/4UuGOwvJNjFhk4bpVKqQKl1K+UUiqwbKFS6hOl1P8E2nxUKTXlDPu/JFCmUSm1Tyk146TlPwv09DcqpfYqpTIC85OVUv8KtKFKKfV0YP4jSqn/2279y5RSut30JqXUw0qpzUAz0D/Q5v2BbXyllFp4UhtmBY5lg1LqiFJqilJqrlJqy0nlfqmU+sfp9rUzWusvtNYrtNY1Wms38D9AmlIqopNjlaOUOtY+yFRK3ayU2hH4Plb57440KKXKlVKPd7bNE9eKUuoBpdRx4M+B+TOUUrsC522TUmp4u3Wy211Pq5VSr6uv040WKqU+ble2w/Vy0rZPe+0Flp9yfs7meAohTk8CaiEuTTcCr+Lvwfs7/kD1XsAOjAeuA352hvVvAf4LiMbfC/7w2ZZVSsUBrwH/f2C7+cDob2j3VuDJE4FfF6wC5rabngqUaq13B6bfBgYBCcBe4OVvqlApZQHeBFbg36c3gRvaFTHgD6L6A8mAG3gaQGv9S2AzcEfgjsF9nWzij0AwMAC4Bvgp8ON2y68E9gAx+APEv5yhuYfwn88I4FHgVaVUfGA/5gJLgFvx9/jPAmqUv0f1HeAIkAL0w3+euuo/gNsCdZYA5cAPAtO3A88opdIDbbgS/3H8/4BIYBJQSKBXWXVMz5hHF87PN5gAlGit6ztZ9hn+c3V1u3m34P97AvAM8LjWOhy4DDhTcJ8EhOK/Bv5TKXUF/mtiIf7ztgJ4M/ADz4J/f1/Efz2toeP1dDZOe+21c/L5EUKcBxJQC3Fp2qS1Xqu19mmtHVrrbVrrLVprj9b6KPACHQOLk/1Da50b6PVbCWSeQ9lpwE6t9Zvteg+rTleJUmoe/uBwHvBOu6Bs6sm9me28CtyglLIGptsCpMC+/1+tdaPWuhVYCoxSSoWcYV8ItEEDz2it3Vrr1cCXJxZqrSu11m8EjmsD8BvOfCzb76MZ+CGwONCuo/iPy3+0K/ZVoNfVC/wVSFJK2TurT2v9mta6LLCvrwIFQHZg8ULgMa319kCP/yGtdTH+HnQ78EutdXNgPz7rSvsDVmit9weOjSdwnR0NbOMjYD1wVaDsT4E/a63XB9pYrLU+qLV2AK/jP9copTKBPsC7Z9GODpT/oc/fA/d3tlxrrYHVBH6AKaUigWsD88AfnA5SSsUEzs3prjnw/0BdqrV2BfZlEfDHwN8zr9Z6RaDcFfivJ5/W+tnAMXsd2H4u+9jFa6/D+TmX7QghTiUBtRCXpuL2E0qpIUqpd5Q//aEBeAh/UHU6x9t9b8HfG3e2Zfu2b0cgoDlTj9m9wO+11u8CdwH/DgTVVwIfdraC1voA8BXwA6VUKP4g/lVoG13jd4GUiAb8PbJw5v0+0e6SQHtPKDzxRSkVopR6USlVFKj3oy7UeUIcYGxfX+B7Yrvpk48nnOb4K6Xmt0szqAOGtGtLP/zH5mT9gIJAwH4uTr62pimltih/qk0dMKULbQD/j4UTD9HOA/4e+OF11gJ3Q/4NPB0IWE/nVeCmwA+bm4AtWusT1+QCYBhwUCm1VSl1/RnqKddau9pNJwO/PHEeAsehD/7z2pdTr/tizkEXr71zqlsIcWYSUAtxadInTT+PP+XhssAt7f8GVDe3oQz/rXEAlFKKjoHjyUz4e/7QWr8J/BJ/ID0PWH6G9U6kfdyIv0e8IDD/x/gfbLwGf0rEZSeacjbtDmifi/q/gVRgdOBYXnNS2ZOPfXsVgBd/ANa+7rN++FIpNQB4DrgTiNFaRwIH+Hr/ioGBnaxaDCQrpYydLGvGn45yQkInZdrnVNvwp0b8HyA+0IZ/d6ENaK03BeoYj//8nVO6h1IqBv918g+t9W/PVDaQClSGv2e6fboHgZ7zH+H/0fMksKbdnY9TqjppuhhYprWObPcJ1lq/RufXU79237tyzE/4pmuvs7YJIc4DCaiFEABhQD3QrPwP5p0pf/p8eRvIUkpND+Tt3gvEnqH868BSpdSIwINjBwAXYANOF9iAP6Ceiv+2+6vt5ocBTqAaf8DyaBfbvQkwKKV+HnhA7GYg66R6W4DaQDD33yetX44/P/oUgR7YfwC/UUqFKv8DnP8LeKWLbWsvFH/wVIn/98pC/D3UJ7wI/G+l1EjlN0gp1Q9/jnd1oA3BSilbIKgF/ygZVyul+gVSIhZ/QxssQFCgDV6l1DRgcrvlfwEWKqUmKf9DoklKqcHtlr+M/0dBs9b6i2/YllkpZW33MSv/w4f/Bj7SWi/5hvVPWIX/mI+jXZ60Uuo/lFJ2rbUP/98VDfi6WOcLwF3KP+yjCpzb6YH0ok2AUSl1Z+B6ugkY1W7dXUB64Lq3AQ+eYTvfdO0JIbqJBNRCCPA/FPYToBF/b/Xfu3uDWutyYA7wFP4AbiD+XGTnaVb5LfA3/MPm1eDvlV6IPwB6RykVfprtlAC5wFg6Plz3ElAa+OwDPu9iu534e7tvB2rxP8z3r3ZFnsLf410dqPO9k6pYDswN3Pp/qpNN/Cf+Hwr5wCf4Ux/+1pW2ndTO3fhzhrfi7wUdAmxpt3wV/mP6d6AB+CcQFcirnQYMxd+zWgTMDqy2Dv+wc3sC9b71DW2owx+cvoH/nM3G/0PqxPLP8R/H3+MPUjfQsXf2b8BwutY7/QLgaPf5c2B7WfiD9vbjs/c9Qz2v4u/Z/UBrXdtu/vXAfuUfGecJYM5JaR2nFci3vhP/j4Na/A+LzgssO3E93RFY9kP8ueLOwPI8/LnQHwMHgY1n2NQ3XXtCiG6iOqYBCiFEzwikGJQCs7XWn/Z0e0TPC/TgVgDDtdb5Pd2e74pSajuwXGv9bUc1EUJ8R6SHWgjRY5RS1ymlIgJDh/0X/hzprT3cLHHhuAv4rLcH08r/avv4QMrHT/HfTfh3T7dLCNF1F+QbnIQQl4wc/EPpBeFPu7ghcAtcXOKUUiX4h6qb2dNt+Q4MxZ96E4J/1JObAilRQoiLhKR8CCGEEEII8S1IyocQQgghhBDfggTUQgghhBBCfAsXXQ613W7XKSkpPd0MIYQQQgjRy23fvr1Ka32mdyQAF2FAnZKSQm5ubk83QwghhBBC9HJKqcKulJOUDyGEEEIIIb4FCaiFEEIIIYT4FiSgFkIIIYQQ4lu46HKoO+N2uykpKaG1tbWnmyK6idVqJSkpCbPZ3NNNEUIIIYTooFcE1CUlJYSFhZGSkoJSqqebI84zrTXV1dWUlJSQmpra080RQgghhOigV6R8tLa2EhMTI8F0L6WUIiYmRu5ACCGEEOKC1CsCakCC6V5Ozq8QQgghLlS9JqDuSdXV1WRmZpKZmUlCQgKJiYlt0y6Xq0t1LFiwgIMHD56xzB/+8AdWrlx5Ppp83i1ZsoTly5d3mFdYWMjEiRMZNmwYaWlpPPvssz3UOiGEEEKI7tMrcqh7WkxMDDt37gRg6dKlhIaG8otf/KJDGa01WmsMhs5/w7z00kvfuJ277rrr2zf2O2Q2m1m+fDmZmZk0NDQwcuRIpkyZwuWXX97TTRNCCCGEOG+kh7obHTlyhOHDh3PHHXeQlZVFWVkZixYtIjs7m7S0NB566KG2sjk5OezcuROPx0NkZCSLFy8mIyODcePGUVFRAXTsBc7JyWHx4sWMHj2awYMH8/nnnwPQ3NzMTTfdREZGBnPnziU7O7st2G/vwQcf5Iorrmhrn9YagEOHDnHNNdeQkZFBVlYWBQUFAPzmN79hxIgRZGRk8Otf/7pL+9+3b18yMzMBCA8PZ8iQIRw7duzcDqYQQgghxAWq1/VQL1u7j7zShvNa57C+4Tw4Pe2c1s3Ly+Oll17iT3/6EwCPPfYY0dHReDweJk2axOzZsxk2bFiHderr67n66qt57LHHuP/++1mxYgWLFy8+pW6tNVu3buWtt97ioYceYt26dTzzzDMkJCSwZs0adu3aRVZWVqftuvfee1m2bBlaa2655RbWrVvH1KlTmTt3LkuXLmX69Om0trbi8/lYu3Yt7733Hlu3bsVms1FTU3PWx+Ho0aPs3buXK6644qzXFUIIIYS4kEkPdTcbOHBghyBy1apVZGVlkZWVxf79+8nLyztlHZvNxtSpUwEYNWpUWy/xyWbNmnVKmU2bNvGjH/0IgIyMDNLSOv8hsH79ekaPHk1GRgaffPIJ+/bto7a2lqqqKqZPnw74x34ODg7mww8/5LbbbsNmswEQHR19VsegoaGBm266iWeeeYbQ0NCzWlcIIYQQ4kLX63qoz7UnubuEhIS0fT98+DBPP/00W7duJTIyknnz5nU6FFxQUFDbd6PRiMfj6bRui8VySpkTqRtn0tLSws9//nN27NhBYmIiS5YsaWtHZ6NpaK3PeZQNl8vFrFmzmD9/PjNmzDinOoQQQgghLmTSQ/0damhoICwsjPDwcMrKynj//ffP+zZycnJ47bXXANizZ0+nPeAOhwODwYDdbqexsZE1a9YAEBUVhd1uZ+3atYB/fO+WlhamTJnCX/7yFxwOB0CXUz601syfP5/MzEzuvffe87F7QgghhBAXHAmov0NZWVkMGzaM4cOHc/vttzN+/Pjzvo27776bY8eOkZ6ezpNPPsnw4cOJiIjoUCYmJoaf/OQnDB8+nBtvvJExY8a0LVu5ciVPPvkk6enp5OTkUFlZybRp07juuuvIzs4mMzOT//mf/+l020uXLiUpKYmkpCRSUlL45JNPWLVqFR988EHbMILd8SNCCCGEEKInqa6kCFxIsrOzdW5ubod5+/fvZ+jQoT3UoguLx+PB4/FgtVo5fPgwU6ZM4fDhw5hMF392j5xnIYQQQnyXlFLbtdbZ31Tu4o+yRAdNTU1MnjwZj8eD1prnn3++VwTTQgghhLg0HW8+TkJIQk8344wk0uplIiMj2b59e083QwghhBDinDS5mth6fCufl37O5tLNFDUWseGHG7Db7D3dtNOSgFoIIYQQQpwXTq8Tr89LsDm4w3yvz0thQyEHag7Q6GokNjiWuOA4Ym2xeLWX3ZW72VW5i50VOzlQcwCP9mAz2RidMJpbht6C2WDuoT3qGgmohRBCCCHEOatpreGT4k/4qPgjvij9glZvK2HmMGKDY4kNjsXhdnCo9hCt3lOHCm7ParSSZk9j/vD5XNn3SjJiMwgyBp1xnQuFBNRCCCGEEJegr+q+YmPJRhpdjTi9zrbPyQNWmI1mrEYrFqMFi9FCs7uZmtYaalprqHRUcqTuCD7tIyEkgRsH3UhccByVLZVUtFRQ0VKBxWRh9uWzGRI9hCHRQ4iyRrUtr3RU4tM+RsSO4PKoyy/4nujTkYBaCCGEEKKXaXA1sP34do7WHyUuOI4+IX3oE9oHozLy74J/8/bRt9lfsx8AgzJgMVqwGq0EGYMwqK9HVdZo3F43Tq+TVm8rHp8Hi9FCjDWGaGs0CSEJXNP/Gib1m8TQ6KFdfhFcXHAcaZz6Mr4mp4f9ZQ1UNTqpanZR3eSkusnF4qlDCLFcuGFrt7ZMKXUd8DRgBF7UWj920vIoYAUwEGgFbtNa7+3ONnWHiRMn8qtf/Yprr722bd7y5cs5dOgQf/zjH0+7XmhoKE1NTZSWlnLPPffwj3/8o9O6n3jiCbKzTz9iy/Lly1m0aBHBwf58peuvv55XX32VyMjIb7FX59/HH3/ME088wdtvv91h/q233kpubi5ms5nRo0fz/PPPYzZfnL9QhRBCiO5yvPk4R+qOUNlSSXlLOZUtlbR4Wgg2BRMSFEKIKYRmTzPbyraRV5OHT/tOW1daTBqLRy/m2pRrz+phP6/Pi0EZzvkNyq1uL01ODyaDwmQ0YDIoyupb+ehABRsOVLA1vwaXt2O7o4LN/OzqAZdmQK2UMgJ/AL4PlADblFJvaa3bv7rvAWCn1vpGpdSQQPnJ3dWm7jJ37lxWr17dIaBevXo1jz/+eJfW79u3b6fBdFctX76cefPmtQXU77777jnX1RNuvfVWXnnlFQBuueUWXnzxRe68884ebpUQQgjRs6ocVWwv387Wsq1sOb6FwobCDssjLZGEmENocbfQ7G7G5XNhMphIt6fzs/SfMTphNIOjB1PtqKa0uZSypjKa3E1clXQVAyIGnFObjAZjl8tWNLbyry+Psau4npI6B8dqHVQ1OU9b/rK4UOaPT2HcgBjiw63YQ4OICgnCbLzw30PYnaH+aOCI1voogFJqNTATaB9QDwP+D4DW+oBSKkUpFa+1Lu/Gdp13s2fPZsmSJTidTiwWCwUFBZSWlpKTk0NTUxMzZ86ktrYWt9vNI488wsyZMzusX1BQwLRp09i7dy8Oh4MFCxaQl5fH0KFD2173DXDnnXeybds2HA4Hs2fPZtmyZfz+97+ntLSUSZMmYbfb2bBhAykpKeTm5mK323nqqadYsWIFAAsXLuS+++6joKCAqVOnkpOTw+eff05iYiJvvvkmNputQ7vWrl3LI488gsvlIiYmhpUrVxIfH09TUxN33303ubm5KKV48MEHuemmm1i3bh0PPPAAXq8Xu93O+vXru3T8rr/++rbvo0ePpqSk5FxPhRBCCHFRcXqd1Dvr2z6H6w6zq3IXuyp2UdLk//8w2BRMdkI2N19+M8Ptw4kPjic2OBaL0dKhLrfXjUaf8iBfWFAYKREpXWqP2+s7bQCrtaa4xkFtiwuPT+Px+vD6NGaTgVCLiVCLCVuQkdyCGl7PLeHjQ5V4fZqUmGCSooKZPCSOxCgbkcFmPF6N16dx+3yEW81cfXks/aKDO93uxaA7A+pEoLjddAkw5qQyu4BZwCal1GggGUgCzj2gfm8xHN9zzqt3KmEETH3stItjYmIYPXo069atY+bMmaxevZo5c+aglMJqtfLGG28QHh5OVVUVY8eOZcaMGae9VfLcc88RHBzM7t272b17N1lZWW3LHn30UaKjo/F6vUyePJndu3dzzz338NRTT7Fhwwbs9o63bLZv385LL73Eli1b0FozZswYrr76aqKiojh8+DCrVq3iz3/+Mz/84Q9Zs2YN8+bN67B+Tk4OX3zxBUopXnzxRX73u9/x5JNP8vDDDxMREcGePf7jXFtbS2VlJbfffjsbN24kNTWVmpqasz7Mbrebl19+maeffvqs1xVCCCEuJFprqlurKWwopKihyP9nYxHVjmoaXA00OBuod9Xj9J7aY2u32cmMzWTO4DmMjB/JsJhhXXpYz2zsWrqkx+ujoLqFQ+WNHCpvpLC6hcLqZopqWqhqcjEgNoQrB8Zw5UA7o5KjOHi80Z+ScbCCwuqWLm0jPtzCogkDuCkricviQru0zsWsOwPqziLGk99z/hjwtFJqJ7AH+BLwnFKRUouARQD9+/c/z808P06kfZwIqE/0CmuteeCBB9i4cSMGg4Fjx45RXl5OQkLnb/zZuHEj99xzDwDp6emkp6e3LXvttdd44YUX8Hg8lJWVkZeX12H5yTZt2sSNN95ISEgIALNmzeLTTz9lxowZpKamkpmZCcCoUaMoKCg4Zf2SkhLmzJlDWVkZLpeL1NRUAD788ENWr17dVi4qKoq1a9cyYcKEtjLR0dFdPXRt/vM//5MJEyZw1VVXnfW6QgghRE9p9bSyq3IXO8p3kF+fT2FjIYUNhTS7m9vKmAwmkkKTsNvsJIcnE2GJIDwovO3PcEs44UHhJIcn0zek71nnKB+rc/Dy5kK2F9YQajERGRxEhM2MLchIg8NNncNNg8NNZaOTo5XNbXnKSkHfCBv9o4P53tB44sIs7C1t4I0dx3jli6K2+i0mA1cOjOGnOakkRdkwGgyYDQqDQeHy+Gh2emhyemh2ekixh5BzmR3TRZCqcb50Z0BdAvRrN50ElLYvoLVuABYAKP+Vkx/4cFK5F4AXALKzs08Oyjs6Q09yd7rhhhu4//772bFjBw6Ho61neeXKlVRWVrJ9+3bMZjMpKSm0tp55HMbO/hLl5+fzxBNPsG3bNqKiopg/f/431nPysDftWSxf3yYyGo0dUktOuPvuu7n//vuZMWMGH3/8MUuXLm2r9+Q2djbvbCxbtozKykqef/75c65DCCGEOB8cHgcbijawp2qPf4SM0D70CelDtDWaBmcD1a3V1LTWUNZURm55LjsrduLyuTAoA31C+pASnkLGwAySw5P9n7Bk+oT2wWQ4u7CrqLqFkroWvD6Nx6vx+DQmgyIi2EykzUxkcBBHKpp46bN83t93HICR/aOoanJxpLKJuhY3rW4v4VYzETYzEcFmEiNtXH15LIMTwrg8PozL4kKxmk/Ni3Z7few5Vs+OwloGxIYwboAdW1DX86cvNd0ZUG8DBimlUoFjwI+AW9oXUEpFAi1aaxewENgYCLIvOqGhoUycOJHbbruNuXPnts2vr68nLi4Os9nMhg0bKCwsPEMtMGHCBFauXMmkSZPYu3cvu3fvBqChoYGQkBAiIiIoLy/nvffeY+LEiQCEhYXR2Nh4SsrHhAkTmD9/PosXL0ZrzRtvvMHLL7/c5X2qr68nMTERgL/+9a9t86dMmcKzzz7L8uXLAX/Kx7hx47jrrrvIz89vS/noai/1iy++yPvvv8/69esxGC6dX7NCCCG+ex6fh8O1/jzl6tZqYm2BN/YFx1LvrOedo+/wYeGHtHhaCDIE4fK5zljfkOgh/GjIjxjTZwxZcVmEBp1beoPT46W+xc3O4jo2Hq7k08NVXU6viAw2s2jCQP5jXDKJkbZvXqELzEYDWf2jyOofdV7q6+26LaDWWnuUUj8H3sc/bN4KrfU+pdQdgeV/AoYCf1NKefE/rPjT7mrPd2Hu3LnMmjWrQzrErbfeyvTp08nOziYzM5MhQ4acsY4777yTBQsWkJ6eTmZmJqNHjwYgIyODkSNHkpaWxoABAxg/fnzbOosWLWLq1Kn06dOHDRs2tM3Pyspi/vz5bXUsXLiQkSNHdpre0ZmlS5dy8803k5iYyNixY8nP9988WLJkCXfddRfDhw/HaDTy4IMPMmvWLF544QVmzZqFz+cjLi6ODz744JQ6169fT1JSUtv066+/zh133EFycjLjxo0D/Kkp//3f/92lNgohhBCn4/A4OFp/lCO1RzhSd4R91fvYW7UXh+fUu7InhJpDuS71OqYNmMao+FG0uFvaRsioaa0hwhJBtDWaGGsMMbaYU16x7fNpqpqdlNc7Kat3cLyhlbL6Vo4HPg63F4/P19bj3Oz0UNfixuH2ttURHGTkyoEx3DY+lUHxoQQZDRgNCrPRgMvro97hpr7FTV2LizCrmetH9JHe4x6mzpQWcCHKzs7Wubm5Hebt37+foUOH9lCLxHdFzrMQQlzatNbUtNb485QbCnF6nZgMJkwGE0ZlpLa1lqLGIoobiyluLKa0qRQdeHwryBDEoKhBZMRmkBmXSUZsBnHBcVQ7qql0+N/ap1CM6zsOq8naYbsVDa3sKKrlUHkTCtrGT9ZoKhudbQFzWX0rFY2tuL0nv2lQERdmJSHCSnCQEXMgQDYZFKEWExE2M5HB/rSMy+LCGJUcRZBJ7theCJRS27XWp38ZSMCFO0K2EEIIIXoFrTUOj+OU3twTyw7XHSb3eC4OjwOv9uLxeXD73DS6GttGxKhz1lHcWEyD68yZoRGWCPqF9iPdns6MgTMYFDWIyyIvo19Yvw45zK1uLxUNLpyeUIxuG1Ek0uz08v7eaqqbXFQ3OymqcfBlUS0ltafv0baYDPSJ8AfLo1OjSYiw+qfDrfSJsJEQYSUmJAiD4dyfMxIXPgmohRBCCNEtXF4X7xe8z6v7X2Vv9V76hPQhLSaNNHsaiaGJ5B7PZeOxjRxvPn7KukZlJDQolIgg/ygYkZZI0mLSSI1IJTUileTwZILNwXh9/gDc4/MQYfWXbc/h8vJlcS1vbcvnUHljl14wAmAyKOLDrWT2i2T+lSlkJUeR1jcco1L+MZh9Gq01oRbTt3ooX/QOElALIYQQ4pxprXF6nbR4WtrGVq531rOnag+vH3yd6tZqUsJTWJS+iOKGYvZW7+XDog8BsJlsjOszjjvS72B84ngiLZEYDUaMyohBnTnloabZxVfHmyisdraNodzqLsdk+DqdorCmhd0ldbi9GqUgJSaEpCgbQwIvGIkNs2AzG7GYDFjNRoKDjMSEWrCHBhFuNZ+2V9kk6criJBJQCyGEEOIUXp+XQ7WH2FGxg+3l2znWdAynx0mrtxWX10WrtxWnx3nGUTCuSryKW4feyri+4zoEyPXOekoJwyB2AAAgAElEQVQaSxgUNeiUt/p1psXl4auKZnYW17KjqI4dRbUdRsAwKOgbaSPUYsLjC7yBz+sjLszCT3MGMDo1ilHJ0UTYuvbiEyHOlgTUQgghxCXK6/Oyo2IHHxV9RFlzGU6v0//xODlaf5QmdxMAfUP6khqZis1ow2KyYDVasRgtbd+DjEEEm4IJt4QTERRBhCWC+OB44kPiO2yv1e1tG9t4f5kLp2cPbq/G6/Ph1RBkNGAxG7CajJiNimN1Dr6qaKK0/uv3LthDLWT1j2Tu6P4MTggjOdr/Wmt5iE/0JAmohRBCiF7K7XVzoOYA+6r34fF52gJgozKSW57L+qL11LTWYDFa6BfWzx8kGy2EBvmHjhsVP4pRcaPoE9rnjNtxery4vf584pPVt7h5fXsxa3eXkVda3zYCRmKkjRCL0f/GPaNCKYXb46PV48Xp9uH0+OgbaWXMgBgGxoYwIDaUEYkRJEXZJGdZXHAkoD4PqqurmTx5MgDHjx/HaDQSGxsLwNatWwkK+ubbWQsWLGDx4sUMHjz4tGX+8Ic/EBkZya233np+Gi6EEKLXqGutI78hn4L6Ao7UHWFP1R7yqvNwejt/+M5msnF10tV8P/n75CTmdDoCR2dqml18kHecL4vqKKxuoaimhdJ6/ygYw/tGcOXAGMYNjCHcZmb11iLe2lVKq9tHRlIEC68aQFb/KEb2j8QeavmGLQlx8ZBxqM+zpUuXEhoayi9+8YsO87X2Pw0sbwI8dxfSeRZCiJ5S5ahiX9U+8uvzyW/IJ7/eH0TXOmvbypgNZobGDCUz1j/ecnpsOjaTjVZPa1taR7+wfm3jLWvtzzt2eX24PL6v//T4cHs1Lo+PXSV1rNt7nM1Hq/H6NNEhQaTEBJMcE0JyTDBawxdHq/myqA6X1wf4X1Byw8hE5o1JZljf8E73R4gLmYxDfQE4cuQIN9xwAzk5OWzZsoW3336bZcuWsWPHDhwOB3PmzGl7I2BOTg7PPvssw4cPx263c8cdd/Dee+8RHBzMm2++SVxcHEuWLMFut3PfffeRk5NDTk4OH330EfX19bz00ktceeWVNDc38+Mf/5gjR44wbNgwDh8+zIsvvkhmZmaHtj344IO8++67OBwOcnJyeO6551BKcejQIe644w6qq6sxGo3885//JCUlhd/85jesWrUKg8HAtGnTePTRR3vikAohxCXD6/NS3lJOUWMRR+uOsqtyF7sqd3Gs6VhbmWhrNKkRqVzT/5q24eRSw1MxEU1MsO2UvOJgUxibv6rmg7wGimp2U93s9I+53ORqC4LPJNUews8mDOD6EX1I6xveaeqFw+Ult7CGykYn3xsWT7hVHgQUvV+vC6h/u/W3HKg5cF7rHBI9hF+O/uU5rZuXl8dLL73En/70JwAee+wxoqOj8Xg8TJo0idmzZzNs2LAO69TX13P11Vfz2GOPcf/997NixQoWL158St1aa7Zu3cpbb73FQw89xLp163jmmWdISEhgzZo17Nq1i6ysrE7bde+997Js2TK01txyyy2sW7eOqVOnMnfuXJYuXcr06dNpbW3F5/Oxdu1a3nvvPbZu3YrNZqOmpuacjoUQQoivtbhbOFx3mAPVByhuLG4bbq7B1UC1o5qSphI8Pk9b+ThbHBlxGcwdMpf02HQGRAwgwhLRttzn03xyqJLF647y2ZHdBJkMDO0TTkZSBIMTwthZVMe/88qpd7gJDjJyWVwosaEWhiSEExMaRGiQiSCTAbPRQJDJQFDgzxPT/aODuTw+9Bvzl21BRq4aFNttx02IC1GvC6gvNAMHDuSKK65om161ahV/+ctf8Hg8lJaWkpeXd0pAbbPZmDp1KgCjRo3i008/7bTuWbNmtZUpKCgAYNOmTfzyl/7gPyMjg7S0tE7XXb9+PY8//jitra1UVVUxatQoxo4dS1VVFdOnTwfAavXfCvzwww+57bbbsNlsAERHR5/LoRBCiEvOwZqDvHP0HfIb8vH6vHi1F6/PS4WjgsKGQnza3ytsNVqJsES0jZIxKGoQk/pPol9YP/qH9Sc5PJn44HiaXV5WflHIQ58cJzr4EIlRNvpG2jAZFKu3FXOkoomEcCv3fW8QzU4Pu0vqWbO9hGaXlzCLie8Pi+e64QlMuDwWq1kGUxbifOl1AfW59iR3l5CQkLbvhw8f5umnn2br1q1ERkYyb948WltbT1mn/UOMRqMRj8dzShkAi8VySpmu5MS3tLTw85//nB07dpCYmMiSJUva2tFZz4PWWp6oFkKILipvLued/Hd4++jbHK49jEmZSI1MxWwwYzKY/NPhqUxNmcrg6MEMjR5KQkjCGf+drW9x8/v1R1jxWT71DjfpSREcq3OwtaCGxlb/v/9pfcNZPieTH6T3wWz8OtXD69OU1LaQEGHFIm8kEaJb9LqA+kLW0NBAWFgY4eHhlJWV8f7773Pddded123k5OTw2muvcdVVV7Fnzx7y8vJOKeNwODAYDNjtdhobG1mzZg233norUVFR2O121q5d2yHlY8qUKfz2t79lzpw5bSkf0ksthBAd5VXn8be8v/F+/vt4tIeM2AyWjFnClJQpRFmjAKhobGXN9mPklTWwp8zHl16Nx1cClGANjL9sMRtQSlHvcNPgcFPX4uZoZRPNLi/fGxrHXZMuY2T/qLbtNrS6qW9xn3Y4OaNBkRwTcsp8IcT5IwH1dygrK4thw4YxfPhwBgwYwPjx48/7Nu6++25+/OMfk56eTlZWFsOHDyciIqJDmZiYGH7yk58wfPhwkpOTGTNmTNuylStX8rOf/Yxf//rXBAUFsWbNGqZNm8auXbvIzs7GbDYzffp0Hn744fPediGEuFC1uFvILc9lc+lmcstzMSkTfUL70DekL7HBsXxS8gnbjm8jxBzC3KFz+dHgH9E/vD/wdW7zqi1FfLi/HI9P0z86GIsp8Ipsoz8IbnX7aHV7cXp8aK0Jt5mJsJmxhwYxIimR/xibzNA+p46UEW41y4N/QvQwGTavl/F4PHg8HqxWK4cPH2bKlCkcPnwYk+ni/+0k51kI8V3x+rzsq97H5tLNbC7bzK7KXXh8HoIMFvoFD8Xjg3pXBY2eKry4CDPFMjN1Dj/LmkukNRytNbtL6lm7q5S3d5dxvKGV6JAgZo9KYs4V/RgYG9rTuyiE6AIZNu8S1dTUxOTJk/F4PGitef7553tFMC2EEOeD2+emuKGYhJCEU15kUtxQzOayzWwu3cyW41todDUCkGi7jFTzVCorkykujadat+8N1hjNLTS6rTy3x8jf1n1OelIkx+ocFNW0YDYqrr48jiXThvL9YfGSwyxELyWRVi8TGRnJ9u3be7oZQghxwXB5XXxR9gUfFH7AhuIN1DvrAYgPjic1IpUYWww7K3a2je8cGRSLXWUT1JJK4bG+HPCEEhxkZHRqNP8xNYZxA+z0jbRiNRvb0jaKaxzsKKple2EtO4vrSI4J5ufXXMa1wxKICJZ0DCF6OwmohRBCXPRcXheVjkoqWio43nycooYiihuLKWos4kD1IRzeZkzYsHnSMTWkEmJrwUsVB53lOPUhrDoZa/1YqqpSaHTZKTcZGdU/ipsmxXDlZTGkJ0V2GDnjZP1jgukfE8wNIxO/w70WQlwoJKAWQghx0aloqeDj4o/5qPgj9lXto85Zd0qZyCA7jpZIGhvT8DQNI9gzhH59oknuF0xVk4tjNQ6O1TlocnroF21jdFIkGZkRpCdFktkvUsZpFkJ0mQTUQgghLghNrib2VO3hePNxGlwNbW8NdHldbWU0mq/qvmJP1R4ArMRh9YwgIyKRYfFJXJGUQhBRvPJpEx/sqqVPhJWHvjeIKwfaOx1WTmuN0+OT4FkI8a1IQC2EEKJHNLub+bj4Y3LLc9lVuYsjtUfQfD3ylEEZCA8Kx2K04PVp3F4fbq/G6w7DWX0tnsZh2Kz9iA638cVXDWzyaV5UTRhUM2ajgfu/fzm3XzUAW9Dpg2WllATTQohvTQLq82DixIn86le/4tprr22bt3z5cg4dOsQf//jH064XGhpKU1MTpaWl3HPPPfzjH//otO4nnniC7OzTj9iyfPlyFi1aRHCw/4n166+/nldffZXIyMhvsVdCCHH+tXpa+aBgA28deZftFZ/j1i7MyobNNwBL83XU1vTB67JjMYQQbgnFZrNQ3eSiutnfS202KkYkRnDNqDgmDo4jrW84SilaXB6+LKpja34NLS4PC68aQHy4tYf3VghxqZCA+jyYO3cuq1ev7hBQr169mscff7xL6/ft27fTYLqrli9fzrx589oC6nffffec6xJCiHPR4GpgZ8VO9lTtoba1lkZXI03uJhpdjdQ7G6luqaPJ3YSXVgB8nlA8DaPwNGRg9qQQbw9nYGwIAy4PxWIyUO9wU9fioq7FzYjESDL6+XObh/YJ63ToueAgE+MvszP+Mvt3vetCCCEB9fkwe/ZslixZgtPpxGKxUFBQQGlpKTk5OTQ1NTFz5kxqa2txu9088sgjzJw5s8P6BQUFTJs2jb179+JwOFiwYAF5eXkMHToUh8PRVu7OO+9k27ZtOBwOZs+ezbJly/j9739PaWkpkyZNwm63s2HDBlJSUsjNzcVut/PUU0+xYsUKABYuXMh9991HQUEBU6dOJScnh88//5zExETefPNNbDZbh3atXbuWRx55BJfLRUxMDCtXriQ+Pp6mpibuvvtucnNzUUrx4IMPctNNN7Fu3ToeeOABvF4vdrud9evXd//BF0L0CK01e6r28F7+e+SW53Kw5iAajUEZCDWHYSIYfFZanUE0tljweZMxq2CSo2JIt48kOyGb5OhQ+kbaiA+zYjCc+spsIYS4WPS6gPr4b36Dc/+B81qnZegQEh544LTLY2JiGD16NOvWrWPmzJmsXr2aOXPm+HPzrFbeeOMNwsPDqaqqYuzYscyYMeOUB2NOeO655wgODmb37t3s3r2brKystmWPPvoo0dHReL1eJk+ezO7du7nnnnt46qmn2LBhA3Z7x56Z7du389JLL7Flyxa01owZM4arr76aqKgoDh8+zKpVq/jzn//MD3/4Q9asWcO8efM6rJ+Tk8MXX3yBUooXX3yR3/3udzz55JM8/PDDREREsGeP/6Gg2tpaKisruf3229m4cSOpqanU1NSc6+EWQlzA6p31vHP0HV7Je43ipq9Q2kyQdwDBzqngHEBLYyLHWvz/vpmNiiEJ4dx4mZ1rhsSR1T8S0xmGnhNCiItVrwuoe8qJtI8TAfWJXmGtNQ888AAbN27EYDBw7NgxysvLSUhI6LSejRs3cs899wCQnp5Oenp627LXXnuNF154AY/HQ1lZGXl5eR2Wn2zTpk3ceOONhISEADBr1iw+/fRTZsyYQWpqKpmZmQCMGjWKgoKCU9YvKSlhzpw5lJWV4XK5SE1NBeDDDz9k9erVbeWioqJYu3YtEyZMaCsTHR3d1UMnhLjA1Dvr+ahoA/869B4Ha/fhQ6O1/2FBp68FjRevIxFP/Y0MDp1AXEgE1ggjFrOB4CAjg+PDSE+KZMhp0jOEEKK36XUB9Zl6krvTDTfcwP3338+OHTtwOBxtPcsrV66ksrKS7du3YzabSUlJobW19Yx1ddZ7nZ+fzxNPPMG2bduIiopi/vz531jPif8AO2OxWNq+G43GDqklJ9x9993cf//9zJgxg48//pilS5e21dvZ0FOn63UXQly4fD5NncPN/soCNpZ8yudln1DYshuNF58rEk/LIPB9/aY/o7KQGXU1N2SPYfKQOGJCLWeoXQghLg29LqDuKaGhoUycOJHbbruNuXPnts2vr68nLi4Os9nMhg0bKCwsPGM9EyZMYOXKlUyaNIm9e/eye/duABoaGggJCSEiIoLy8nLee+89Jk6cCEBYWBiNjY2npHxMmDCB+fPns3jxYrTWvPHGG7z88std3qf6+noSE/1v/frrX//aNn/KlCk8++yzLF++HPCnfIwbN4677rqL/Pz8tpQP6aUW4sLg8fpoaPVQ1+KisKaFXSUVfFl2hMM1hdR4D2MIPoDRWg6AzxWDxTmRkfYJXJd2BVnJUYRZTFhM/h5oi8kgP56FEOIkElCfR3PnzmXWrFkd0iFuvfVWpk+fTnZ2NpmZmQwZMuSMddx5550sWLCA9PR0MjMzGT16NAAZGRmMHDmStLQ0BgwYwPjx49vWWbRoEVOnTqVPnz5s2LChbX5WVhbz589vq2PhwoWMHDmy0/SOzixdupSbb76ZxMRExo4dS35+PgBLlizhrrvuYvjw4RiNRh588EFmzZrFCy+8wKxZs/D5fMTFxfHBBx90aTtCiPNrZ9kh/rLjXbaUf47DW4PXF1igNMrowGBq9E9HQBBGkmxpDI+aydj48WT1vZzkmBAJmoUQ4iyoM6UFXIiys7N1bm5uh3n79+9n6NChPdQi8V2R8yzE12qbXby9p4zaZhdGA9R7CjnY/An76jbjVP7eZpM3gThrf4KMBsxGA2aTgShrOGmxqQyKTqFfWD9SIlIIMYf08N4IIcSFSSm1XWt9+peBBEgPtRBCXCS01mw+Ws3qrcWs23sMt6Eac/heTOFfYrSWo7URk3MQ2fYfsGDk9UwYMLinmyyEEJcECaiFEOICUtvsYkdJKWu/WsvOmo24fR6014LXa8HpMuHUdZgsNVgvr8WCF4B0ewbXpvyUiX2/R1KEXcZ0FkKI75gE1EII0YN8Ps0X+RWs2XWQT47uoyloM6awPSiDB5x9MatQDMYmlKkGk9lJvC2GYbFZpET0p19YP66Iv4J+4f16ejeEEOKS1msCahm2rXe72HL9hThZbWst7+a/S0VLBVWOKgrrjlNQd5x6Vw3a0IxSGmIhRAUzJu4H3DL0Zsb3T5d/14QQ4iLQKwJqq9VKdXU1MTEx8p9PL6S1prq6GqvV2tNNEeIbnRjXubrJSavbR1y4hfym3fx606+ocFRgVGYMvjBaW0PAG0af0FTS4pO4ol8y/cL7MDphNMHm4J7eDSGEEGehVwTUSUlJlJSUUFlZ2dNNEd3EarWSlJTU080QogO3z01+7XHW7T/IJ18d4WhVCw11iXjdoYESPoLsHxFkX4/Ba8dY9b+oq42jX3QwPxuTzM3Z/YgOCerRfRBCCPHt9YqA2mw2t73yWgghupNP+3jr0Hpe2L2C4uZ9oNqlI9kh2A5R5kQGho2g1l3GV427GGC9ioGGH6NDrcy4oS9XD4qVBweFEKIX6RUBtRBCdKcmp4cvi6pYue9NttSswWMsw+eOxOb8HukJqeSkDmBM/1TcPhdfVnzJjvIdbK/4DI/Pw0NXPsQNl90g6WhCCNGLSUAthBD4c/U1Gq9Pc6i8kZ3FtWwq3MfuqlxqfHkYg4+ijE4sKpGJ9vu4PWsWQxMiTwmUM+MyWTB8AT7tw+PzEGSUlA4hhOjtJKAWQlzSKporeXb7K6wrfAOHr/bUAiEQbezDiJjvc+Pga5mSenWXepsNyiDBtBBCXCIkoBZC9Dpaa0pqHdhDLdiCjKcsr2t28c+8z3j98GuUuDaD8uJtGoLdPJ6ECCsJEVb6RNgYGtufsX3GkhCS0AN7IYQQ4mIhAbUQoteoanLyry+P8XpuCQfLGzEoGBAbSlrfcC6LDSGv+hBfVm+g0ZSLIagG7bPQ13gNNw+aw+z0kUTJiBtCCCHOgQTUQoiLSk2zi+c/+Yq1u0qxmo1EBJuJtJnx+DSbv6rG49Ok9Xcx86rjVLaWUdZUzicNVXzYWIUhqAZsBvrb0rmm30IWZM7AHhzR07skhBDiIicBtRDiotDQ6ubFT/NZsSmfZpeHyUPisZgNNDjcVDQ10sQRMjOP0qj2UtRSRFEVmJQJe4idtNg4YiwjGdd3DFNSphBji+np3RFCCNGLdGtArZS6DngaMAIvaq0fO2l5BPAK0D/Qlie01i91Z5uEEBeff+4oYdnaPOodbq4fkcCdE/tR7Mzly4ovqazcxbHaQ3i1lyZnEFckXMGPh9/CVYlXkRSWhEEZerr5QggherluC6iVUkbgD8D3gRJgm1LqLa11XrtidwF5WuvpSqlY4KBSaqXW2tVd7RJCXFhqml2s319Oi8vLjVmJhFvNbcucHi8Prc1j5ZYiRqdEc9+1ffmy/m3u/PRe6p31BJuCGRE7gp+O+CmZsZmMih8lr+0WQgjxnevOHurRwBGt9VEApdRqYCbQPqDWQJjyj0EVCtQAnm5skxDiAlBc08L7+47z77xycgtq8AVeNvj4+we5dUx/bstJxe31ccfKzeRVFvCDsWb6JOzk3s/+Rau3lUn9JvGTtJ+QGZuJ0XDqKB5CCCHEd6k7A+pEoLjddAkw5qQyzwJvAaVAGDBHa+3rxjYJIbqZx+tjw8FKmp0eBsaGkhobQqjFRH2Lm3f2lPGvL4+xtaAGgCEJYfz8mkFMGRYPwHMfH+EvuRt4+cjvMIYcgrAGQsJgYz2YGk1MGzCNBWkLGBA5oCd3UQghhOigOwPqzt58oE+avhbYCVwDDAQ+UEp9qrVu6FCRUouARQD9+/fvhqYKIb6tJqeH17YVs+KzfEpqHR2WxYdbqG124/L6GBgbwn3f70/mAC+x4Wa8vlbc+ij7qvZRGroGW/IRjFgJ86Uz7fKRZCRcRr+wfiSHJxMaFNpDeyeEEEKcXncG1CVAv3bTSfh7ottbADymtdbAEaVUPjAE2Nq+kNb6BeAFgOzs7JODciFEDymrd7C9sJat+TW88eUxGls9ZCdHseQHwxgQG8LRyia+qmzmq8omIm1mRgxoYGfdOl4teI+/lDhOqW+EfQRLxy3lutTrCDGH9MAeCSGEEGevOwPqbcAgpVQqcAz4EXDLSWWKgMnAp0qpeGAwcLQb2ySE+BbcXh8bD1Xy1q5StubXUFbfCoDFZOB7Q+NZeFUqI/tHtZW/PD4Mt8/NW0feYtWBVbyeexCbycZ1KdcxPnE8QYYgTAYTRoOR+OB4BkYO7KldE0IIIc5ZtwXUWmuPUurnwPv4h81bobXep5S6I7D8T8DDwP9VSu3BnyLyS611VXe1SQhxbnYV17FmRwlv7y6jptlFVLCZnEGxZPWPJKt/FEP7hBNk6jg8ndfn5d38d/njzj9S0lTCkOgh/NfY/+L61OsldUMIIUSv0q3jUGut3wXePWnen9p9LwWmdGcbhBDnRmvNpiNVPPvREbbk12AxGfj+sHhuHJnIhMtjMRv9AXSjq5HPSj+hprUGr/bi8Xlo9bby5pE3OVp/lCHRQ/jD5D9wVeJV+Af0EUIIIXoXeVOiEKKNz6c53tDKruI6/rTxKLuK64gPt/Bf04Zxc3YS4VYzWmvyqvPYeGwjm0s3s7tyN17tPaWugREDeWriU0zuP1leriKEEKJXk4BaiEuY16f5977j/PPLYxytbKK41oHL4x+5sl+0jd/cOIKbRiViMRmpbKlkxd61bT3PCkVaTBo/HfFTxvUZR1JYkj8fWhkxGoyEmcOkR1oIIcQlQQJqIS5BTU4Pr+f6h7grrnGQGGljRGIE3xsaT79oGyZrGRHh9ZS3fMST20vJr89n2/FteLWXkXEjWXblMq7pdw2R1sie3hUhhBCix0lALUQv1+r2kltQy1eVTW2f3cX1NDr9Q9z9+vqhfH9YAi2eJtZ+tZa/H/w7R+u/HmwnzBxG39C+LBi+gJkDZ5ISkdJzOyOEEEJcgCSgFqKXqne4eeWLQl76rICqJicAYRYTA+JCuX5EH340uh8j+0eRX5/PI1se4p2j7+DwOBgeM5xlVy4jLSaNvqF9CQsK6+E9EUIIIS5sElAL0YtorTla1cxr24pZuaWIJqeHqwbZWTB+BMMTI4gNtbTlNR+sOcgvPnmUfxf8myBjENenXs+cwXNIs6f18F4IIYQQFxcJqIW4yLk8PjYfrWbDgQo+OlBBUU0L/4+9+46Oqur6OP69U9J7QhJSSOgt9C4iRfABEURBEVDpKlixYUHxVdRHLBR7RcXCI6AiRZoiTULvIBBIQnqvM8nU+/5xaZEkgKQA7s9aLlcyd+aemUzIb/bd5xydAre0DuO+GxoQE+575ti80jxi02JZfmI565PX42n0ZFzMOO5pcQ+B7oG1+CyEEEKIq5cEaiGuUkWlNr7bepIvNseTUWjBzajjuoZBTLyhAX2bB1PX1x2ALHMW3//1PX+m/smhnEOoqPi7+jO57WRGNhuJr6vvBc4khBBCiMpIoBbiKmJ3OEnIMbF4VwrfxCZSVGqne6NAZgxpRY/GQbgZ9WWO35Wxi8f/eJx8Sz5t6rRhctvJdA/rTovAFuh1+grOIoQQQohLIYFaiCuYxe7g590p/Hk8h6MZxRzPLMbqcKJTYEBMXe7v2YDWEecvXaeqKt//9T1vbn+TcO9wPrvpMxr5N6qFZyCEEEJc+yRQC3EFKrE6+G7bST7dcIL0wlLq+rrRLNSbG5oE0TTEm07RAUQGeJR732JrMa9tfY2lJ5bSK6IXr/Z4FR8Xnxp+BkIIIcS/hwRqIa4QBWYbu5Py2Bafy/+2J5FjstKlfgBv3tGa6xsFVbrrYGpxKuuT17M+aT3b0rdhd9qZ3HYy97e+X7b9FkIIIaqZBGohalFSrpnPN8WzKS6buMxiAHQK3NCkDg/2bkSn6IBy7+dUnRzIPsAfSX+wPnk9R/OOAhDtE83IZiPpX78/MUExNfY8hBBCiH8zCdRC1IKkXDMf/BHHwh3J6BSF7o0CGdI2jPZR/rSJ8MPTtfxfzfiCeL7/63tWJ6wmpzQHvaKnbXBbnujwBD0je1Lft34NPxMhhBBCSKAWogblFFt4a/VRFu5IQqcojOxSj0m9Gp5Z4q48TtXJ5pTNfPvXt2xO2YxRZ6R3ZG961+tNj/AesuydEEJcK3KOg70U6jQH3QXa9QrTYNM7YCmCWz+48PHnKs6ChI0QvwEyD0OrYdB+NBhcLm/8F5KXCBvfgoxD4BcJflHgHwVBTSGiI8GJ040AACAASURBVBhcz79PQQqc3AIxQ6GS1sfaJoFaiBrgdKos3JnE67/+RXGpnRGd6zG5d/lBOqEggW3p24jLjyMuP45jecfIt+QT5B7Eg20fZFiTYQS5B9XCsxBCCFEtrGb443XY8h6oTvAIgvo9oP4NEN5BC57up1Z0Ks6CzbNh+2dgtwAqRF0H7e+t/BwOG+z5FrZ9ChkHtO+5+oBPGKx4EjbPhZ5PQ5sR2hhSdmiBO2UXNBuoPf6FAq3VBL/PgOIMiD41/oAGUJSuBemdX4Gig4hOkLoHDi8Fp127r8ENIrto9/GLgpN/aufPidNur9sGghr/45e4uimqqtb2GC5Jx44d1R07dtT2MIS4aEczinj+p/1sT8ijU7Q/r97WiiYh3uUeuzZxLVM3TMXqtOJp9KSRXyMa+TWic2hn+kX1w6g31vDohRDiGmUp1oKebwQY3WpvHPEb4JdHIC9eC62RXSD+VPW4KPXscW6+4FcPck6AvQRa36UF4J8nQfZReGgHeJQz78bpgP2LtMCeFw9h7aH5IKjfUwupOj0c/00Lwqm7wTsMSvK0cyg67evCZC0gD5oDgQ3Lfx7ZcfC/uyHrL/AK1kI1gE8EmLO14Nz+XujxJPiGnx1bYSqk7z9bMT8d9l28Ibr72WAeEnNpVfgqoijKTlVVO17wOAnUQlS9uMxiVh9KZ82hDHafzMfPw8hzA5ozrEMEOl35n/AX/LWA17a+Rqs6rfjv9f8lwjui0pU9hBBXKNupIFLe5evqoKpgLQbX8j+oX5TSAjB6gr6KLlyrqtaK4FZDS3ZaiiH2Q+016DAajBW00akqJG2FXfPh4E9gM2nf9wrVWg9OtyCc/r+7PxQka60K+YlQlKZVbyuiM0LjftB8MLiUv7TpGU4nrJwK2z4B/2gYNBca9Cw71pzjkHnw7PnzEsEzCK5/HOo00Y5L3w8f3wAdx8PAt8qeI3kH/DwZso9AaGvoMw0a31R+pVlV4cgKrYocUF8LsVHXgasv7P4aVr8ADiv0fg46jC37sz20BH5+EPRGGPY5NOitVZbj12sfDtx84fop2uNeiCkbClMguGXVvR8vgwRqIWqY3eFk8a5kPtlwguNZ2j/SrSN86dc8hJFd6hHoVf4fV1VVeXf3u3y6/1N6RfRiZs+ZuBsq7qkWQlyhSgtgy/uw5QMtULcaBu3vgbptL6730+nUwlP8BijOhJjbtQpiefIStONOrNf+b8qCfv8H3R+9yLEWQuJm7b6nq4KBjWHwuxDV7aKfcoXWvQYb3oK2I7Uqql+9s7c57BC3Rmsl6DgOfOqW/xi2UtC7XLgqGbcWlk6BgpPa1951occTZ3uC7VatfeHEejj4o1bNdfGClrdBvW5aeDs3sBYmlx+ajZ7aWHWVhLzSAi10u/poP/9290B4+/KPXfsSbJoFne+Hvi9dOIBXZsVTWgvIfeuhbmvte0dXww/3glcduGkGNBt0eRXewjStNeSvZdrX7v6nWlH84cQ6rTXljq+03uhriARqIWqIw6mybF8qs9YcJSHHTOsIX+7oEEHfFiGVTja0OW3sSN/BwqMLWZO4hqGNhzKt6zQMlf1jLa4tDpt2yfM0RVf9k4LOdXKrdpk1+nrtMvA/Obeq1uxEoRN/aBWsVsOq5vGyjmohq04zrSJX3iXzC7EUw7aPtR7U0nytOml016p29lIIaQVN+2tVyNOVT73r2QCXn6BVGeM3Qkmu9piKHlSHVlVsf69W8UvddaritwHyT4VHrxBt3KUFcGw1DJgJXe6vfLx/LYefJoGl4GzfamRn2Pc/7XE7TYAbp//z6nJ2HHzQVWsNyD2hvUc6jIE2d2nn3vMdFKdrx3rWgWHztH7h0+wW2Pg2bHxHe2/5RpxfOfaLBg9/WD8T9n4PQU20DwNOu9a6cHIL+NaDoEZwMhZsZkDRnmu7u7Uw7epV/vgdNq0qnZ+otT74Rmo/O4/AC7/XVVX7oLLr67M//9Z3wS2zygbmnV/B0ke01+WW2Zf/O1SSD+920F7zsSu11+SXhyE0BkYt0lowqoKqau/B1D1n378FydDoRu1DQU1dlalBEqiFqGbJeWZWHkjnf9uTOJZZTLNQb564qSl9mweX26qhqirppnR2Z+7mj+Q/2JS8iSJbEW56Nya0msB9re+TFo9/k7+Ww6Jx2h/cc3kElhMeorQ/6L6RVRe4c+Phk55aEAOt+hbVDWKGQdsRFd+vtFALK/EbtD+s+UlakGkx+Pxj7VbYtwCa3fLPgurf/bUCfrhHC03XT9FCX0W/M5Zi7ZL+7vmQcVAbQ/t7IKq7dp/ceFj/hhYiz61GhrbSjnE7Z/UcnQFaD9d+Fn+X+Rd8OwwKkqBJf+1y+Omqckk+HFgEu7+BtL2Vtwr4Rmq9og16av938dD6Xnd9pYXt09z8Tk1W66kF6aAm2vNx2GDhGK16eMts6Dj2/HM47LBuhlYVrdsW+r2sBczT/cOWYi2Mbv1Im6jWZoTWX3uai5dWafY/9X509z//HKqqvR5J27SeXqdNq1Tvnq/93BSd1nLQ7h7tcRaO1UJ33+lw3SOQvF0Lgll/aas6+Eae88EjEcw5Zc+nM0D3x+CGp84+D1XVeoLXv6m9v+vfoP0X3b38MVeXknxtkuGGtyC4BQyfrwXe47/DN8OgQS8Y+UPVtTXs/gaWPKi9D4+u1B5/+DeX1wp0EVRVxZGfjy05BVtKMraUFIxhYXj16YPO9eoP2BKohagGJoud+bGJrNifxr5kLYjEhPvwQM+G3BxT97z+aIfTwaKji9iavpW9mXvJLMkEwN/Vn16Rvegd2ZuuYV2lxePfpjAVPrxOm6wTc/vZ7zvtZytjeYlaSDs9Ax60quVNM6Db5PIf9/g6rWIZ0qLy89tK4PN+WjXy3l+088RvgLjfIPc43P2jVnH6u4M/w+IJWkjSu2pVzdJ8LVQO/0arwp5mKdbC7/HftTB6+ycX//qU59haWDBCm5gUGqNVANuO0iZJnZ6sq6paINv1tRamrcVaG0N4BziyArW0kJz4SPKPGYi8LhVXf0WrxnZ76NRrcKr6m7Tt/A86br5w+6fQ5D9nv3dyK3x3p1aVu+OrClslzNu3U7J3j/ZaleRBSR6u4QF49Ti1moFfvcov96fu0VoWwjtqgf/ckHsuu1WbFHZsNQz5QGu3OK04CxaP055fhzHQ/42KJ+IlbYdlj52dHFaR0NYwYsHZCWagfVBcMBL+83rZ92luPCRsgkZ9y7Z4WIpgyUNw6Gft8dL3g084DJqt9SL/naVIe9+eroxGX3/h93tti1t76vfGAb2e1SYH+kbCuJWX3WOeOXs2+d8vwBAaijE8HJeCrRjsqVrbR8xQ0BnQubvh3r4Dro0boZxq+VCdTszbtpG/aDGmzZtxbdwYj65d8OzSBfdWrXBabVo4Tk7Gnp2D9419MASdv7qUPTubkxPvw3L48Hm36Xx98R00CL9hQzEEB2Petg1TbCzm2K1g0BN0//343Hwziv7s+1lVVUoPHMCWkor3f266IopMEqiFqGJWu5OxX25jc1wObSL9GBATyoCYUKICPcs93ua08dzG51iZsJJwr3Ba12lN2zptaRPchmb+zdBX9EdRXNucTvjmdm1i1P0btUvSFR57agb86YB98Eftj/MdX0HLIWWP3TUffnlIC7oD36p8Ca0lD2rVrJE/lA2ItlL46HqcpaVYB3yDLTMXRa/H84YbUAqS4cPuENgA+v6fFqaN7loF8OtbtSrwiAVaEC/Ogu/ugLR9Wo9q4ia47w8Ia/fPXrMT67XgGtQYRi8FNz8cv76CdeVcbD4dsIXehO1gLNYTh7HllaLodATcFIPv2KdQoruCouDITif1kfso3nUMFBX3qACiFixE8Quv9NTm7dvJePVljI6T+IWl4XnHIyh9ntVC68IxWvi750etYvs3jvx8Mv77BgU//1zuY/vfew8hTz6J4nL2qoOjuJisWbMpWvc7xuAQjBERGMPDMYaGlAnSeh9vvPv1QzH8rbppK4Xvh2uv2alqrK0YSjNteITY0d/2NrQbVelztmVkkvbCNKzxCRgjwnGJiMAYHoFnx9a4h3to78Xc41pLhquP9vzrNNU+qL3fWatk37/x4iuvqqpNKPztZe0qwo0vVntV9bwhWK2U7N9Pyf79WqU1ORlbihYmqSQnKS4uePXpjd/QYbjFtKw4AOafhB9Ga207XqEw8TetleX0+VWV4vXryfnkUxS9Ht+ht+Pzn/+gc6+42FKwdBmpTz2F53XdUFxcsaUkY01KQi21lHu8PiAAjy6dcYmIpHDlSmxJSeh8fPC64QasJ05Qeviw9lwNBrDby9zXGBZG5Gef4drg7KRCe14eJ++9F2tyCkGTJ+ESHX3qvRJO6YED5C9aTNGaNag225n76Dw98ejYEVt6OpYjR3Bp1JA6Dz+CR+dOFC5dSv6ixViOajv/Bj8zlcAxYyp8/jVFArUQVcjpVJnywx6W7Enl7TvaMLRDRKXHWx1Wnlr/FL8n/c6UDlMYFzOuhkYqLkpJvvaHLbgleIfU7Lm3fACrnq34snxlbCXw1WBI3wejl0FkJ+37+xbCjxNPrRCgaBOE2t6tBeu/r3aw62vtkvoNT2kz/k8/dFoa2R9+RNGqX3EUFJW5i/d//kPd5kfQ5+6DBzZq68oCzpISzDt24hpZB+Ov47RZ/bfMhg1vQmEK9pveo7TQG7fND2KIaq6F4UupOJ2+dP+/e8AvCkuPd8n64jtMf/6Js7CwzKE6oxOjvysuUfWxFoLlyFFcGjSgzsMPYYysR8pjj2HLyCBk6lR0np6kPfssIS9MI2BU+eFSVVVy531J5ttvYwwJwWky4SgowOhhx7e1Lx4eSRjrN8F430IU39Dz7lu0ciXpM17FUVBA4PjxBI4dA4ZTlXSng6z33iPv6/m4t2tH+OxZGENCKF6/nrSX/g97ejpeffrgLC7Wgl16Ojgc543Rq++NhL/1Fjq3spVmtbSYovefxLT/BKZjOdhyzAC4Noom6pvv0fv5VfiSm7ZtI+XxJ3CaTHj17IktLRVbcgqOnBzQ6wl+fAoB48ZpwTFtH3w7DGeJhayS2zDFbsWgpuPSoT/G5p1wqR+NR/v2lZ6vDKezWpZFU61Win5fR/5PP2JPS9c+oERE4BIRjtNqxbx1G+adO1FLSgAt9BkjIjBGRGAIroOiVDwme24uxevWoVosuDZtit/QoXj16Y1LRDl/I+wWbUWPRn0huPmZb5u2bCFr9hxK9u7FGBEBeh22xJPovLzwGTiQgLtH4dq47PrLpUePkjD8LtxatiBq3jwUo/beUlUVp8lc5lhHfj7m7dsxx8Ziio3FnpGBR9eu+A0dine/vmfeP478fEzbt1O6dy86X18tHEdE4CwpIeWxKeB0EvnxR7i3aYOjoIDEMWOxnjhB5Mcf4dm1a/mvT14ehctX4DSb8ezSGbeWLVEMBlSnk6JVq8ia+y7W+Pgzx7vFxOA3bCimzX9StHYt4XPn4NOvnCsVNUgCtRBV6LUVh/lkwwme7t+Uyb0qqSgCpfZSpvwxhU0pm3im8zOMal55NUhUgbS92oz57o9qfYPlSdisrSxwYj2k7dH6WQ3u0Hmi1oPpGVj948w4CJ/0hoZ9YMT3/2wikikbPrtRa6mYsFZ77ovGQb1uWHvNQXWCS8IClI1vau0BvZ5FVfWY9h6hYNVGHAm78Wgahuekd3GLaYUjN5fsTz4lf8ECVMBnQH9c7UdxyY/FOGI25sRiMt9+BxcvKxEvPojroCk4rVbyf1hI9scf4cjKBsAlKhIPn3Tc3TOxFHthKqmPJT5ZG7Neh3ddE75jH8Zr+KOoTicle/Zg3vgH5rWLcZhtWlXTxRMMrhhDg/EMBw924+o4is3QkKzc6ylcuRadhwc+AwfiEh2tVU8dyRhtx9F3vQeCmwHa5eyitWvJmjsXa9xxAAwhIYTPnoVHu3aoqkrShImU7N5Ng2VLMYaFlXmJHcXFpD37HEVr1uDdrx91X38NxWik+LffyJ/3Lqb98cCpn51ejzE0FJ3X2QluqsWCNSEBt5YtqfvqDNyaNSv3R1m4YgWp015A5+6OR/v2FK1Zg0ujhtR95RU82p2t5qs2G/a8PDjnz3XRqpVkvP5f3Nu3J/KD99H7aj3fluPHSZv2AiW7d6Pz9sajUyc8u3ZB5+ND+gsv4tqsGfW++By9d9kKsKqq5H7xBZnvzMKlXj0i5s4pE+IcBQWkTX+JopUr8ep7I2Gvv47e25vilYtJf2EatiLwDLViV/yxmfRnP/AoCm7Nm+PRtSvubduU7anVGzCGhmAMDy9TiXVaLNhSUrGlpZaplKpOJ/bMrDPVY1taOu5t2xI4cQKGgPN79C1xceQvWkzBkiU48vIwhITg1rw5tpQUrCkpqOZTHzQaN8KjS1c8u3bBvX179P7+l9Rq4CgspHD5cvIXLab04EEAjOHheHTtgkeHjqhWC7bkZKzJKdhSU1EtZyvIamkp1sREDKGhBE2ahN/tt4HBgHn7dgoWL6Zw1WpUu53A8eMJmjwJnasrjuJiEobdgaO4mPo/LsYYfPETDlVVRTWb0XmWf2W1ItaEBE5OmIg9J4ew114l54t5WP76i4gP3serR48LP0BF47HbKVy+HMuJeHxuHoBb06aA9mE9cfQYLEePEjX/a9xbtfrH57hcEqiFqCKfbTzBjOWHGd0tipcGV3xJz+qwsjtzNx/v+5gd6Tt4sduLDGtSRSsRiIplHIIvB2qrIyg6rerafcrZSldRurbU0+Gl2gSmiE44QrqS8WsCvlEleJpXg9EDuk6C6x4uOxntIlmOHSN/8Y84zWZCpz2PokPryS3OPOcoFZY/CaZMmLRFW8rqn8o+Bp/11S63F6WihrUnTzecjHfmgN2OITgYjxb18LRtxpZvJT/eHbvZgN7Fid5ThzVPexidtzeqzYZqs+F3+20EPfAAxvBwbeLhB920y+63vofp9UGkbA3C6TQSMGoUBcuWY09Lw6NTJwLGjMZ6MglzbCzm7dtwmktQXFxw79Aezy5dcYuJwbRpAwX/+xpHCegDA3CazKilpaCAW4ANg7dRq74DGNyw5DixFWvtDXofDxwmC4rRSMA9dxMwbhwG/4ubWKY6HBSuWIF51y7qPPxwmdBlTU7hxODBeHTsQOTHH6MoinbZfd0fZL7xBtbkZIKfeIKAsWPO+523nYzDmpSJNTXl1ESsFJylJWWO8ezUCf9Ro85vyfgbS1wcyY88ijUpiaD77iPw/vvQuVzcxNPCX38l9empuERHE/HhBxQuXUr2Bx+i8/Ag+Nln8L3lljLnL1q3juSHH8G9VSvqffYpOk9PVLud4k2byPt6PqY//9SuRrz6Knqv8wOXqqrkff01GW++hTE8DPdWrSlctgyX6HrU7VKEh1sSPLgVfMJwFBZiOXoU09atmGO3UrJnT5lL/3+nDwrCEFwHR3YO9szMCo8DwGDAGBaGISiIkj17UNzcCLj3HgLHjgW9gcJfV1CwaDEle/eC0Yh37974DRuKZ/fuZ/p1VVXFkaf9IpQXxv8py4kTmLZswRy7FdO2bTgLtLk2itGIMSwMY3g4ikfZq0aenbvgN/zOcifw2fPyyJz5JgU//YRL/frUnfEKuV9+RdHvvxP15Tw8OnWqsrFfiD0ri5P33a/1SxsMRMydg3efPtV3vuxsEobfhdNiof7/Fmj/NtUCCdRCXIbsYgub47JZfySLH3enMCAmlPdGtkf/t0mHZpuZn+J+YlPKJnZm7KTEXoKLzoWXrnuJQQ0H1dLoryG2Eq3XOH6DFow7jdcmmJ2WfQzmDdCC8qiF2uoFBxZD05u1SVmHl8Lqadql1l7PQKeJ2PJNJE2YiOXYMQzBwTScPwfdttnaJLagplo/qG8EOfO+xBDgj++tt2q9zFve11oaontA/R449T4ULF9OwcIfKNl3AHQKOFV8m0DddmkoSgX/tp7qW1ZVFXtm1qlLyuV/SLOlpmIICirTY3tGwib4egjOgJakxbWhcOUavHr3xqtnT8zbtmKK3YojNxcUBc/2MfgN6InXdR3QhbXAXmw9E3RQFALHjcUlOrrs4x9drfVBG9zA3R/bsCWkPPsyJbt24damNcGPPopHt25lxq7abFgTEzFGRp4XDtT9Syiacx9Ftm7oIxvjWbgcj4BC9KO/017T3BPapMCEzeAVgjX0JszHczFv24o+IJDAcWMx1LmMDyHlyP36azJee52wN2eiDwgga85cSvftw1ivHmGvzqixsOIsLcVRUIgx5NKXNjPFxpL84EM4S0rA6cTn5gGEPP88hsDyr7gUrlpNyuOP49G+Pe7t21Pw00/YMzPRBwQQ9MAD+N9z9wWrs+adO0l5bAr2vDwCJ4wnaNIkdAad1k/vef7ENdAqjpa442VWOlFtNmypaVrvb3Iy9sxMDIFBZ/u2w8JQ/vY+MgQFYQgJOROMLSfiyX7vPQpXrNA+IDocqGYzLo0a4jd0GL63Dq7SwHwpVIcDa3w8Oi8vDMHBZyYE/hPFmzaTPn06tpQUAIKfeorA8TXfSugoLiZz5pt49epZrWH6NEtcHAkjRmIMDSHqu+/Ou7JSEyRQC3GJ8s1W/rc9iaX7UjmQol2u9PMw0r9lKC8Nbombsewkwg3JG5gRO4M0UxrRPtFcF3Yd14VdR6fQTngYL2OBfqFt+LDmRW21BYdFW93C6AHWImg6EPo8r/UGz7tZWwVjzApt1zBV1XoUVz2nbQhhM0PU9TB4LgQ2xHLiBCcnTMBZUEjQ5ElkvvkWgRPGE/zkk1poX3A3uHhSFD2V5OffACB85gx88udrfckuXmAtxmFRSNwYjiXbiYuPDb8GZnwbOclLiSJ7SyF1BrclaOQgbcWNc/svveui1mmKafOfZM2ZQ+n+/bg2boTv0KH43norBn9/HAUFFCxbpk3OOXwYxd0djw4d8OzaBY/OndEHnA1KjoQDpL42B2tCInUee4zACePPzuJXVazHj2v9oHUr2DjjQhZPhP0/wD0/QcM+qDYblrg4XJs1u/TZ96qq/byyj2gfUAyu2vq4pzehqAWqw0HCyJGUHjgIDgeGsLrUmTwZ31tvPdOTejUoPXSIzDlz8B9+F959el/w+IJly0l96intw1aP67Ve2l69yv/gVgFHQQGOoqLye4VrQemRI+R8/jk6V1f8hg7FrU2bK2KFiKrkNJnI/vBDVJud4GemXnPPryKm2FgyXn2NiA8/xCWi5qvUEqiFuEhH0ov48s8EftqdTKnNSft6fvRpFswNTerQMsz3vKp0dkk2b2x7g5UJK2no25Dp102nXfA/XL3gWuGwaysQVMU/8FaTtimE3QKt7tDW2z29HFnsR/Dnu2Ap1JabUvQwZvn5y2ad3Aprp0PrO6H9GNDpKNmzh6T7HwCjkXqffIxbixakPvc8BUuX0mDJz7g2aADpB7B9MpT4xQqGyCh0Li6UHokjqm8B7qP/C21H4YiL5eSjz2I5mU344CC8+t6E0qAnRHRCNbiSOnUqhb8sJeytt/C9ZeCZIamqSsmOHWTOmUPJjp0YwuriN+Q2ijdvonTvPjAa8WjThpJ9+1CtVlxbNMd34EBsaemYt8ZiORZX7sulDwgg/J23K5wUdFnsFm3r46palixlJ3zaBwIaVrgyRk2zHD9O2vTp+AwYgN8dd1x0u8XVrvTwYfT+/hhDQy98sBC1THU4yiyvV5MkUAtxAUm5Zl5edog1hzJwNei4rV04o6+LpnnditcFXZu4lul/TqfEXsJ9re9jfMx4jPqrp5JVLbLj4KtB2nazg+aemRhWGdPWbdhSU/G9dfD5l0FXPgex72tV5+ju59/ZnKttlnB0NQx5v+KtmU+xZ2eT/ckn2lqtdetS7/PPcInUtsa15+RwfMDNuMfEEPn5ZwAkjbkH886d1B+Qj95oJ2FtEE69D9ELF2Pw9+fkhImU7N9PxNy55VYDnVYrSePGU7J3L+GzZ+E0mTBticW0NRZ7ahqGOnUInPQAfsOGnQlvpUePUrB4McWbN2v9lMOG4taibIi1Z2Vh3rkLp/mcGfw6Ba/u3au8FaJaJW3XNreoio1ehBCimkmgFqICpTYHn2w4wfvr4tDrFB7o2ZC7u0YR4FlxZcrutDN391zmHZhHTGAMr/Z4lQa+DWpw1Feo3HjtMr7DovVGWk3acmzdH6twR7/iDRtIevAhsNlwb9+eujNe0arDAMk7tA1HOoyFW965rKE58vPJ+fxzcr/5FtVqxfe2IQRPmXJeb2nuN9+SMWMG4XPmYM/MJOPVVwmZ+jgByhJw88XS+kkSxk7SejcDAjDv2kX4O+/g85+bKj13wl0jsCYkAKD39cWjSxc8u3fH99bB5y1zJoQQ4sokgVqIcqw/msX0JQdIyDEzsFVdnh/YnDC/yncpzCnJYeqGqWxN38qdTe5kauepuOj/HZeFATi2BpY/rk0c6/n02cv0+UlamLYWaW0XnsGwcqo2KTC4BQx857yd40xbtpD0wCRcIkPx/083Mr9ZgWouIejByQSOvgdlXl9tYtPk2DI7iFmTkzH9+SeGOnXOrI1a2YYH5l27SHpgEs6iInxuuYU6D04+f9LdKardTvzQYThyc3EUFuLRtQuRH31Upj/RtG0bJ8dPALudsDffLNPKURFbaipF69bh0b49rk2bXtaEJCGEELVDArUQ58gptvDyskMs2ZNKgzqevDw4husblz8b/Vz7svbx+B+Pk2/JZ1rXaQxpNOSC97lmOB2w/g1YPxP8o6AwDVSHtgNfu7th0Xit/WL0LxDW9uz9jqyEZVOgKBUa9dMmEIa1w7xjBycnTMDFB+p1T8DgqmL3aU36oUiKNu3GJcQHv7pJ+E6Zg6HLHQDYMjLI/vBD8hctPn/nrvBwQl+aft4aqCX79nFy7DgMdeoQPncObk2aXPCpmnfuJHHU3Dc4LwAAIABJREFU3egDAmjwy5Jyt9g1xcai2myXteaqEEKIq4sEaiHQJoIt3pXCjOWHMFnsTO7ViMm9G+JqqHxyg6qqLDy6kP9u+y/BHsHM6jWL5oHNK73PNcWcC4snaLvUtRkJA9+G0nzY+Dbs/AqcNnDxhnt/hohy/p2xmrTVNjbPgZI8TG69SP4uDoObhaibHRj6TdF6aNe/AfknKbLEkLMxg5JsIxgMePfujSE4mPyFC1FVFf87huE/ahTOoiJtc4TkZApXrMBy7BhBkycT9OBkFJ2O0sOHSRw9Br2vL1HfzMcYcvG7IOb//DOuDRvW6gYCQgghriwSqMW/Xk6xhcd/2Mv6o1l0jPLn9dtb0TjkwmtYltpLmRE7gyXHl9A9vDtv9HgDX9dL3+zjquGwa+v/5p6AvATIT9SWqyvJgwEzocOYsqt35CXC9k+h+a1nt74u72ELCij4aRH5336BJSkXo7eTqGkjMfZ/XNswBMBuhd3zYcNb4LBiGbCA/OW/azubFRTgO2QIQZMnl7tUkrOkhPSX/o+CJUvw7NGDoPsmkvzwIyge7kTPn19rmwAIIYS4dkigFv9q2xNyefi73eSarUwb2Jy7u0Sh0114Sbf4gnimbpjK4dzDPNDmAR5o/QB6Xe0s1VNdSg4cJOezz/AbehuePuko6/8Ludr2zBjcwK+etqxZz6chvP1591edTizH4rDGx5/ZkMGWkoJaes52uk4Hpfv2n1n+zW/IYHwHDkAfWEHF2G7RNnFx99Pub7XiNJvR+/lV+lxUVSX/h4VkzJiBarNhCA4mav7XuERF/bMXRwghhDiHBGrxr+R0qnyy8QRvrjpCpL87749qT8uwC1eXU4pT+GjvR/xy/Bc8jZ68fv3r9IzsWQMjrlnW5BQShg/HkZMDgHsdC8E3BOIx8nmI7AJeIThLS7GlZ2iV61OcVisle/dijt2Keds2HPn5Z27T+fpiDA9D71F2q2LXJk3KXf6tOpTsP0DuvC8IeuihsyuGCCGEEJdJArX41zFZ7Dy6YA9rD2cwsFVd/ju0Fd5ula8RnV2SzUd7P2LxscXo0DG82XDGxYwjyP3CExavWE4nFKUB5/xum7JxHPqNhJfmYy8oJapPFuaSCHL2u2LPK8K9bVtU1YktOeVM2C6PIawunl264tGlM25Nm2KMiKiVrWCFEEKImnCxgdpQE4MRorqlF5Qy7svtHMkoYvqgFoy5LvqC27IWWAoYu3IsyUXJDG0ylImtJhLiefGT2GqaardTeugQpthYnAUFGE8tH2cMj0Dn5oo1KRnbjuXYti4BUzY+UWZcfRzafZ2Qsj4Qa64r9SZ2wa3/MNyaDMDPZifv+wUULFmC3t8P7z69MYZHYAyrW3YbYkWHW/NmGCMj/zXb3QohhBAXSyrU4qp3MLWA8V/uoNhi572R7ejVNPiC97E6rExcPZH92fv59KZP6RDSoQZGeulUVaVw+QoKly/HvG0rTpO2S56iU1GdlQRbRQFVxb1pBH692mA+mkbBul3Ufe01/G6/rYZGL4QQQlzdpEIt/hV+/yuDh77bja+7kYUPdKt02/DTnKqTaZunsStzFzNvmHnFhmlrcjLpL07H9OefGP0M+IQW4Blqw6NLV/Sh0dgPbcSWlIitWI/ToWAMCcSl3yQMPcfiKCqmYMkSChb/SNrHywG07a4lTAshhBBVTirU4qrkcKrM/e0Yc38/RsswHz4f3YkQn4vbznnurrl8uv9THm3/KBNaTajmkV461eEgd/58smbPQXFaCW6Vi1/HIJT290LbkeB7znJwhWkQv0GrSLe8DfRle8ZVVaVk506siYn43n67tGsIIYQQl0Aq1OKalVVk4bH/7WZzXA63tw9nxpAYPFwu/FbOMGWw8OhCPt3/KUMbD2V8zPgaGO3FU1UV06ZNZM2aTemhQ3hF2AntVIxx4NPQ7aHzwjIAPnWhzfAKH1NRFDw6dsSj4wX/LRBCCCHEPySBWlxVtp7I4eHvd1NQYmPm0Nbc0TGi0qprfmk+qxJW8WvCr+zK2IWKSr+ofkzrOu2Kqtaatm4ja84cSnbtwuhrIKxbLj49OqDc+i4ENqzt4QkhhBCiEtUaqBVF6Q/MAfTAZ6qq/vdvtz8FjDpnLM2BOqqq5lbnuMTVR1VV5scm8n9LD1EvwIOvxnW+YL/01rStPLX+KfIseTT0bciDbR+kf/3+RPnU3qYfqtVKycGDWBMSsSUnY0tOxhIXR+nBgxi8DYR2zMcvxgul73+h/WjQ6WptrEIIIYS4ONUWqBVF0QPvA/2AZGC7oii/qKp66PQxqqq+Cbx56vhBwBQJ0+LvbA4n0385yHdbT9K3eTCzhretdH1pVVX56uBXzNo1i/o+9fmw34e0CGhRaxXp0iNHMG3ciCl2K+adO1FLSrQbFDD4umH0guB2BfjHuKDrORU6TwQXz8ofVAghhBBXjOqsUHcG4lRVPQGgKMoC4FbgUAXHjwC+r8bxiKtQrsnKpG92sjU+l8m9GvLkTU0r3ULcbDPz4p8vsiphFf2i+vFK91fwNNZOOFXtdrJmzybns88BcKnjjl90MR4BBbj52TB4ONB5+IJ/PWj2CHSdBG4X3tVRCCGEEFeW6gzU4UDSOV8nA13KO1BRFA+gP/BQNY5HXGUyCku546MtpBeWMnt4W4a0C6/0+MTCRB5b9xgnCk4wpcMUxrYcW2tVaXtWFikPT8K85yB+jUzUaVmEIaQu1O8D0T0gpCX4R4G7f62MTwghhBBVpzoDdXlJpqI1+gYBmytq91AU5T7gPoB69epVzejEFc1idzDpm51kF1tYcF9X2terPHiuT1rPsxufRafT8WHfD7ku7LoaGik4LRaw2898XbJlDanPTsdhthDWvRTfUfdDm7sgoIG2vJ0QQgghrinVGaiTgchzvo4AUis49i4qafdQVfUT4BPQ1qGuqgGKK9f/LT3ErpP5fDCqfaVh2qk6+Xjvx3yw9wOaBzRnVu9ZhHtVXsm+LEUZcPAnCGkBEZ0p/O0PUp+eimq1ljnM6O0g+ukBuA17ETwDq288QgghhKh11RmotwONFUWpD6SgheaRfz9IURRfoCdwdzWORVxFvt92ku+2nmRSr4bc3KpuhccVWgt5buNzrE9ez+CGg3mh6wu4GS5uc5d/pCgDvrwZcuIAsBR7kLrKH9dQb3zqloC1GFy8UaI64jv5ZfR1Zbk7IYQQ4t+g2gK1qqp2RVEeAlahLZv3haqqBxVFeeDU7R+dOvQ2YLWqqqbqGou4euw6mcf0JQfp0TiIJ29qWuFxx/KOMeWPKaQUpfBcl+e4q+ld1dsvbcqGrwdrOxPevRhHUTHJj76KzmAiomMCxjZ9od3d0Kgf6GV5dyGEEOLfpFr/8ququgJY8bfvffS3r78EvqzOcYirQ06xhUnf7CTE15V3R7RDX8FqHisTVvLi5hfxNHryRf8vaBfcrnoHZs6F+UMgLwFGLUSN7kHalMexZpupN+9LjJ07SW+0EEII8S8mpTRxxZi19ijZxVZ+eag7fh4u593uVJ3M3jWbeQfm0bZOW97u9TbBHsHVO6iSfPhmKGQdgRHfQ/0byPvqK4pWriT4ySfw7NK5es8vhBBCiCueBGpxRYjLLOL7bUmM6lKPlmHnr8WsqiozYmew8OhC7mxyJ890fgajvuLNXarEkV9h2eNgysRx88eYTjgxf/cyeT8sxKvvjQSMH1+95xdCCCHEVUECtbgivLbiLzyMeh69sfF5t6mqymtbX2Ph0YWMjxnPo+0frZZ+aWtyMgU//kjJ7p1aRbo4A1y8sLt0wvL9i6CqKO7uePfuRd3XXqu1Na6FEEIIcWWRQC1q3ea4bH7/K5NnBjQj0Mu1zG2qqvLG9jdYcGQBY1qOqfIwrVqtFK5eQ/7iRZi3xIKi4OrvQFEc4BMB3nUxeHnhffNgPLt2xT0mBsXl/HYUIYQQQvx7SaAWtcrhVJmx/DDhfu6MuS66zG2qqvLWjrf49vC33N38bh7v8HiVV4VTp02j8JelGMPDCOrfHD/jHxibtIVbP4DgZlV6LiGEEEJcmyRQi1q1eFcyh9MKmTuiHW5G/Znvm2wmXtj8AmsS1zCi2Qie7vR0lYdpa1IShcuW4z/8dkLq7UBJ+g063w83zQCDVKGFEEIIcXEkUItaY7baeXv1EdpG+jGo9dkNXBIKEnhs3WPEF8bzeIfHGdNyTLX0K+d+8TnoFAKVH1DSi2Ho59BqWJWfRwghhBDXNgnUolaUWB3cP38nmUUW3h/Z/kxgXndyHc9teg6DzsDH/T6ma92uVX/yzL+wb/qM/B+W4VuvBGNQMNz5CwQ3r/pzCSGEEOKaJ4Fa1Diz1c74L3cQG5/DzKGt6RgdAMA3h77hje1v0CKwBbN6zSLMK6xqT5y4Bda9CgkbyTvoi+rwJPCJV6DPKNDpL3x/IYQQQohySKAWNarYYmfcl9vZkZDLO3e24bZ2Eaiqyvt73ufjfR/Tt15fXu/xOm4Gt6o7acouLUjHrQXPYJw9XyRv1SI8e7bGte+9VXceIYQQQvwrSaAWNaao1MaYedvZk5TP7LvaMbhNGE7VyetbX2fBkQUMaTSE6d2mY9BV0duyKB1+nQqHfgZ3f+j3MnSaSMFPy3Dk5RM4TjZmEUIIIcTlk0AtaoTTqfLogj3sScrn3RHtuLlVXWxOG9M2TWNF/ApGtxjNEx2fqJrJh6oKu+fD6mlgK4Wez0C3B8HNB9XpJHfePNxatsSjc6fLP5cQQggh/vUkUIsa8c6ao/z+Vyav3NqSm1tpK3rM3jmbFfEreKTdI0xoNaFqwnTuCVj6KMRvgKjuMGguBDU6c3Px779jTUgg/J23ZadDIYQQQlQJCdSi2q3Yn8Z76+IY3jGSu7tGAfBH0h98fehrhjcdzsTWE6vmRKYc+PwmsFvgllnQfgzodKhOJ+Zt28hfuIiiNWswRkTgfdNNVXNOIYQQQvzrSaAW1epwWiFP/LCX9vX8eHlISxRFIa04jec3PU+zgGY81empqjvZymegJB/u+wOnf2NKtm3HFLuFwmXLsSUno/PxwW/YMALGjEYxyFtfCCGEEFVDUoWoNnkmK/fN34GPu4GP7u6Aq0GPzWnj6Q1PY3faeavnW7jqXavmZMfW4Ny9kHxlEEXPvE3Jrl2oVivodHh06kSdRx/Fu19fdG5VuHqIEEIIIQQSqEU1ev3Xw2QUWPjf/V0J9tGC7Hu732NP1h5m3jCTKJ+oKjmPsyiH/NcfJXtPGA7zDlybNsV/xAg8unbBo2NH9N7eVXIeIYQQQojySKAW1SIus4hFO5MZ170+7er5A7AmcQ1fHPiCYU2GMaD+gCo5T8GSJWS+/hL2fBWP1s2oM3UaHh06VMljCyGEEEJcDAnUolq8teooHi4GJvfWVtj4LfE3nl7/NK3rtGZqp6lVco6czz8n8823cAu0EjapJx6PfC4rdwghhBCixkmgFlVub1I+Kw+m81jfxgR4urA2cS1PrX+KFkEt+Ljvx1WyC2Lu/PlkvvkWPg0Vwvq4ozwwFyRMCyGEEKIWSKAWVW7mqr8I8HRhQo8GZ8J0y6CWfNT3I7xcvC7vwVWVvPdnkPHed3hHlBB2ow/KHZ+B62U+rhBCCCHEPySBWlSpzXHZbI7L4YVbWrA7a8tlh2nLiXichQXaF8WZlCx4hYy12XjVg/BXXkDpeC/ojVX8LIQQQgghLp4EalFlVFVl5sq/CPN1Y0AbL0asmEYDvwb/KEyrqkr2Bx+Q/e57593m2bIe4V8vRPH0qaqhCyGEEEL8YxKoRZVZdTCdvckFvHF7K2bueJUiaxGf3fTZpYdph4P0V14hf8H/8Bk0CN/6Fti7AHwjUfo8i0efQSguLtX0LIQQQgghLo0EalElbA4nM1ceoWEdT1z9d/Pb4d+Y0mEKjf0bX9LjOC0WUp98iqI1awi8dwR16u1HiVsNN90Jg2aDi2c1PQMhhBBCiH9GArWoEgu2J3Ei28TM4fWYuf052gW3Y3SL0Zf0GI7CQpIffAjz9u2E3NOPAN3nEF8CN78FnSbIKh5CCCGEuCJJoBaXrdhiZ87ao3SK9mdt1rvYVTszus9Ar9Nf9GPYMjJJmjgRy4kThN0aiq/tK6jbDQa/C0GXVuUWQgghhKhJutoegLj6fbL+ONnFVrq0OcKWtC080eEJ6vnUu+j7W07EkzhiBLakRCJ75uPrewwGvg1jVkiYFkIIIcQVTyrU4rJkFJby6cZ4bmzlwqL4j+latyt3Nr3zou9fsncvSfc/ADio1ysT9yYNYOQC8I2ovkELIYQQQlQhqVCLyzJrzVHsTgcE/ojD6eDFbi9e1PbfqqqSv2gRiWPGonM3Et0zFfdGkXDvzxKmhRBCCHFVkQq1+MeOZhTxw44kbuyYTmzGJp7s+CSR3pEXvJ/15EnSXpyOOTYWj9bNCG+6A0NwCNz7C3gG1cDIhRBCCCGqjgRq8Y+9ueoInm5Wjtrm0yKwBaOaj6r0eNXhIPfLr8h6910Ug57QMX3wU5ehuPtrYdo7pIZGLoQQQghRdSRQi3/kQEoBaw5l0KHDeo6X5PNRtw8x6Cp/O+XN/4bMN9/Eq5k/oc2PYyw9BuEdYdgX4BteQyMXQgghhKhaEqjFPzL3t2N4+yVw1Pwb42LG0TyweaXHq04nuZ+9i3uQhYiuqShtxkC7eyA0pmYGLIQQQghRTSRQi0t2KLWQ1YfSiW69GjfXcCa1mXTB+5jmTcOWbaLOqC4oT8wDo1sNjFQIIYQQovrJKh/iks397Rjevgnk2E4wsdVE3AwXCMdHfiX/++/RexjwfuoLCdNCCCGEuKZIoBaX5HBaISsPphMWHUuQexC3NLyl8juk7sH29XiKUtzwvXMEOjf3mhmoEEIIIUQNkUAtLsnc347h5Z1BqnUvo5qPwlXvWvHBufHw3XDyE/1ABf+Rd9fcQIUQQgghaogEanHR/kov5NcD6TRstB1Po2fFOyI6nbD1E/joelRLCfmJAXh2745LvYvfjlwIIYQQ4mohgVpctPd+j8PLs5BEyxbuaHIHPi4+5x+UdQTm9Ydfn4LIzhTHzMSelYPfXcNrfsBCCCGEEDVAArW4KEm5ZlbsT6Np090oilL+Ji7bPoWProfsozDkI7j7R/KW/Y4hOBjv3r1rftBCCCGEEDVAls0TF+WrPxNQ9GYSresYWH8goZ6hZ29UVfjt/2DTLGj8H7j1PfAKxpqUhGnTJoImT0YxyFtNCCGEENcmSTnigopKbSzYnkSLpvtIcJQypuWYszc6bLD0UdjzLXQYCwPfBp0egLwFC0Cnw+/OO2pn4EIIIYQQNUACtbigH3YkU2I4SJK6lH5R/Wjk30i7wWqChWPg2Gro9Sz0nAqKAoDTbCZ/0WK8+/bFGBJSe4MXQgghhKhm1dpDrShKf0VRjiiKEqcoyjMVHNNLUZQ9iqIcVBRlfXWOR1w6u8PJp9vW4Rn5LU38m/DydS+fvfHnSRC3Fm6ZBb2eOROmAQqWLsNZUEDAPbJUnhBCCCGubdVWoVYURQ+8D/QDkoHtiqL8oqrqoXOO8QM+APqrqnpSUZTg6hqP+Gfm79xOse/HBLkF8UHfD/By8dJuSPwTDi2B3s9Dx3Fl7qOqKnnfzMe1RXPcO3SohVELIYQQQtSc6qxQdwbiVFU9oaqqFVgA3Pq3Y0YCP6qqehJAVdXMahyPuETppnTmHnwKnaLnqwGfEeQepN2gqrB6GniHQbeHzrufeetWLMfiCLj7HpRzqtZCCCGEENei6gzU4UDSOV8nn/reuZoA/oqi/KEoyk5FUe4t74EURblPUZQdiqLsyMrKqqbhinOpqsqk1Y9hU83cHf0KUb6RZ288+COk7IQ+08DF47z75n49H72/Pz4Db67BEQshhBBC1I7qDNTllSbVv31tADoAA4H/AC8oitLkvDup6ieqqnZUVbVjnTp1qn6k4jwHcw4SV3gQJe9mHuze8+wNdgusfQlCWkGbu867nzUpieJ16/Abfic610q2JRdCCCGEuEZU5yofycA5ZU0igNRyjslWVdUEmBRF2QC0AY5W47jERfh873eoTheGNxuCp+s5b5Ntn0D+SbjnZ+z5BThyc3Ft1OjMzXnffgd6Pf4jRtTCqIUQQgghal51Vqi3A40VRamvKIoLcBfwy9+OWQL0UBTFoCiKB9AFOFyNYxIXochaxLrk1ahFbZnUs+XZG8y5sOFNaNQXu38bEobfxYlbBhF/+1Dyvv8eW0YG+YsX43PTTbJUnhBCCCH+NaotUKuqagceAlahheQfVFU9qCjKA4qiPHDqmMPASmAfsA34TFXVA9U1JnFx5u//EQcW+kUOIcjrVNuG06FNRLQU4bzhBZIffAh7ZiZBDz6I6nSS/n8vE9erN86iIvxlqTwhhBBC/Isoqvr3tuYrW8eOHdUdO3bU9jCuWaqq0v2bgRSYnay96yfq+rqDKRsWjYP49ajXPUbqyiIKV/xK+OxZ+PTvj6qqlB48RP7iRSiKQsgLL8jqHkIIIYS46imKslNV1Y4XOk52ShRlrEvYRpEzibZ+E7UwnbQdFo4Gcw7c+j5Z67IoXPEDwU8+gU///gAoioJ7TEvcY1pe4NGFEEIIIa491bpTorj6vLP1a1SHK9N7j4Td38C8AaA3wvjV5Md7kvPJJ/jdcQcB48fX9lCFEEIIIa4IUqEWZ8TnZpJQ8ieRLj1p4u8Jn02FyM5w17eoLj5kzXoY9/btCX1RWjqEEEIIIU6TCrU44+V181F0dp7oNhrifgNrMdzwJLj7Y/pzC/asLAJGj0YxGmt7qEIIIYQQVwwJ1AKA7KJStueuwFtpSN+G7eDgT+AeANE3AFCwZAk6X1+8eveq3YEKIYQQQlxhJFALAP5vzTIUl0zGxIwAqxmO/AotBoPegKO4mKK1a/G5eQA6F5faHqoQQgghxBVFArUgOc/MbylLMODBPa0HQ9wasJmg5e0AFK1ahVpait+tt9bySIUQQgghrjwSqAVvrN6Jzms/tzQYhLvBXWv38KwDUd0BKPjpZ1yio3Fr06aWRyqEEEIIceWRQP0vdyS9iFUnl6LoHIxpNQKsJji6Cppr7R7W5GTMO3bgO2SIrOwhhBBCCFEOCdT/cjNXHcbVfzutg9rS0K+hFqZtZmh5G6BNRkRR8B08qJZHKoQQQghxZZJA/S+2IyGXPxK3gDGbEc2Ha988+BN4hUDUdaiqSsGSX/Do0gVjWFjtDlYIIYQQ4v/bu/Mou8/6zvPvb+2r9irtkmVZBkuyZC2WN2wMBoKDG0NwJ9DZJiFNSDeBTqa7QyZn6HO60+d00kl3JmEbhgDpJNOeDA7EA97AYLxJtkq7SrK1WbL2fau96tYzf9SltJVwyVW3fnVL79c5Or73+T26+urRUh89/v6e3yhloL6O/elTr1PXsJbxFRN4/9z3Q+d52PkMLHwYSkpp37CB7jffZLw3I0qSJF2Vgfo6tetYC2v374OarTx804epLK3sa/fo6bjQ7vHdfyKqqxn3gfdnXK0kSdLoZaC+Tj3dfITyCU30kuORmx/pG2z+DtRPh9l3knI5zj/zDPUPPEBJbW22xUqSJI1iBurr1NPbDlM7pYlV01Yxb/w8OHe4b4d60S9ASQntmzaRO3OG+vc9kHWpkiRJo5qB+jp05GwHzSc20lNyko8u6Gvv4JWvQsrBqn8JQMuPfwxlZdTec0+GlUqSJI1+Burr0DPbjlA2fiOVpVW8d/Z7+25GbPpm39nTk+YB0PLcc9SsXElpfX3G1UqSJI1ugwrUETE/Iirzr++PiM9GxITClqZCebL5AJXjt/LAnPdSU14D6/8HdJ6Fuz8LQNeBA3Tu3EX9e+7PtlBJkqQiMNgd6seAXETcBPw1MA/4vwtWlQrmTFsX646uIZW08aEbPwS5blj95b7HjM9aAUDLj58DoO7++7MrVJIkqUgMNlD3ppR6gI8Cf5FS+j1geuHKUqE8u/0YJeM2UF8+nrtm3NV3sse5A/2709DX7lExbx4Vc+dmWKkkSVJxGGyg7o6ITwC/DnwvP1ZemJJUSN/f+gbl9dv5+RsfpDzK4KW/hCnvgAUfACDX0krbq69S9573ZFypJElScRhsoP4N4C7gP6eU3oiIecDfFa4sFUJ7V47VR5+D6OahGz8Ee56Do1vg7s9ASd9vhdaXXyJ1d1N3/7szrVWSJKlYlA1mUkppG/BZgIiYCNSnlP5LIQvT8Ht+53Go3cCUyuksbVgKT/8C1E2FJb/UP6fluZ9QMm4cNcuWZVipJElS8RjsKR/PRcS4iJgEbAK+GRH/rbClabg9vvU1ymp38fCCh4ijW2H3j+CO34aySgBSby8tP/kJdffeS5Tb0SNJkjQYg235GJ9SOgf8AvDNlNIK4H2FK0vDrTvXywsHfwiR+PD8h+DlL0J5Laz8zf45HVu2kDt50tM9JEmSrsFgA3VZREwHfpELNyWqiKzde4qemnXMrL6JG6MCtn4blv8aVE/sn3P+ueegtJS6e9+VXaGSJElFZrCB+j8CTwO7U0prI+JGYGfhytJw++6WrZRWH+CjNz8Ea74CKcFd/6r/ekqJlh8+S82yZZRO8Jk9kiRJgzWoQJ1S+n9TSktSSr+Tf78npfSxwpam4ZJS4rn9LwHwvukrYN3fwKKPwoQ5/XPOfe97dO7cyfiPfiSrMiVJkorSYG9KnBUR34mIYxFxNCIei4hZhS5Ow2PH0RbOpW3UlU3mxp3PQdd5uPt3+6/nWlo4+qd/StWttzL+ox/NrlBJkqQiNNiWj28CjwMzgJnA/5cfUxF4pvkQpbW7uWva7cQr/yfMuw9m3NZ//cQXv0TuxEmmfeF/J0oG+1tCkiRJMPhA3ZBS+mZKqSf/7VtAQwHr0jD6/o71lJS18p4og/OH4O7P9V/r3LmTU3/7t0x45BGqb701wyolSZKK02AD9YmI+JW70aI6AAAgAElEQVSIKM1/+xXgZCEL0/A4dq6DPec3AHDn6z+CxkVw0wNAX2/1kT/+z5TU1dHw+7+XZZmSJElFa7CB+jfpOzLvCHAYeIS+x5FrlPvh9mOU1u5kbuU0Go6+1neyRwQA5598krZXXqHx33yOsokT3+KTJEmSNJDBnvLxZkrpwymlhpRSY0rpI/Q95EWj3DPb91NWu5d7ewMqx8Givl+21NvL0f/6Z1QtXMiEX/zFjKuUJEkqXkO5A+33h60KFURbVw+rD66D6OGuQ6/BrY9ARQ0AXfv20XP4MBN/+V8QpaUZVypJklS8hhKoY9iqUEE8v+MEqWoHZZSwsvUcLPvV/msd27YBULVoUVblSZIkjQlDCdRp2KpQQfxw+1Eq63extLeEmsZFMGNZ/7XO7duJ8nIq58/PsEJJkqTiV/azLkbEeQYOzgFUF6QiDYtcb+LZHXtg5kHuPHMG7vyj/psRoW+HuvLmm4ny8gyrlCRJKn4/M1CnlOpHqhANr6a9pzjPdqoD7urshSUXbjxMKdHRvI36D3wgwwolSZLGBh+LN0Y9ufUIVfU7qO9NLLrxA1Azqf9az+HD5M6epWrhLRlWKEmSNDYYqMeg3t7EU82HGVf/Gre3t1O2/Ncuud5/Q+LChVmUJ0mSNKb8zJYPFadNB85wtO0gdSWt3Bk1MO/dl1zv2LYdSkqovPnmjCqUJEkaO9yhHoOe2nqEhvr1ANyz4GEoufSXuWPbNirn30hJtfeVSpIkDVVBA3VEfDAiXo+IXRHx+QGu3x8RZyNiY/7bFwpZz/UgpcSTW48wc+IWZnd3M2f5J6+Y07Ftm+0ekiRJw6RgLR8RUQp8CXg/cABYGxGPp5S2XTb1hZTSQ4Wq43qz7fA53jx9jvbG4zycq4VJ8y653nPiBD3HjlF5izckSpIkDYdC7lCvAnallPaklLqAR4GHC/jjiXy7R81WOgLeNeOeK653bN8OeEOiJEnScClkoJ4J7L/o/YH82OXuiohNEfFkRPgc7CF6YsthFjWspSwlVi39jSuudzTnT/hwh1qSJGlYFPKUjxhg7PKnLq4H5qaUWiLi54HvAguu+KCITwGfApgzZ85w1zlm7Dx6nt3HW6mbuI/luVJqLnrU+E91bN9O+Zw5lNb7zB5JkqThUMgd6gPA7IvezwIOXTwhpXQupdSSf/0EUB4RUy7/oJTS11JKK1NKKxsaGgpYcnF7cusRJpQdZE9pD/dMXjzgnI5t29ydliRJGkaFDNRrgQURMS8iKoCPA49fPCEipkVE5F+vytdzsoA1jWlPbj3CvdNfBuCeW37xiuu5c+fo3r/f/mlJkqRhVLCWj5RST0R8BngaKAW+kVJqjohP569/FXgE+J2I6AHagY+nlC5vC9Eg7DvZyvbD57jxpu1M6YWbF/yzK+Z0bH8N8IZESZKk4VTQJyXm2zieuGzsqxe9/iLwxULWcL14fucJ6mlhU0kL99fOJUqu/J8PFx45bsuHJEnScPFJiWPEmt0nuX/Si5wtLeGeeQ8OOKdj+zbKpk6lbPLkEa5OkiRp7DJQjwEpJdbsOcnkuo1ESty1+JcHnOcNiZIkScPPQD0G7DjaQlvrOXaWHmdx+QQmVE+6Yk5vWxtde96wf1qSJGmYGajHgNW7T3B/2Wq2VpZxz4y7B5zTuno19PZSs3LFCFcnSZI0thmox4DVe06yfPxP6I3g7lt+acA553/4LCX19dTcfvsIVydJkjS2GaiLXG9v4sSeTZyoPE51lLG4cckVc1IuR8tzz1H37ncT5eUZVClJkjR2GaiL3PYj53io+2maqqtY2rCU8pIrA3P7hg3kTp+m/oH3ZlChJEnS2GagLnJrdxzg/eUvsLOinNtnDtw/ff6HzxLl5dTee+8IVydJkjT2GaiL3dbHeL06kYCVU1decTmlxPkf/YiaO++ktK5u5OuTJEka4wzURSzXm7j9xHd4vraRytJKFk9ZfMWczp076X7zTeofeCCDCiVJksY+A3UR27PpBRaxh/XjJrK0YSkVpRVXzGn50Y8AqHvPe0a6PEmSpOuCgbqI5V79Ooejin29p1k57cp2D4Dzz/6IqiVLKJ/aOMLVSZIkXR8M1MWq/QzzjjzF39UtI5EG7J/uPnqUji1bbPeQJEkqIAN1kepp/i6VqZNNjbOpKKlgScOV50//tN3D4/IkSZIKpyzrAvT2tGx5gtY0mROVJ1kybgmVpZVXzDn/w2cpnzuHivnzM6hQkiTp+uAOdTHq6aLmwAs8xa0cbt89YP90rqWF1ldfpf6B9xERGRQpSZJ0fTBQF6P9a6jItbF+8g300jtg/3Tbq2uhu5u6++7LoEBJkqTrh4G6CHVuf4quVMrpaVWUlZQN2D/d1tRElJdTfdvSDCqUJEm6fthDXYS6XnuGTb3vpKXsDZbUL6G6rPqKOW1NTVQtWUJJVVUGFUqSJF0/3KEuNmf2U39uJz8pXcqbLTtYMXXFFVN6W1vpaG6mZuXAZ1NLkiRp+Bioi0za+QMA9s2eSy7lBrwhsW3jRsjlDNSSJEkjwEBdZNqan2R/bwM09lAapdzWcNuVc5qaoKSE6mXLMqhQkiTp+mKgLiY9nVTsf4HnepfSFru5eeLN1JTXXDGtfW0TVQsXUlpXm0GRkiRJ1xcDdTHZ9zLluXa21N7OjrPN3NZ45e50b2cn7Zs32+4hSZI0QgzURaRnxzN0pTK6599Ee087yxqvbOno2LKF1NVFze0GakmSpJFgoC4iXdufZk3vLdQ3nAS4ev80UL18+YjWJkmSdL0yUBeL03upObeb59NttLCTxppGptVOu2Ja29omKhcsoGzixAyKlCRJuv4YqIvFrh8CcGL6fWw9uZlljcuIiEumpJ4e2jZssN1DkiRpBBmoi0THzp9wME1m+oLZHG49PGC7R8f27aS2Nm9IlCRJGkEG6mKQErH3Rdb03sKkyYcBBjzho21tvn/aQC1JkjRiyrIuQINw/HUqu06xufRWqnt2UFVaxTsmveOKaW1NTVTMnUt5Y2MGRUqSJF2f3KEuBntfAKBr9t1sPL6RxVMWU15SfsmU1NtL27p1VNs/LUmSNKIM1EWgPd8/Pfemm3jt1GsDnj/duXMXvWfP2j8tSZI0wgzUo11KlOx7Kd8/fYxcyg3YP9360ksA1N5xx0hXKEmSdF0zUI92+f7pTaWLOZ3bAcDShqVXTGt5/nkqFyygfPr0ka5QkiTpumagHu1+2j896242n9jEjeNvZHzl+Eum5FpaaVu3jrp335dFhZIkSdc1A/Uo177zeQ6mycxfsJBNxzcNfFzemtXQ3U3tvQZqSZKkkWagHs1SomRf3/nTs6e1cbbz7IAPdGl5/gVKamupWX7lzYqSJEkqLAP1aJbvn95YspgWdgGwtPHS/umUEi3PP0/t3XcT5eUDfYokSZIKyEA9ml3UP73x+AYmVk5k3rh5l0zp3LmTniNH7J+WJEnKiIF6FOvYle+fvnkR64+tZ1njMiLikjmtzz8PQO2992ZRoiRJ0nXPQD1apUTs7eufvnkm7D+/n+VTl18xreX5F6h85zspnzo1gyIlSZJkoB6tLuqfbi/p659e3nhpoM61tNC2fj117k5LkiRlxkA9WuX7pztm9vVPV5dV887J77xkSuvLL0NPj/3TkiRJGSpooI6ID0bE6xGxKyI+/zPm3R4RuYh4pJD1FI2U6F73t+zsncn8mxex4dgGlkxZQnnJpad4tL7wAiX19VTfduVRepIkSRoZBQvUEVEKfAl4EFgIfCIiFl5l3p8ATxeqlqJzYC3lRzfxN7kPsGROFa+ffp1lUy89Y7rvuLwXqL3nHqKsLKNCJUmSVMgd6lXArpTSnpRSF/Ao8PAA834XeAw4VsBaisuar9BeUsdTpffTXf4Gvan3iv7pzh076Dl61P5pSZKkjBUyUM8E9l/0/kB+rF9EzAQ+Cny1gHUUl7MHYds/8f2yB1h4www2Hd9AaZSytOHSB7qc+/4TUFJC3X0GakmSpCwVMlDHAGPpsvd/AfxBSin3Mz8o4lMR0RQRTcePHx+2Akelpm+QUi9/cf493DFvEhuObeCdk95JTXlN/5TU08PZ73yHuvvuo6yhIcNiJUmSVMhAfQCYfdH7WcChy+asBB6NiL3AI8CXI+Ijl39QSulrKaWVKaWVDWM5QHZ3wLpvcmz6ezmQGllxQz1bTmxhWeOl/dMtz79Az/HjTPjn3sMpSZKUtULezbYWWBAR84CDwMeBf3HxhJRS/3O0I+JbwPdSSt8tYE2j29bHoO0kT854mOryUsqqD9GZ62TF1BWXTDvz2GOUTplC3X0elydJkpS1gu1Qp5R6gM/Qd3rHduAfUkrNEfHpiPh0oX7copUSvPIVaLiFR4/fwMobJrL5xAYAbmu8cCxez/HjtDz3HBM+8jBRXn61T5MkSdIIKeh5aymlJ4AnLhsb8AbElNL/UshaRr03V8ORLbR+4M957fEWHlo6gw1HN3DDuBuYUj2lf9qZ734XcjnG/8LHMixWkiRJP+WTEkeLzf8PVNTzcs17AVg1byLrj62/pH86pcTZx/6R6pUrqLxx3tU+SZIkSSPIQD1anNgJUxfx8v52qspLqK8/xbmucyyfeuH86fZ16+jau5cJH/NmREmSpNHCQD1anNwNk+ezZs8pVsydyJaTGwEueaDLmW8/RkltLeN+7gNZVSlJkqTLGKhHg84WaDlCe/1cXjtyjjvmTWbd0XVMqZ7C7Pq+kwdz589z7qmnGPehD1FSU/MWHyhJkqSRYqAeDU7tAWBHdwMpwR3zJrHu6DpWTF1BRN/zcc4/8wypo4MJj3gzoiRJ0mhioB4N8oH61XMTqSwroXFSK0fbjl7S7tHWtI7SiROpuvXWrKqUJEnSAAp6bJ4G6dRuAJ4+XMPyOePZenITwCUPdGnfvJnqJUv6d6wlSZI0OrhDPRqc3ENvbSPrjvRwx4197R71FfUsmLgA6Ouf7tqzh6qlSzIuVJIkSZczUI8Gp3Zztno2KcGdN/bdkLi8cTkl0ffL07FlC6RE9ZKlGRcqSZKkyxmoR4NTe3iT6VSUljB7So695/Zeev705s0AVC+xf1qSJGm0sYc6a53noeUo22IKi2aOY9vpAfqnN22m4sYbKR03LqsqJUmSdBXuUGctf8LH2nOTWDxjPOuOrqOqtIqFkxYCfY8b/+kNiZIkSRp9DNRZO9l3wsdrXVNYPHMc64+uZ2nDUspLywHoPniI3MmTVHtDoiRJ0qhkoM5afod6b5rGvMZSXjv12iX90x2b+1pAqtyhliRJGpUM1Fk7tYfz5VPoLq2mld0k0mX905uIykqqbr45wyIlSZJ0NQbqrJ3czYGYzjum1bPpxHrKoowlDRd2o9s3baZq0SKivDzDIiVJknQ1BuqMpVO7+/qnZ4xn/bH1LJyykOqy6r5rXV10bNvmDYmSJEmjmIE6Sx3niNbj7Oieys3Tq9hyYgsrGi+0e3S8voPU1eUNiZIkSaOYgTpL+RsS30jTqK47SE9vz6X90/kbEt2hliRJGr0M1Fk61Xdk3psxjZM9rxEEtzXe1n+5Y/NmSqdMoWzGjKwqlCRJ0lswUGfpZN8OdfmU+Ww+sYEFExcwvnJ8/+X2TZupXrqUiMiqQkmSJL0FA3WG0qndHGMSN86YwsbjG1neeOH86dzZs3Tt3Wu7hyRJ0ihnoM5Q9/Fd7OmdSuOUE7T3tF/WP70FwBsSJUmSRjkDdZZO7uaN3mn0VPT1Ul/8hMT2zZsggqrFi7OqTpIkSYNgoM5Kx1kqOk+xj6kc6dzG7PrZNNY0Xri8tZmKefMoravLsEhJkiS9FQN1VvJH5rXVzWXTiQ2XtHsAdDQ3U7VoURaVSZIk6RoYqLNysq/No2vaRM52nr3khsSe48fpOXaMqkULs6pOkiRJg2SgzkjbkR0AtE/qAGDl1JX91zq2bQOg2h1qSZKkUa8s6wKuV+cPvs7ZNInzZXtpqG5gVv2s/mvtzc0QQeUt7lBLkiSNdu5QZ6T0+DZ29M5gb8tWVkxdccnDWzqat1Fxww2U1tVmWKEkSZIGw0Cdhe4OJrbuZnPNDRxvP3bJcXngDYmSJEnFxECdgY6Dmyklx8HpkwAuOeGj5+RJeo4cMVBLkiQVCQN1BnZtegmA85MT4yrGcdOEm/qvdTQ3A3jChyRJUpEwUGfg3J61nKGOvd1vsLxxOSVx4ZehP1DfcktW5UmSJOkaGKhHWEd3jglnmtlRv4A3z795Rf90e3MzFXPnUlpfn1GFkiRJuhYG6hH2wvaD3MR+ds2YDTDAExK32T8tSZJURAzUI2zL+pepiBxvjK+kuqyaWyZfaO3oOXWKnsOHDdSSJElFxEA9gjp7crS80QTAuo4jLGlYQnlJef/1jua+JyQaqCVJkoqHgXoEvbTrBDfldnG0agI7z+/jzul3XnLdEz4kSZKKj4F6BD2x5QhLy/axftp8AFZNW3XJ9Y7mZsrnzvGGREmSpCJioB4hXT29/Kj5AO+I/aytraW2vJaFky/die5obqbadg9JkqSiYqAeIS/vPsH0zjcoS928mjvPyqkrKSsp67/ec/o03YcO2T8tSZJUZAzUI+TJLUdYWbGPI6Wl7Os8OUC7hzckSpIkFSMD9Qh5Yedx3jf+MK+OmwjAHdPvuOR6/w2JC70hUZIkqZgUNFBHxAcj4vWI2BURnx/g+sMRsTkiNkZEU0S8q5D1ZOXgmXYOne3gFnbzyoQGJlROYMHEBf3XU28v5773PSoXLKB03LgMK5UkSdK1KligjohS4EvAg8BC4BMRcfn267PA0pTSbcBvAl8vVD1Zatp7inJ6mNiyi1dLerl92u2UxIWlP/fkk3Tu3Mnk3/7tDKuUJEnS21HIHepVwK6U0p6UUhfwKPDwxRNSSi0ppZR/WwskxqCmvadZUnGYgyW9HOlt545pF9o9Uk8PJ/7qi1QuWMC4n38wwyolSZL0dhQyUM8E9l/0/kB+7BIR8dGIeA34Pn271FeIiE/lW0Kajh8/XpBiC6lp32kenHyEV6orAVg1/cINiWf/6XG69u6l4XOfJUpsaZckSSo2hUxwMcDYFTvQKaXvpJTeCXwE+E8DfVBK6WsppZUppZUNDQ3DXGZhnevo5rUj57i98k1era2nsaaRG8bdAEDq6uLEl75E1eLF1D3wQLaFSpIk6W0pZKA+AMy+6P0s4NDVJqeUngfmR8SUAtY04ja8eYaUYF7X67xaVcUd0+4gou/fGmcee4zuQ4do+Nzn+sckSZJUXAoZqNcCCyJiXkRUAB8HHr94QkTcFPkkGRHLgQrgZAFrGnFNe09RV9LJkZadnIre/naP3o4OTnzlq1SvWEHtu+7JuEpJkiS9XWVvPeXtSSn1RMRngKeBUuAbKaXmiPh0/vpXgY8BvxYR3UA78EsX3aQ4Jqzde4qHpxxmLeUA/Q90Of3oo/QcO8bMP/8zd6clSZKKWMECNUBK6QngicvGvnrR6z8B/qSQNWSpO9fLxv1n+O1Ze/hOrorZdTOZUTcD6LsZsXrZMmpuvz3jKiVJkjQUHitRQM2HztHR3cstuWaaampYNf1OAHpOnaJz+3bq3v3ujCuUJEnSUBmoC6hp7ylKyXG8pZnzceFx462rVwNQe/ddWZYnSZKkYWCgLqCmvae5f/xR1pb3tYXfPq2vvaN19WpKxo2jatGiLMuTJEnSMDBQF0hKiaZ9p3lowj5eraripvq5TKmeQkqJ1pdfpvaOO4jS0qzLlCRJ0hAZqAtk38k2TrR0civbWV9dzaqZfUfjde/bR8+hw9Tec3fGFUqSJGk4GKgLpGnfaSBxumML7XHhceP9/dN32T8tSZI0FhioC6Rp7ykWVp2kKdoJYOXUlQC0vvwy5TNmUD5nTrYFSpIkaVgYqAukad9pfmHym7xaVcUt425kfOV4Ui5H65pXqL3nbh/mIkmSNEYYqAvgTFsXu461sKL8dTZVVXLHrPsA6Ni6ld7z5233kCRJGkMM1AWw4c0zAJzt3kJ3BKtmXHr+dI2BWpIkacwwUBfAun2naSg5z6be05QRLG9cDkDrSy9TufAWyiZOzLhCSZIkDRcDdQGs23eah/P907eOn09NeQ29bW20bdxI3d0elydJkjSWGKiHWU+ul437z3Bn9Q62Vlawavb9ALQ1NUF3t+0ekiRJY4yBepi9duQ87d05OtMWeiO4Y2bfjnTry6uJigpqVqzIuEJJkiQNJwP1MFv/5mkmco7m3FEqo5QlDUsAaF2zhurlyympqsq4QkmSJA0nA/UwW7fvNA/XNrO6upLbJr6DytJKcmfP0vn669Ssuj3r8iRJkjTMDNTDbN2+09xav5ZdFRW876aPANC2fj2kRM3KlRlXJ0mSpOFmoB5GR891cPT0ebaU7aGKEj40/yGg74bEKC+nesmSjCuUJEnScDNQD6P1+06zonQrT9VW8IEpy6ivqAf6AnXVkiX2T0uSJI1BBuphtG7faWZOeJ7WkhI+dtu/BKC3tZWO5m22e0iSJI1RZVkXMJas23eKivEHmEcVy2b0HZfXvmkT9PQYqCVJksYod6iHSUd3jrMnXmRbZQkfm3oHEQHkH+hSUkL1smUZVyhJkqRCMFAPk60HzzJx/I8pS4l/tuxf9Y+3rW2iauFCSutqM6xOkiRJhWKgHiav7j3GwXGHeE9POZOmLgagt6uL9k2bbPeQJEkaw+yhHiYv7P0eraXwyNS7+8c6tmwhdXVRc7uBWpIkaawyUA+DlBJHOp5gZlkPd976a/3jbWubAKhevjyr0iRJklRgtnwMg62HD3Gy6jgPtucomXXh8eJtTU1ULlhA2cSJGVYnSZKkQjJQD4PHtv+AFHDHxGVQ0rekqaeH9vXrbfeQJEka4wzUw2DzwaeYlMux8tZH+sc6tr9Gb1ubNyRKkiSNcQbqIcr15tife513tbVTNv/+/vG2pnz/9AoDtSRJ0lhmoB6iVw5toKOkh6W9E6GuoX+8bV0T5XPnUD61McPqJEmSVGgG6iH67vanKE2JxY3v6h9LuRxta5ts95AkSboOGKiHaOPhH7O0s5O5Sx/qH+vYsoXes2epu+eeDCuTJEnSSDBQD8GxtmMcTse4u62L2vkXdqhbXnwJIqi5664Mq5MkSdJIMFAPwQsHXgRgPnOhoqZ/vPXFF6m69VbPn5YkSboOGKiH4OmdT9HY00PjtPv7x3Jnz9K+eTN177LdQ5Ik6XpgoH6bunu72XCiiXvbOpi85Of6x1tXr4HeXmrf9a6f8b0lSZI0Vhio36aNxzbSQTcr2hMz3nlH/3jrSy9SUl9P9ZIlGVYnSZKkkWKgfpteOPA8ZSkxIRYSpWUApJRoeeklau+8kygry7hCSZIkjQQD9dv03N4fsqKjk96Z7+4f63rjDXoOHabW4/IkSZKuGwbqt+FI6xHeaD3AvW3tTFj0gf7x1hf7Tv2wf1qSJOn6YaB+G9YcXgPAvLZq3nHLrf3jLS++SMUNN1Axa2ZWpUmSJGmEGajfhtUHX2Zirpe2smVUVfT1Svd2dtL26lp3pyVJkq4zBQ3UEfHBiHg9InZFxOcHuP7LEbE5/+3liFhayHqGQ0qJNYde5q72djqmruwfb1+3jtTRQa3nT0uSJF1XChaoI6IU+BLwILAQ+ERELLxs2hvAu1NKS4D/BHytUPUMl51ndnKq6yx3tXcw+aYLgbrlxZegvJzaVasyrE6SJEkjrZBnu60CdqWU9gBExKPAw8C2n05IKb180fw1wKwC1jMsVh9aDcCKtm4qF68A+natW194gZrlyympqflZ312SJEljTCFbPmYC+y96fyA/djWfBJ4sYD3DYs3hNUzvKaUrTadx4ngAWp57js6dOxn34Aczrk6SJEkjrZA71DHAWBpwYsR76AvUA97RFxGfAj4FMGfOnOGq75p157ppOtrEz7W1c3pcX7t36unh2J/9ORVz5zLhYx/LrDZJkiRlo5A71AeA2Re9nwUcunxSRCwBvg48nFI6OdAHpZS+llJamVJa2dDQUJBiB2PT8U109HTw3vazlM3oOy7vzLcfo2v3bhr/3b8lysszq02SJEnZKGSgXgssiIh5EVEBfBx4/OIJETEH+EfgV1NKOwpYy7BYfXg1QXB7ewdTF6wg19LK8b/6K6pXrqDugQeyLk+SJEkZKFjLR0qpJyI+AzwNlALfSCk1R8Sn89e/CnwBmAx8OSIAelJKK6/2mVlbc3gNs3LjqU+Juptv5/hff53cyZNM/cqXydcvSZKk60whe6hJKT0BPHHZ2Fcvev1bwG8Vsobhcr7rPFtPbOW9LeM4UzqZ2tZeTn3zW4z7+Z+nesmSrMuTJElSRgoaqMeK3Jkz7P3IQ/xRZTezyk9ycvI0zn/hP0AuR8Pv/17W5UmSJClDBupB6O3q4vAN9VTtP83kI9107TpNFz9h8m99kopZo/7obEmSJBWQgXoQyhsb+auHy+g9/w6+v+dZuh/8Mr2Nd1Mxe/Zbf2dJkiSNaYU85WPMONJ6hL3n9jL1XDUA5TfeTuW8eUSZ/x6RJEm63hmoB6G+op4v3PHHLD7RTndJJUyen3VJkiRJGiUM1INQW17LlLiLO3OH6Zj4DigpzbokSZIkjRIG6kFau+ckt5S8SfXspVmXIkmSpFHEJuBB2rNnJxOjBWYYqCVJknSBO9SD0NmTo/fIlr43UxdnW4wkSZJGFQP1IBw928mdNYf63kxdlG0xkiRJGlUM1IMwZ3INvzm/BSbMhapxWZcjSZKkUcRAPVhHt8K0W7OuQpIkSaOMgXowulrh5G4DtSRJkq5goB6MtpMwexXMXJF1JZIkSRplPDZvMCbMgU8+k3UVkiRJGoXcoZYkSZKGwEAtSZIkDYGBWpIkSRoCA7UkSZI0BAZqSZIkaQgM1JIkSdIQGKglSZKkITBQS5IkSUNgoJYkSZKGwEAtSVT/i/EAAAdkSURBVJIkDYGBWpIkSRoCA7UkSZI0BAZqSZIkaQgM1JIkSdIQGKglSZKkITBQS5IkSUNgoJYkSZKGwEAtSZIkDUGklLKu4ZpExHFgX0Y//BTgREY/9ljhGg4P13F4uI5D5xoOD9dxeLiOw8N1vGBuSqnhrSYVXaDOUkQ0pZRWZl1HMXMNh4frODxcx6FzDYeH6zg8XMfh4TpeO1s+JEmSpCEwUEuSJElDYKC+Nl/LuoAxwDUcHq7j8HAdh841HB6u4/BwHYeH63iN7KGWJEmShsAdakmSJGkIDNSDEBEfjIjXI2JXRHw+63qKRUTMjogfR8T2iGiOiM/lxydFxA8iYmf+vxOzrnW0i4jSiNgQEd/Lv3cNr1FETIiIb0fEa/nfk3e5jtcuIn4v/+d5a0T8z4ioch3fWkR8IyKORcTWi8auum4R8Yf5rzmvR8TPZVP16HKVNfyv+T/TmyPiOxEx4aJrruEABlrHi67924hIETHlojHXcRAM1G8hIkqBLwEPAguBT0TEwmyrKho9wP+aUroFuBP41/m1+zzwbEppAfBs/r1+ts8B2y967xpeu/8DeCql9E5gKX3r6Tpeg4iYCXwWWJlSWgyUAh/HdRyMbwEfvGxswHXL/z35cWBR/vt8Of+16Hr3La5cwx8Ai1NKS4AdwB+Ca/gWvsWV60hEzAbeD7x50ZjrOEgG6re2CtiVUtqTUuoCHgUezrimopBSOpxSWp9/fZ6+ADOTvvX7m/y0vwE+kk2FxSEiZgEfAr5+0bBreA0iYhxwH/DXACmlrpTSGVzHt6MMqI6IMqAGOITr+JZSSs8Dpy4bvtq6PQw8mlLqTCm9Aeyi72vRdW2gNUwpPZNS6sm/XQPMyr92Da/iKr8XAf478O+Bi2+ucx0HyUD91mYC+y96fyA/pmsQETcAy4BXgKkppcPQF7qBxuwqKwp/Qd9fcr0XjbmG1+ZG4DjwzXzrzNcjohbX8ZqklA4Cf0bfDtZh4GxK6Rlcx7frauvm15235zeBJ/OvXcNrEBEfBg6mlDZddsl1HCQD9VuLAcY8GuUaREQd8Bjwb1JK57Kup5hExEPAsZTSuqxrKXJlwHLgKymlZUArtiVcs3yP78PAPGAGUBsRv5JtVWOSX3euUUT8EX1thn//06EBprmGA4iIGuCPgC8MdHmAMddxAAbqt3YAmH3R+1n0/S9ODUJElNMXpv8+pfSP+eGjETE9f306cCyr+orAPcCHI2Ivfe1G742Iv8M1vFYHgAMppVfy779NX8B2Ha/N+4A3UkrHU0rdwD8Cd+M6vl1XWze/7lyDiPh14CHgl9OFs4Bdw8GbT98/kjflv9bMAtZHxDRcx0EzUL+1tcCCiJgXERX0Nec/nnFNRSEigr6e1e0ppf920aXHgV/Pv/514J9GurZikVL6w5TSrJTSDfT93vtRSulXcA2vSUrpCLA/It6RH3oA2IbreK3eBO6MiJr8n+8H6Ls3wnV8e662bo8DH4+IyoiYBywAXs2gvlEvIj4I/AHw4ZRS20WXXMNBSiltSSk1ppRuyH+tOQAsz/+96ToOUlnWBYx2KaWeiPgM8DR9d7R/I6XUnHFZxeIe4FeBLRGxMT/2vwH/BfiHiPgkfV+g/3lG9RUz1/Da/S7w9/l/GO8BfoO+TQXXcZBSSq9ExLeB9fT97/UN9D1RrQ7X8WeKiP8J3A9MiYgDwH/gKn+OU0rNEfEP9P2jrwf41ymlXCaFjyJXWcM/BCqBH/T9G481KaVPu4ZXN9A6ppT+eqC5ruPg+aRESZIkaQhs+ZAkSZKGwEAtSZIkDYGBWpIkSRoCA7UkSZI0BAZqSZIkaQgM1JI0ykVELiI2XvRt2J7yGBE3RMTW4fo8SboeeQ61JI1+7Sml27IuQpI0MHeoJalIRcTeiPiTiHg1/+2m/PjciHg2Ijbn/zsnPz41Ir4TEZvy3+7Of1RpRPxfEdEcEc9ERHV+/mcjYlv+cx7N6KcpSaOegVqSRr/qy1o+fumia+dSSquALwJ/kR/7IvA/UkpLgL8H/jI//pfAT1JKS4HlwE+f+roA+FJKaRFwBvhYfvzzwLL853y6UD85SSp2PilRkka5iGhJKdUNML4XeG9KaU9ElANHUkqTI+IEMD2l1J0fP5xSmhIRx4FZKaXOiz7jBuAHKaUF+fd/AJSnlP44Ip4CWoDvAt9NKbUU+KcqSUXJHWpJKm7pKq+vNmcgnRe9znHh/poPAV8CVgDrIsL7biRpAAZqSSpuv3TRf1fnX78MfDz/+peBF/OvnwV+ByAiSiNi3NU+NCJKgNkppR8D/x6YAFyxSy5J8pQPSSoG1RGx8aL3T6WUfnp0XmVEvELfBskn8mOfBb4REf8OOA78Rn78c8DXIuKT9O1E/w5w+Co/ZinwdxExHgjgv6eUzgzbz0iSxhB7qCWpSOV7qFemlE5kXYskXc9s+ZAkSZKGwB1qSZIkaQjcoZYkSZKGwEAtSZIkDYGBWpIkSRoCA7UkSZI0BAZqSZIkaQgM1JIkSdIQ/P+q1KEiGwIdTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['acc'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(L2_acc_values, label='Training acc L2')\n",
    "ax.plot(L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(baseline_model_acc, label='Training acc')\n",
    "ax.plot(baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:36:40.247875Z",
     "start_time": "2020-09-14T16:35:59.185108Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 16.0091 - acc: 0.1333 - val_loss: 15.5992 - val_acc: 0.1370\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 15.2374 - acc: 0.1676 - val_loss: 14.8513 - val_acc: 0.1680\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 14.5011 - acc: 0.1941 - val_loss: 14.1314 - val_acc: 0.1890\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 13.7896 - acc: 0.2133 - val_loss: 13.4337 - val_acc: 0.2040\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 13.0999 - acc: 0.2365 - val_loss: 12.7558 - val_acc: 0.2220\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 12.4300 - acc: 0.2639 - val_loss: 12.0980 - val_acc: 0.2580\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 11.7801 - acc: 0.2881 - val_loss: 11.4597 - val_acc: 0.2790\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 11.1498 - acc: 0.3157 - val_loss: 10.8408 - val_acc: 0.3010\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 10.5384 - acc: 0.3412 - val_loss: 10.2394 - val_acc: 0.3190\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 9.9449 - acc: 0.3679 - val_loss: 9.6550 - val_acc: 0.3500\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 9.3694 - acc: 0.3983 - val_loss: 9.0901 - val_acc: 0.3740\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 8.8125 - acc: 0.4292 - val_loss: 8.5457 - val_acc: 0.3810\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 8.2765 - acc: 0.4479 - val_loss: 8.0205 - val_acc: 0.4310\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 7.7624 - acc: 0.4819 - val_loss: 7.5207 - val_acc: 0.4420\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 7.2711 - acc: 0.4999 - val_loss: 7.0388 - val_acc: 0.4930\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 6.8024 - acc: 0.5299 - val_loss: 6.5827 - val_acc: 0.5170\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 6.3565 - acc: 0.5537 - val_loss: 6.1503 - val_acc: 0.5160\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 5.9334 - acc: 0.5645 - val_loss: 5.7401 - val_acc: 0.5390\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 5.5330 - acc: 0.5827 - val_loss: 5.3530 - val_acc: 0.5560\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 5.1556 - acc: 0.5884 - val_loss: 4.9856 - val_acc: 0.5850\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 4.8013 - acc: 0.6057 - val_loss: 4.6440 - val_acc: 0.5860\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 4.4703 - acc: 0.6188 - val_loss: 4.3267 - val_acc: 0.5930\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 4.1622 - acc: 0.6237 - val_loss: 4.0293 - val_acc: 0.5970\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 3.8765 - acc: 0.6296 - val_loss: 3.7568 - val_acc: 0.6090\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 3.6135 - acc: 0.6375 - val_loss: 3.5087 - val_acc: 0.6110\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 3.3734 - acc: 0.6451 - val_loss: 3.2737 - val_acc: 0.6380\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 3.1551 - acc: 0.6505 - val_loss: 3.0674 - val_acc: 0.6370\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.9589 - acc: 0.6591 - val_loss: 2.8833 - val_acc: 0.6380\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.7842 - acc: 0.6616 - val_loss: 2.7186 - val_acc: 0.6490\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.6306 - acc: 0.6629 - val_loss: 2.5738 - val_acc: 0.6540\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.4977 - acc: 0.6675 - val_loss: 2.4509 - val_acc: 0.6570\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.3842 - acc: 0.6652 - val_loss: 2.3468 - val_acc: 0.6630\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.2906 - acc: 0.6675 - val_loss: 2.2626 - val_acc: 0.6590\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.2162 - acc: 0.6656 - val_loss: 2.1983 - val_acc: 0.6600\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.1585 - acc: 0.6701 - val_loss: 2.1462 - val_acc: 0.6700\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.1154 - acc: 0.6687 - val_loss: 2.1094 - val_acc: 0.6700\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.0835 - acc: 0.6700 - val_loss: 2.0817 - val_acc: 0.6660\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.0574 - acc: 0.6700 - val_loss: 2.0579 - val_acc: 0.6640\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.0344 - acc: 0.6704 - val_loss: 2.0344 - val_acc: 0.6700\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.0142 - acc: 0.6721 - val_loss: 2.0166 - val_acc: 0.6620\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.9950 - acc: 0.6743 - val_loss: 1.9976 - val_acc: 0.6640\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9772 - acc: 0.6756 - val_loss: 1.9826 - val_acc: 0.6640\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9599 - acc: 0.6717 - val_loss: 1.9626 - val_acc: 0.6650\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9430 - acc: 0.6748 - val_loss: 1.9428 - val_acc: 0.6700\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9283 - acc: 0.6767 - val_loss: 1.9283 - val_acc: 0.6690\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.9131 - acc: 0.6784 - val_loss: 1.9165 - val_acc: 0.6690\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.8984 - acc: 0.6781 - val_loss: 1.9009 - val_acc: 0.6710\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.8848 - acc: 0.6796 - val_loss: 1.8851 - val_acc: 0.6740\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8711 - acc: 0.6820 - val_loss: 1.8744 - val_acc: 0.6740\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8581 - acc: 0.6812 - val_loss: 1.8634 - val_acc: 0.6720\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8455 - acc: 0.6813 - val_loss: 1.8476 - val_acc: 0.6790\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8332 - acc: 0.6817 - val_loss: 1.8355 - val_acc: 0.6850\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8214 - acc: 0.6828 - val_loss: 1.8232 - val_acc: 0.6840\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8094 - acc: 0.6821 - val_loss: 1.8139 - val_acc: 0.6880\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.7979 - acc: 0.6829 - val_loss: 1.7985 - val_acc: 0.6880\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7870 - acc: 0.6864 - val_loss: 1.7894 - val_acc: 0.6860\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7759 - acc: 0.6852 - val_loss: 1.7783 - val_acc: 0.6880\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.7649 - acc: 0.6860 - val_loss: 1.7756 - val_acc: 0.6820\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7548 - acc: 0.6865 - val_loss: 1.7593 - val_acc: 0.6850\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7443 - acc: 0.6877 - val_loss: 1.7467 - val_acc: 0.6830\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7349 - acc: 0.6892 - val_loss: 1.7377 - val_acc: 0.6900\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7244 - acc: 0.6887 - val_loss: 1.7262 - val_acc: 0.6880\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7147 - acc: 0.6888 - val_loss: 1.7209 - val_acc: 0.6840\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7059 - acc: 0.6909 - val_loss: 1.7093 - val_acc: 0.6840\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6965 - acc: 0.6909 - val_loss: 1.6983 - val_acc: 0.6830\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.6871 - acc: 0.6932 - val_loss: 1.6935 - val_acc: 0.6870\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.6782 - acc: 0.6931 - val_loss: 1.6903 - val_acc: 0.6850\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6695 - acc: 0.6940 - val_loss: 1.6799 - val_acc: 0.6860\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6607 - acc: 0.6940 - val_loss: 1.6708 - val_acc: 0.6810\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.6563 - acc: 0.693 - 0s 40us/step - loss: 1.6530 - acc: 0.6953 - val_loss: 1.6599 - val_acc: 0.6840\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.6439 - acc: 0.6955 - val_loss: 1.6499 - val_acc: 0.6890\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6358 - acc: 0.6960 - val_loss: 1.6430 - val_acc: 0.6890\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6278 - acc: 0.6972 - val_loss: 1.6352 - val_acc: 0.6880\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.6197 - acc: 0.6979 - val_loss: 1.6300 - val_acc: 0.6850\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.6114 - acc: 0.6967 - val_loss: 1.6174 - val_acc: 0.6880\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.6040 - acc: 0.6975 - val_loss: 1.6112 - val_acc: 0.6850\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5956 - acc: 0.6984 - val_loss: 1.6041 - val_acc: 0.6900\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.5887 - acc: 0.6981 - val_loss: 1.5968 - val_acc: 0.6880\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5810 - acc: 0.7003 - val_loss: 1.5863 - val_acc: 0.6920\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.5735 - acc: 0.6997 - val_loss: 1.5808 - val_acc: 0.6920\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.5668 - acc: 0.6995 - val_loss: 1.5759 - val_acc: 0.6910\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5598 - acc: 0.6999 - val_loss: 1.5681 - val_acc: 0.6830\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5523 - acc: 0.7013 - val_loss: 1.5660 - val_acc: 0.6860\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.5453 - acc: 0.7031 - val_loss: 1.5552 - val_acc: 0.6900\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.5383 - acc: 0.7031 - val_loss: 1.5516 - val_acc: 0.6850\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5316 - acc: 0.7024 - val_loss: 1.5406 - val_acc: 0.6890\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.5243 - acc: 0.7040 - val_loss: 1.5406 - val_acc: 0.6880\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.5177 - acc: 0.7029 - val_loss: 1.5280 - val_acc: 0.6900\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5109 - acc: 0.7049 - val_loss: 1.5292 - val_acc: 0.6940\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.5049 - acc: 0.7025 - val_loss: 1.5188 - val_acc: 0.6890\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4986 - acc: 0.7043 - val_loss: 1.5097 - val_acc: 0.6830\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4918 - acc: 0.7057 - val_loss: 1.5064 - val_acc: 0.6870\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4860 - acc: 0.7061 - val_loss: 1.4960 - val_acc: 0.6880\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.4795 - acc: 0.7052 - val_loss: 1.4965 - val_acc: 0.6860\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.4735 - acc: 0.7057 - val_loss: 1.4852 - val_acc: 0.6950\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4674 - acc: 0.7065 - val_loss: 1.4821 - val_acc: 0.6890\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.4617 - acc: 0.7072 - val_loss: 1.4776 - val_acc: 0.6850\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4556 - acc: 0.7079 - val_loss: 1.4714 - val_acc: 0.6890\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4498 - acc: 0.7096 - val_loss: 1.4630 - val_acc: 0.6900\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4436 - acc: 0.7077 - val_loss: 1.4575 - val_acc: 0.6910\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4386 - acc: 0.7089 - val_loss: 1.4548 - val_acc: 0.6870\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4329 - acc: 0.7101 - val_loss: 1.4477 - val_acc: 0.6940\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4268 - acc: 0.7104 - val_loss: 1.4423 - val_acc: 0.6920\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4216 - acc: 0.7089 - val_loss: 1.4363 - val_acc: 0.6950\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4156 - acc: 0.7111 - val_loss: 1.4304 - val_acc: 0.6960\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4106 - acc: 0.7120 - val_loss: 1.4372 - val_acc: 0.6960\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4054 - acc: 0.7119 - val_loss: 1.4233 - val_acc: 0.6960\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3997 - acc: 0.7119 - val_loss: 1.4172 - val_acc: 0.6920\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3942 - acc: 0.7139 - val_loss: 1.4122 - val_acc: 0.6920\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3892 - acc: 0.7128 - val_loss: 1.4062 - val_acc: 0.6950\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.3825 - acc: 0.713 - 0s 34us/step - loss: 1.3837 - acc: 0.7128 - val_loss: 1.4118 - val_acc: 0.6950\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3789 - acc: 0.7143 - val_loss: 1.3993 - val_acc: 0.6960\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3740 - acc: 0.7137 - val_loss: 1.3901 - val_acc: 0.6980\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3689 - acc: 0.7141 - val_loss: 1.3888 - val_acc: 0.6950\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3644 - acc: 0.7144 - val_loss: 1.3812 - val_acc: 0.6930\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3592 - acc: 0.7145 - val_loss: 1.3828 - val_acc: 0.6950\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3548 - acc: 0.7157 - val_loss: 1.3759 - val_acc: 0.6950\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3490 - acc: 0.7152 - val_loss: 1.3718 - val_acc: 0.6970\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3457 - acc: 0.7155 - val_loss: 1.3669 - val_acc: 0.6960\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3402 - acc: 0.7159 - val_loss: 1.3597 - val_acc: 0.6960\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3357 - acc: 0.7175 - val_loss: 1.3557 - val_acc: 0.7010\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3314 - acc: 0.7173 - val_loss: 1.3521 - val_acc: 0.6990\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3277 - acc: 0.7176 - val_loss: 1.3566 - val_acc: 0.6950\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3225 - acc: 0.7173 - val_loss: 1.3414 - val_acc: 0.7070\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.3183 - acc: 0.7200 - val_loss: 1.3390 - val_acc: 0.7010\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3139 - acc: 0.7197 - val_loss: 1.3417 - val_acc: 0.6960\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3101 - acc: 0.7179 - val_loss: 1.3292 - val_acc: 0.7020\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3054 - acc: 0.7211 - val_loss: 1.3266 - val_acc: 0.7000\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3014 - acc: 0.7205 - val_loss: 1.3228 - val_acc: 0.7010\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2976 - acc: 0.7189 - val_loss: 1.3175 - val_acc: 0.7020\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.2926 - acc: 0.7223 - val_loss: 1.3153 - val_acc: 0.7050\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2892 - acc: 0.7228 - val_loss: 1.3130 - val_acc: 0.6990\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2852 - acc: 0.7217 - val_loss: 1.3078 - val_acc: 0.7040\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2814 - acc: 0.7235 - val_loss: 1.3023 - val_acc: 0.7030\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2774 - acc: 0.7212 - val_loss: 1.3025 - val_acc: 0.7020\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.2755 - acc: 0.723 - 0s 35us/step - loss: 1.2735 - acc: 0.7239 - val_loss: 1.2979 - val_acc: 0.7040\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.2696 - acc: 0.7228 - val_loss: 1.3092 - val_acc: 0.6980\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2665 - acc: 0.7229 - val_loss: 1.2923 - val_acc: 0.7060\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2620 - acc: 0.7245 - val_loss: 1.2893 - val_acc: 0.7020\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2591 - acc: 0.7239 - val_loss: 1.2841 - val_acc: 0.7030\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2548 - acc: 0.7249 - val_loss: 1.2874 - val_acc: 0.7040\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2518 - acc: 0.7251 - val_loss: 1.2773 - val_acc: 0.7060\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2479 - acc: 0.7252 - val_loss: 1.2777 - val_acc: 0.7000\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2443 - acc: 0.7272 - val_loss: 1.2736 - val_acc: 0.7030\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2409 - acc: 0.7255 - val_loss: 1.2726 - val_acc: 0.7080\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2376 - acc: 0.7268 - val_loss: 1.2620 - val_acc: 0.7060\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2337 - acc: 0.7252 - val_loss: 1.2607 - val_acc: 0.7060\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2308 - acc: 0.7283 - val_loss: 1.2568 - val_acc: 0.7070\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2275 - acc: 0.7268 - val_loss: 1.2548 - val_acc: 0.7080\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.2241 - acc: 0.7279 - val_loss: 1.2574 - val_acc: 0.7030\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "kernel_regularizer=regularizers.l1(0.005)\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50,\n",
    "                          activation='relu',\n",
    "                          input_shape=(2000,),\n",
    "                          kernel_regularizer=kernel_regularizer))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model.add(layers.Dense(25,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=kernel_regularizer))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:37:11.619901Z",
     "start_time": "2020-09-14T16:37:11.433358Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:44:26.165404Z",
     "start_time": "2020-09-14T16:43:31.325868Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 1.9903 - acc: 0.1347 - val_loss: 1.9386 - val_acc: 0.1730\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.9596 - acc: 0.1521 - val_loss: 1.9225 - val_acc: 0.2050\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.9437 - acc: 0.1631 - val_loss: 1.9121 - val_acc: 0.2100\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.9323 - acc: 0.1769 - val_loss: 1.9026 - val_acc: 0.2170\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.9213 - acc: 0.1916 - val_loss: 1.8956 - val_acc: 0.2270\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.9127 - acc: 0.1992 - val_loss: 1.8880 - val_acc: 0.2270\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.9035 - acc: 0.2104 - val_loss: 1.8793 - val_acc: 0.2300\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.8973 - acc: 0.2151 - val_loss: 1.8704 - val_acc: 0.2350\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.8895 - acc: 0.2224 - val_loss: 1.8602 - val_acc: 0.2480\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.8792 - acc: 0.2300 - val_loss: 1.8491 - val_acc: 0.2590\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.8681 - acc: 0.2368 - val_loss: 1.8368 - val_acc: 0.2730\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.8588 - acc: 0.2429 - val_loss: 1.8233 - val_acc: 0.2810\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.8455 - acc: 0.253 - 0s 48us/step - loss: 1.8448 - acc: 0.2555 - val_loss: 1.8077 - val_acc: 0.3060\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.8314 - acc: 0.2668 - val_loss: 1.7910 - val_acc: 0.3250\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.8188 - acc: 0.2684 - val_loss: 1.7730 - val_acc: 0.3410\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.8047 - acc: 0.2884 - val_loss: 1.7549 - val_acc: 0.3520\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.7906 - acc: 0.2941 - val_loss: 1.7338 - val_acc: 0.3640\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.7712 - acc: 0.3060 - val_loss: 1.7115 - val_acc: 0.3880\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.7590 - acc: 0.3164 - val_loss: 1.6914 - val_acc: 0.4100\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.7496 - acc: 0.3204 - val_loss: 1.6704 - val_acc: 0.4310\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.7252 - acc: 0.3373 - val_loss: 1.6466 - val_acc: 0.4390\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.7137 - acc: 0.3317 - val_loss: 1.6228 - val_acc: 0.4530\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.6971 - acc: 0.3484 - val_loss: 1.5996 - val_acc: 0.4630\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.6802 - acc: 0.3567 - val_loss: 1.5783 - val_acc: 0.4770\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.6605 - acc: 0.3651 - val_loss: 1.5531 - val_acc: 0.4830\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.6498 - acc: 0.3669 - val_loss: 1.5303 - val_acc: 0.4950\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.6290 - acc: 0.3871 - val_loss: 1.5069 - val_acc: 0.5030\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.6139 - acc: 0.3861 - val_loss: 1.4868 - val_acc: 0.5120\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.6007 - acc: 0.3825 - val_loss: 1.4669 - val_acc: 0.5250\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.5837 - acc: 0.3980 - val_loss: 1.4448 - val_acc: 0.5260\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.5606 - acc: 0.4057 - val_loss: 1.4212 - val_acc: 0.5430\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.5548 - acc: 0.4048 - val_loss: 1.4015 - val_acc: 0.5450\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.5231 - acc: 0.4231 - val_loss: 1.3787 - val_acc: 0.5510\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.5271 - acc: 0.4165 - val_loss: 1.3617 - val_acc: 0.5550\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4969 - acc: 0.4293 - val_loss: 1.3411 - val_acc: 0.5590\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.4757 - acc: 0.4397 - val_loss: 1.3181 - val_acc: 0.5680\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.4703 - acc: 0.4416 - val_loss: 1.2976 - val_acc: 0.5800\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.4536 - acc: 0.4543 - val_loss: 1.2810 - val_acc: 0.5790\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4333 - acc: 0.4611 - val_loss: 1.2620 - val_acc: 0.5870\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.4274 - acc: 0.4509 - val_loss: 1.2478 - val_acc: 0.5930\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.4164 - acc: 0.4579 - val_loss: 1.2299 - val_acc: 0.6010\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4018 - acc: 0.4709 - val_loss: 1.2112 - val_acc: 0.6050\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.3895 - acc: 0.4732 - val_loss: 1.1971 - val_acc: 0.6120\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.3782 - acc: 0.4843 - val_loss: 1.1807 - val_acc: 0.6190\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3614 - acc: 0.4853 - val_loss: 1.1705 - val_acc: 0.6250\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.3625 - acc: 0.4861 - val_loss: 1.1560 - val_acc: 0.6310\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3434 - acc: 0.4919 - val_loss: 1.1443 - val_acc: 0.6370\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.3208 - acc: 0.4992 - val_loss: 1.1289 - val_acc: 0.6410\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.3267 - acc: 0.499 - 0s 49us/step - loss: 1.3214 - acc: 0.4992 - val_loss: 1.1176 - val_acc: 0.6440\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.3096 - acc: 0.5017 - val_loss: 1.1059 - val_acc: 0.6480\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3160 - acc: 0.4951 - val_loss: 1.0928 - val_acc: 0.6490\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.2771 - acc: 0.5111 - val_loss: 1.0799 - val_acc: 0.6510\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.2794 - acc: 0.5161 - val_loss: 1.0670 - val_acc: 0.6560\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2666 - acc: 0.5223 - val_loss: 1.0574 - val_acc: 0.6570\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2725 - acc: 0.5141 - val_loss: 1.0480 - val_acc: 0.6580\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.2597 - acc: 0.5225 - val_loss: 1.0415 - val_acc: 0.6620\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.2490 - acc: 0.5277 - val_loss: 1.0337 - val_acc: 0.6650\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.2349 - acc: 0.5297 - val_loss: 1.0214 - val_acc: 0.6680\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2318 - acc: 0.5347 - val_loss: 1.0136 - val_acc: 0.6690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2186 - acc: 0.5315 - val_loss: 1.0046 - val_acc: 0.6720\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.2301 - acc: 0.5281 - val_loss: 0.9969 - val_acc: 0.6800\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.2174 - acc: 0.5373 - val_loss: 0.9892 - val_acc: 0.6820\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1997 - acc: 0.5368 - val_loss: 0.9829 - val_acc: 0.6790\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1840 - acc: 0.5551 - val_loss: 0.9727 - val_acc: 0.6840\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1951 - acc: 0.5429 - val_loss: 0.9686 - val_acc: 0.6880\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1834 - acc: 0.5552 - val_loss: 0.9609 - val_acc: 0.6910\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1772 - acc: 0.5525 - val_loss: 0.9510 - val_acc: 0.6920\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1580 - acc: 0.5632 - val_loss: 0.9432 - val_acc: 0.6930\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1567 - acc: 0.5567 - val_loss: 0.9384 - val_acc: 0.6920\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.1486 - acc: 0.5677 - val_loss: 0.9284 - val_acc: 0.7000\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1649 - acc: 0.5599 - val_loss: 0.9222 - val_acc: 0.6980\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1450 - acc: 0.5711 - val_loss: 0.9165 - val_acc: 0.7000\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.1167 - acc: 0.5817 - val_loss: 0.9109 - val_acc: 0.6940\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1350 - acc: 0.5679 - val_loss: 0.9021 - val_acc: 0.7040\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1287 - acc: 0.5667 - val_loss: 0.8965 - val_acc: 0.7070\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1157 - acc: 0.5804 - val_loss: 0.8917 - val_acc: 0.7040\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1267 - acc: 0.5765 - val_loss: 0.8882 - val_acc: 0.7040\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1125 - acc: 0.5807 - val_loss: 0.8814 - val_acc: 0.7060\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0998 - acc: 0.5883 - val_loss: 0.8754 - val_acc: 0.7100\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0914 - acc: 0.5932 - val_loss: 0.8707 - val_acc: 0.7050\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1016 - acc: 0.5792 - val_loss: 0.8666 - val_acc: 0.7060\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0752 - acc: 0.5983 - val_loss: 0.8592 - val_acc: 0.7130\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0828 - acc: 0.5932 - val_loss: 0.8546 - val_acc: 0.7140\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0750 - acc: 0.6012 - val_loss: 0.8501 - val_acc: 0.7100\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0613 - acc: 0.6083 - val_loss: 0.8413 - val_acc: 0.7130\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0640 - acc: 0.5961 - val_loss: 0.8399 - val_acc: 0.7120\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0604 - acc: 0.6081 - val_loss: 0.8349 - val_acc: 0.7120\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0579 - acc: 0.6033 - val_loss: 0.8297 - val_acc: 0.7150\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0458 - acc: 0.6105 - val_loss: 0.8241 - val_acc: 0.7160\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0382 - acc: 0.6085 - val_loss: 0.8186 - val_acc: 0.7170\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0301 - acc: 0.6123 - val_loss: 0.8129 - val_acc: 0.7200\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0266 - acc: 0.6172 - val_loss: 0.8110 - val_acc: 0.7150\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0375 - acc: 0.6120 - val_loss: 0.8087 - val_acc: 0.7150\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0375 - acc: 0.6100 - val_loss: 0.8069 - val_acc: 0.7180\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0174 - acc: 0.6177 - val_loss: 0.8021 - val_acc: 0.7150\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0269 - acc: 0.6107 - val_loss: 0.7976 - val_acc: 0.7200\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0083 - acc: 0.6252 - val_loss: 0.7951 - val_acc: 0.7190\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0185 - acc: 0.6164 - val_loss: 0.7912 - val_acc: 0.7200\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0099 - acc: 0.6280 - val_loss: 0.7895 - val_acc: 0.7190\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9995 - acc: 0.6275 - val_loss: 0.7849 - val_acc: 0.7220\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9858 - acc: 0.6343 - val_loss: 0.7775 - val_acc: 0.7240\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9814 - acc: 0.6335 - val_loss: 0.7747 - val_acc: 0.7220\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9904 - acc: 0.6315 - val_loss: 0.7704 - val_acc: 0.7210\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9974 - acc: 0.6292 - val_loss: 0.7691 - val_acc: 0.7230\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9790 - acc: 0.6328 - val_loss: 0.7651 - val_acc: 0.7230\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9827 - acc: 0.6291 - val_loss: 0.7646 - val_acc: 0.7210\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9845 - acc: 0.6401 - val_loss: 0.7597 - val_acc: 0.7220\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9697 - acc: 0.6336 - val_loss: 0.7602 - val_acc: 0.7230\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9730 - acc: 0.6341 - val_loss: 0.7562 - val_acc: 0.7230\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9626 - acc: 0.6401 - val_loss: 0.7540 - val_acc: 0.7220\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9507 - acc: 0.6472 - val_loss: 0.7518 - val_acc: 0.7230\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9613 - acc: 0.6435 - val_loss: 0.7469 - val_acc: 0.7240\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9633 - acc: 0.6349 - val_loss: 0.7466 - val_acc: 0.7270\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9521 - acc: 0.6473 - val_loss: 0.7414 - val_acc: 0.7260\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9460 - acc: 0.6405 - val_loss: 0.7393 - val_acc: 0.7270\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9354 - acc: 0.6520 - val_loss: 0.7359 - val_acc: 0.7240\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9485 - acc: 0.6485 - val_loss: 0.7361 - val_acc: 0.7240\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9352 - acc: 0.6561 - val_loss: 0.7354 - val_acc: 0.7270\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9457 - acc: 0.6457 - val_loss: 0.7326 - val_acc: 0.7260\n",
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9372 - acc: 0.6527 - val_loss: 0.7308 - val_acc: 0.7260\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9332 - acc: 0.6492 - val_loss: 0.7281 - val_acc: 0.7280\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9273 - acc: 0.6543 - val_loss: 0.7287 - val_acc: 0.7230\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9256 - acc: 0.6569 - val_loss: 0.7229 - val_acc: 0.7280\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9241 - acc: 0.6511 - val_loss: 0.7208 - val_acc: 0.7280\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.9226 - acc: 0.6535 - val_loss: 0.7188 - val_acc: 0.7290\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9197 - acc: 0.6595 - val_loss: 0.7166 - val_acc: 0.7310\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9217 - acc: 0.6557 - val_loss: 0.7146 - val_acc: 0.7310\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9106 - acc: 0.6577 - val_loss: 0.7144 - val_acc: 0.7280\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9146 - acc: 0.6619 - val_loss: 0.7103 - val_acc: 0.7290\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9020 - acc: 0.6600 - val_loss: 0.7082 - val_acc: 0.7270\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8952 - acc: 0.6701 - val_loss: 0.7046 - val_acc: 0.7310\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9068 - acc: 0.6635 - val_loss: 0.7054 - val_acc: 0.7330\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9099 - acc: 0.6591 - val_loss: 0.7037 - val_acc: 0.7290\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8868 - acc: 0.6781 - val_loss: 0.7011 - val_acc: 0.7310\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8865 - acc: 0.6673 - val_loss: 0.7001 - val_acc: 0.7310\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8865 - acc: 0.6736 - val_loss: 0.6972 - val_acc: 0.7310\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8822 - acc: 0.6755 - val_loss: 0.6952 - val_acc: 0.7320\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8773 - acc: 0.6720 - val_loss: 0.6931 - val_acc: 0.7300\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8734 - acc: 0.6703 - val_loss: 0.6907 - val_acc: 0.7320\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8879 - acc: 0.6760 - val_loss: 0.6915 - val_acc: 0.7280\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8727 - acc: 0.6775 - val_loss: 0.6887 - val_acc: 0.7280\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8862 - acc: 0.6695 - val_loss: 0.6888 - val_acc: 0.7290\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8695 - acc: 0.6819 - val_loss: 0.6857 - val_acc: 0.7300\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8742 - acc: 0.6744 - val_loss: 0.6841 - val_acc: 0.7360\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8660 - acc: 0.6737 - val_loss: 0.6824 - val_acc: 0.7340\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8670 - acc: 0.6801 - val_loss: 0.6803 - val_acc: 0.7330\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8493 - acc: 0.6803 - val_loss: 0.6773 - val_acc: 0.7360\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8571 - acc: 0.6751 - val_loss: 0.6751 - val_acc: 0.7380\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8506 - acc: 0.6873 - val_loss: 0.6760 - val_acc: 0.7300\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8572 - acc: 0.6821 - val_loss: 0.6735 - val_acc: 0.7350\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(50, activation='relu'))\n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:44:56.216407Z",
     "start_time": "2020-09-14T16:44:55.859324Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 39us/step\n",
      "Training Loss: 0.569 \n",
      "Training Accuracy: 0.797\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 37us/step\n",
      "Test Loss: 0.63 \n",
      "Test Accuracy: 0.777\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:46:11.050189Z",
     "start_time": "2020-09-14T16:45:55.337375Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:50:18.695440Z",
     "start_time": "2020-09-14T16:46:14.794044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 1.9094 - acc: 0.2058 - val_loss: 1.8345 - val_acc: 0.2880\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.7063 - acc: 0.3807 - val_loss: 1.5580 - val_acc: 0.4847\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.3807 - acc: 0.5635 - val_loss: 1.2276 - val_acc: 0.6242\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.0952 - acc: 0.6571 - val_loss: 0.9973 - val_acc: 0.6935\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.9136 - acc: 0.6978 - val_loss: 0.8595 - val_acc: 0.7147\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.8042 - acc: 0.7236 - val_loss: 0.7780 - val_acc: 0.7322\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.7356 - acc: 0.7393 - val_loss: 0.7270 - val_acc: 0.7430\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.6898 - acc: 0.7512 - val_loss: 0.6955 - val_acc: 0.7502\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6573 - acc: 0.7601 - val_loss: 0.6702 - val_acc: 0.7538\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6332 - acc: 0.7665 - val_loss: 0.6528 - val_acc: 0.7598\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6142 - acc: 0.7726 - val_loss: 0.6389 - val_acc: 0.7620\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5982 - acc: 0.7787 - val_loss: 0.6315 - val_acc: 0.7635\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5846 - acc: 0.7837 - val_loss: 0.6199 - val_acc: 0.7722\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5729 - acc: 0.7893 - val_loss: 0.6100 - val_acc: 0.7775\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5625 - acc: 0.7930 - val_loss: 0.6030 - val_acc: 0.7820\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5531 - acc: 0.7967 - val_loss: 0.5983 - val_acc: 0.7797\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5444 - acc: 0.7998 - val_loss: 0.5962 - val_acc: 0.7820\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5360 - acc: 0.8036 - val_loss: 0.5874 - val_acc: 0.7865\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5287 - acc: 0.8066 - val_loss: 0.5828 - val_acc: 0.7895\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5214 - acc: 0.8103 - val_loss: 0.5783 - val_acc: 0.7955\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5150 - acc: 0.8127 - val_loss: 0.5737 - val_acc: 0.7957\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5086 - acc: 0.8158 - val_loss: 0.5723 - val_acc: 0.7940\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5028 - acc: 0.8182 - val_loss: 0.5718 - val_acc: 0.7920\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4972 - acc: 0.8205 - val_loss: 0.5656 - val_acc: 0.7987\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4921 - acc: 0.8224 - val_loss: 0.5641 - val_acc: 0.7942\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4870 - acc: 0.8242 - val_loss: 0.5627 - val_acc: 0.7945\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.4822 - acc: 0.826 - 2s 33us/step - loss: 0.4821 - acc: 0.8266 - val_loss: 0.5585 - val_acc: 0.7918\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4780 - acc: 0.8280 - val_loss: 0.5539 - val_acc: 0.8013\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4736 - acc: 0.8302 - val_loss: 0.5533 - val_acc: 0.8003\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4693 - acc: 0.8321 - val_loss: 0.5562 - val_acc: 0.8002\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4655 - acc: 0.8328 - val_loss: 0.5514 - val_acc: 0.8035\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4613 - acc: 0.8346 - val_loss: 0.5507 - val_acc: 0.7987\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4579 - acc: 0.8374 - val_loss: 0.5481 - val_acc: 0.8025\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4544 - acc: 0.8376 - val_loss: 0.5493 - val_acc: 0.7980\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4511 - acc: 0.8392 - val_loss: 0.5443 - val_acc: 0.8050\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4476 - acc: 0.8407 - val_loss: 0.5452 - val_acc: 0.8045\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4447 - acc: 0.8413 - val_loss: 0.5458 - val_acc: 0.8040\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4418 - acc: 0.8425 - val_loss: 0.5422 - val_acc: 0.8042\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4388 - acc: 0.8435 - val_loss: 0.5408 - val_acc: 0.8070\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4360 - acc: 0.8451 - val_loss: 0.5430 - val_acc: 0.8037\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4332 - acc: 0.8461 - val_loss: 0.5427 - val_acc: 0.8105\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4309 - acc: 0.8464 - val_loss: 0.5387 - val_acc: 0.8115\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4278 - acc: 0.8478 - val_loss: 0.5411 - val_acc: 0.8050\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4252 - acc: 0.8490 - val_loss: 0.5381 - val_acc: 0.8085\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4232 - acc: 0.8505 - val_loss: 0.5392 - val_acc: 0.8097\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4206 - acc: 0.8509 - val_loss: 0.5424 - val_acc: 0.8055\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4183 - acc: 0.8531 - val_loss: 0.5397 - val_acc: 0.8075\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4161 - acc: 0.8533 - val_loss: 0.5355 - val_acc: 0.8110\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4139 - acc: 0.8541 - val_loss: 0.5350 - val_acc: 0.8125\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4119 - acc: 0.8550 - val_loss: 0.5383 - val_acc: 0.8090\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4096 - acc: 0.8553 - val_loss: 0.5391 - val_acc: 0.8110\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4080 - acc: 0.8563 - val_loss: 0.5406 - val_acc: 0.8105\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4059 - acc: 0.8571 - val_loss: 0.5432 - val_acc: 0.8062\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4041 - acc: 0.8578 - val_loss: 0.5395 - val_acc: 0.8125\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4022 - acc: 0.8584 - val_loss: 0.5358 - val_acc: 0.8130\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4002 - acc: 0.8588 - val_loss: 0.5353 - val_acc: 0.8110\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3983 - acc: 0.8596 - val_loss: 0.5390 - val_acc: 0.8127\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3967 - acc: 0.8607 - val_loss: 0.5356 - val_acc: 0.8128\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3950 - acc: 0.8610 - val_loss: 0.5476 - val_acc: 0.8022\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3934 - acc: 0.8615 - val_loss: 0.5408 - val_acc: 0.8065\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3918 - acc: 0.8625 - val_loss: 0.5451 - val_acc: 0.8093\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3903 - acc: 0.8631 - val_loss: 0.5353 - val_acc: 0.8125\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3886 - acc: 0.8639 - val_loss: 0.5364 - val_acc: 0.8127\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3871 - acc: 0.8636 - val_loss: 0.5380 - val_acc: 0.8112\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3856 - acc: 0.8648 - val_loss: 0.5387 - val_acc: 0.8117\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3841 - acc: 0.8653 - val_loss: 0.5425 - val_acc: 0.8143\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3826 - acc: 0.8660 - val_loss: 0.5380 - val_acc: 0.8102\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3808 - acc: 0.8673 - val_loss: 0.5396 - val_acc: 0.8110\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3796 - acc: 0.8665 - val_loss: 0.5378 - val_acc: 0.8118\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3784 - acc: 0.8671 - val_loss: 0.5433 - val_acc: 0.8112\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3768 - acc: 0.8677 - val_loss: 0.5408 - val_acc: 0.8148\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3755 - acc: 0.8679 - val_loss: 0.5380 - val_acc: 0.8123\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3742 - acc: 0.8690 - val_loss: 0.5401 - val_acc: 0.8113\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3726 - acc: 0.8689 - val_loss: 0.5413 - val_acc: 0.8108\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3714 - acc: 0.8691 - val_loss: 0.5419 - val_acc: 0.8123\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3704 - acc: 0.8697 - val_loss: 0.5432 - val_acc: 0.8127\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3691 - acc: 0.8700 - val_loss: 0.5442 - val_acc: 0.8120\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3676 - acc: 0.8708 - val_loss: 0.5487 - val_acc: 0.8103\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3669 - acc: 0.8713 - val_loss: 0.5430 - val_acc: 0.8108\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3655 - acc: 0.8720 - val_loss: 0.5435 - val_acc: 0.8110\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3644 - acc: 0.8720 - val_loss: 0.5489 - val_acc: 0.8113\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3631 - acc: 0.8731 - val_loss: 0.5425 - val_acc: 0.8143\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3618 - acc: 0.8732 - val_loss: 0.5453 - val_acc: 0.8133\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3611 - acc: 0.8736 - val_loss: 0.5455 - val_acc: 0.8110\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3600 - acc: 0.8736 - val_loss: 0.5447 - val_acc: 0.8115\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3587 - acc: 0.8740 - val_loss: 0.5451 - val_acc: 0.8140\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3577 - acc: 0.8739 - val_loss: 0.5443 - val_acc: 0.8140\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3563 - acc: 0.8752 - val_loss: 0.5503 - val_acc: 0.8122\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3552 - acc: 0.8757 - val_loss: 0.5483 - val_acc: 0.8125\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3543 - acc: 0.8752 - val_loss: 0.5508 - val_acc: 0.8090\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3533 - acc: 0.8751 - val_loss: 0.5477 - val_acc: 0.8115\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3522 - acc: 0.8766 - val_loss: 0.5487 - val_acc: 0.8145\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3511 - acc: 0.8771 - val_loss: 0.5492 - val_acc: 0.8135\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3503 - acc: 0.8774 - val_loss: 0.5516 - val_acc: 0.8095\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3493 - acc: 0.8771 - val_loss: 0.5526 - val_acc: 0.8127\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3482 - acc: 0.8778 - val_loss: 0.5535 - val_acc: 0.8145\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3472 - acc: 0.8785 - val_loss: 0.5534 - val_acc: 0.8147\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3459 - acc: 0.8787 - val_loss: 0.5658 - val_acc: 0.8030\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3451 - acc: 0.8787 - val_loss: 0.5523 - val_acc: 0.8157\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3440 - acc: 0.8787 - val_loss: 0.5539 - val_acc: 0.8132\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3432 - acc: 0.8801 - val_loss: 0.5566 - val_acc: 0.8100\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3423 - acc: 0.8790 - val_loss: 0.5696 - val_acc: 0.8015\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3415 - acc: 0.8799 - val_loss: 0.5550 - val_acc: 0.8110\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3405 - acc: 0.8799 - val_loss: 0.5539 - val_acc: 0.8122\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3396 - acc: 0.8806 - val_loss: 0.5593 - val_acc: 0.8135\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3386 - acc: 0.8807 - val_loss: 0.5579 - val_acc: 0.8130\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.3377 - acc: 0.881 - 2s 32us/step - loss: 0.3375 - acc: 0.8812 - val_loss: 0.5613 - val_acc: 0.8148\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3367 - acc: 0.8817 - val_loss: 0.5604 - val_acc: 0.8097\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3358 - acc: 0.8823 - val_loss: 0.5594 - val_acc: 0.8150\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3347 - acc: 0.8830 - val_loss: 0.5670 - val_acc: 0.8050\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3341 - acc: 0.8822 - val_loss: 0.5607 - val_acc: 0.8112\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3333 - acc: 0.8833 - val_loss: 0.5662 - val_acc: 0.8105\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3323 - acc: 0.8830 - val_loss: 0.5668 - val_acc: 0.8085\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3313 - acc: 0.8844 - val_loss: 0.5615 - val_acc: 0.8113\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3305 - acc: 0.8849 - val_loss: 0.5629 - val_acc: 0.8115\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3296 - acc: 0.8845 - val_loss: 0.5686 - val_acc: 0.8090\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3285 - acc: 0.8850 - val_loss: 0.5636 - val_acc: 0.8110\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3281 - acc: 0.8848 - val_loss: 0.5637 - val_acc: 0.8105\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3267 - acc: 0.8851 - val_loss: 0.5643 - val_acc: 0.8140\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3263 - acc: 0.8863 - val_loss: 0.5677 - val_acc: 0.8097\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3254 - acc: 0.8866 - val_loss: 0.5663 - val_acc: 0.8107\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3246 - acc: 0.8867 - val_loss: 0.5685 - val_acc: 0.8088\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3236 - acc: 0.8866 - val_loss: 0.5724 - val_acc: 0.8080\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3228 - acc: 0.8860 - val_loss: 0.5690 - val_acc: 0.8107\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3218 - acc: 0.8887 - val_loss: 0.5708 - val_acc: 0.8112\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3212 - acc: 0.8876 - val_loss: 0.5743 - val_acc: 0.8095\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3202 - acc: 0.8877 - val_loss: 0.5740 - val_acc: 0.8082\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3189 - acc: 0.8887 - val_loss: 0.5778 - val_acc: 0.8060\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3185 - acc: 0.8891 - val_loss: 0.5782 - val_acc: 0.8080\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3175 - acc: 0.8893 - val_loss: 0.5740 - val_acc: 0.8090\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3171 - acc: 0.8890 - val_loss: 0.5774 - val_acc: 0.8075\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3158 - acc: 0.8901 - val_loss: 0.5792 - val_acc: 0.8018\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3152 - acc: 0.8904 - val_loss: 0.5765 - val_acc: 0.8123\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3145 - acc: 0.8909 - val_loss: 0.5765 - val_acc: 0.8085\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3131 - acc: 0.8909 - val_loss: 0.5855 - val_acc: 0.7993\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3128 - acc: 0.8914 - val_loss: 0.5801 - val_acc: 0.8075\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3115 - acc: 0.8911 - val_loss: 0.5770 - val_acc: 0.8095\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3107 - acc: 0.8916 - val_loss: 0.5889 - val_acc: 0.8080\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3099 - acc: 0.8929 - val_loss: 0.5866 - val_acc: 0.8045\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3091 - acc: 0.8924 - val_loss: 0.5830 - val_acc: 0.8095\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3083 - acc: 0.8928 - val_loss: 0.5796 - val_acc: 0.8092\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3076 - acc: 0.8930 - val_loss: 0.5881 - val_acc: 0.8035\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3063 - acc: 0.8937 - val_loss: 0.5854 - val_acc: 0.8063\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3058 - acc: 0.8945 - val_loss: 0.5830 - val_acc: 0.8088\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3047 - acc: 0.8937 - val_loss: 0.5836 - val_acc: 0.8060\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.3039 - acc: 0.894 - 2s 33us/step - loss: 0.3037 - acc: 0.8944 - val_loss: 0.5871 - val_acc: 0.8092\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3030 - acc: 0.8954 - val_loss: 0.5861 - val_acc: 0.8093\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3021 - acc: 0.8953 - val_loss: 0.5874 - val_acc: 0.8070\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3012 - acc: 0.8961 - val_loss: 0.5909 - val_acc: 0.8107\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3008 - acc: 0.8957 - val_loss: 0.5912 - val_acc: 0.8075\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T16:52:03.743228Z",
     "start_time": "2020-09-14T16:52:01.806528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 36us/step\n",
      "Training Loss: 0.296 \n",
      "Training Accuracy: 0.897\n",
      "----------\n",
      "4000/4000 [==============================] - 0s 35us/step\n",
      "Test Loss: 0.591 \n",
      "Test Accuracy: 0.807\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
